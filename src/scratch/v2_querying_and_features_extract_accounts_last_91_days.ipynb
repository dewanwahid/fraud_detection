{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Counts: Periodic Invoices - All Accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "get_ipython().magic(u'config IPCompleter.greedy=True')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install simplejson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect with the Redshift Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import closing\n",
    "\n",
    "\n",
    "import psycopg2\n",
    "import simplejson\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')\n",
    "\n",
    "DEFAULT_DB = 'data_depot'\n",
    "DEFAULT_HOST = 'freshbooks-data.c8exzn6geij3.us-east-1.redshift.amazonaws.com'\n",
    "DEFAULT_PORT = 5439\n",
    "\n",
    "\n",
    "class PsycopgConnector:\n",
    "    '''\n",
    "    A database connector that uses Psycopg to connect to Redshift.\n",
    "\n",
    "    How to play:\n",
    "\n",
    "        psy_conn = PsycopgConnector(username, password)\n",
    "        df = psy_conn.run_query(sql=sql, return_data=True)\n",
    "\n",
    "    NOTE: This class commits queries to redshift if return_data=False.\n",
    "    This means INSERT, DROP, TRUNCATE, etc. all work against the DB.\n",
    "    '''\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        username=None,\n",
    "        password=None,\n",
    "        db=DEFAULT_DB,\n",
    "        host=DEFAULT_HOST,\n",
    "        port=DEFAULT_PORT,\n",
    "    ):\n",
    "\n",
    "        self.db = DEFAULT_DB\n",
    "        self.host = DEFAULT_HOST\n",
    "        self.port = DEFAULT_PORT\n",
    "\n",
    "        self.username = username\n",
    "        self.password = password\n",
    "\n",
    "    def _get_connection(self):\n",
    "\n",
    "        self.conn = psycopg2.connect(\n",
    "            dbname=self.db,\n",
    "            user=self.username,\n",
    "            password=self.password,\n",
    "            host=self.host,\n",
    "            port=self.port\n",
    "        )\n",
    "\n",
    "        return self.conn\n",
    "\n",
    "    def run_query(self, sql, return_data=False):\n",
    "\n",
    "        with closing(self._get_connection()) as conn:\n",
    "            with conn, conn.cursor() as cur:\n",
    "                if return_data:\n",
    "                    return pd.read_sql(sql=sql, con=conn)\n",
    "                else:\n",
    "                    cur.execute(sql)\n",
    "                    \n",
    "\n",
    "# Read the Redshift's credentials file \n",
    "with open(\"redshift_creds.json.nogit\") as fh:\n",
    "    creds = simplejson.loads(fh.read())\n",
    "    \n",
    "username = creds.get(\"user_name\")\n",
    "password = creds.get(\"password\")\n",
    "\n",
    "pig = PsycopgConnector(username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing connection\n",
    "sql_test = '''SELECT * FROM report_systems LIMIT 5'''\n",
    "df_test = pig.run_query(sql_test, return_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>systemid</th>\n",
       "      <th>business_id</th>\n",
       "      <th>admin_identity_id</th>\n",
       "      <th>subdomain</th>\n",
       "      <th>is_freshbooks_account_active</th>\n",
       "      <th>is_modern</th>\n",
       "      <th>most_recent_migrated_to_smux_at</th>\n",
       "      <th>is_contractor</th>\n",
       "      <th>currency_code</th>\n",
       "      <th>timezone</th>\n",
       "      <th>...</th>\n",
       "      <th>staff_count</th>\n",
       "      <th>staff_deleted_count</th>\n",
       "      <th>contractor_count</th>\n",
       "      <th>contractor_deleted_count</th>\n",
       "      <th>user_contact_count</th>\n",
       "      <th>enabled_gateway_count</th>\n",
       "      <th>google_sso_first_linked_date</th>\n",
       "      <th>google_sso_most_recent_linked_date</th>\n",
       "      <th>google_sso_first_removal_date</th>\n",
       "      <th>google_sso_most_recent_removal_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://systemdt.freshbooks.com</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>CAD</td>\n",
       "      <td>Etc/GMT+5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://IntercodeTechnologiesInc.freshbooks.com</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>USD</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2332</td>\n",
       "      <td>91460.0</td>\n",
       "      <td>122105.0</td>\n",
       "      <td>https://cstoneweb.freshbooks.com</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-11-14</td>\n",
       "      <td>0</td>\n",
       "      <td>USD</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://paul.freshbooks.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>GBP</td>\n",
       "      <td>Etc/GMT</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7541</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://Prological1.freshbooks.com</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>USD</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   systemid  business_id  admin_identity_id  \\\n",
       "0       848          NaN                NaN   \n",
       "1      2154          NaN                NaN   \n",
       "2      2332      91460.0           122105.0   \n",
       "3      6359          NaN                NaN   \n",
       "4      7541          NaN                NaN   \n",
       "\n",
       "                                         subdomain  \\\n",
       "0                  https://systemdt.freshbooks.com   \n",
       "1  https://IntercodeTechnologiesInc.freshbooks.com   \n",
       "2                 https://cstoneweb.freshbooks.com   \n",
       "3                      https://paul.freshbooks.com   \n",
       "4               https://Prological1.freshbooks.com   \n",
       "\n",
       "   is_freshbooks_account_active  is_modern most_recent_migrated_to_smux_at  \\\n",
       "0                             1          0                            None   \n",
       "1                             1          0                            None   \n",
       "2                             1          1                      2016-11-14   \n",
       "3                             0          0                            None   \n",
       "4                             1          0                            None   \n",
       "\n",
       "   is_contractor currency_code    timezone  ...  staff_count  \\\n",
       "0              1           CAD   Etc/GMT+5  ...            3   \n",
       "1              0           USD  US/Eastern  ...            0   \n",
       "2              0           USD  US/Eastern  ...            0   \n",
       "3              0           GBP     Etc/GMT  ...            9   \n",
       "4              0           USD  US/Eastern  ...            0   \n",
       "\n",
       "  staff_deleted_count contractor_count contractor_deleted_count  \\\n",
       "0                   3                4                        6   \n",
       "1                   0                0                        0   \n",
       "2                   0                0                        0   \n",
       "3                   9                0                        0   \n",
       "4                   0                0                        0   \n",
       "\n",
       "  user_contact_count enabled_gateway_count google_sso_first_linked_date  \\\n",
       "0                  9                     2                         None   \n",
       "1                  0                     0                         None   \n",
       "2                  1                     1                         None   \n",
       "3                  2                     0                         None   \n",
       "4                  0                     0                         None   \n",
       "\n",
       "  google_sso_most_recent_linked_date google_sso_first_removal_date  \\\n",
       "0                               None                          None   \n",
       "1                               None                          None   \n",
       "2                               None                          None   \n",
       "3                               None                          None   \n",
       "4                               None                          None   \n",
       "\n",
       "  google_sso_most_recent_removal_date  \n",
       "0                                None  \n",
       "1                                None  \n",
       "2                                None  \n",
       "3                                None  \n",
       "4                                None  \n",
       "\n",
       "[5 rows x 133 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word count fuction\n",
    "import re\n",
    "def words_count (strg):\n",
    "    \n",
    "    #print(strg)\n",
    "    \n",
    "    if strg == '' or pd.isnull(strg):\n",
    "        no_of_words = 0\n",
    "        #print('NaN')\n",
    "    else:\n",
    "        strg_words_list = re.findall(r\"[\\w']+\", strg)\n",
    "        no_of_words = len(strg_words_list)\n",
    "\n",
    "        \n",
    "        #print(strg_words_list)\n",
    "    \n",
    "    return no_of_words \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Invoice Data & Extract Avg Word Counts Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.01 Invoice within 7 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL for impoorting all invoices created within 7 days after signup_date\n",
    "sql_invoices_7days_all_accounts = '''WITH invoices_in_a_period AS (\n",
    "    SELECT \n",
    "            systemid, \n",
    "            signup_date\n",
    "    FROM report_systems rs\n",
    "    WHERE signup_date BETWEEN '2019-08-01' and '2019-10-31'\n",
    "), invoice_created_at AS (\n",
    "    SELECT\n",
    "           pic.systemid,\n",
    "           pic.signup_date,\n",
    "           inv.invoiceid,\n",
    "           inv.create_date,\n",
    "           inv.created_at,\n",
    "           inv.description,\n",
    "           inv.notes,\n",
    "           inv.terms,\n",
    "           inv.address,\n",
    "           DATEDIFF(days, pic.signup_date, inv.created_at) AS days_to_invoice_creation\n",
    "    FROM invoices_in_a_period AS pic\n",
    "    LEFT JOIN coalesced_live_shards.invoice_stable as inv USING (systemid)\n",
    "    WHERE ((days_to_invoice_creation BETWEEN 0 AND 7) OR days_to_invoice_creation IS NULL)\n",
    ")\n",
    "\n",
    "SELECT *\n",
    "FROM invoice_created_at;'''\n",
    "\n",
    "# Import as dataframe from redshift\n",
    "# df_invoices_7days_all_accounts = pd.read_sql_query(sql_invoices_7days_all_accounts, connect_to_db)\n",
    "df_invoices_7days_all_accounts = pig.run_query(sql_invoices_7days_all_accounts, return_data=True)\n",
    "\n",
    "\n",
    "# Words count in invoice's description, notes, terms, address\n",
    "df_invoices_7days_all_accounts['avg_wc_description_day_7'] = df_invoices_7days_all_accounts.apply(lambda x: words_count(x['description']), axis=1)\n",
    "df_invoices_7days_all_accounts['avg_wc_notes_day_7'] = df_invoices_7days_all_accounts.apply(lambda x: words_count(x['notes']), axis=1)\n",
    "df_invoices_7days_all_accounts['avg_wc_terms_day_7'] = df_invoices_7days_all_accounts.apply(lambda x: words_count(x['terms']), axis=1)\n",
    "df_invoices_7days_all_accounts['avg_wc_address_day_7'] = df_invoices_7days_all_accounts.apply(lambda x: words_count(x['address']), axis=1)\n",
    "\n",
    "                                                                                                                   \n",
    "# Filters the text columns from the dataframe\n",
    "df_invoices_7days_all_accounts_fil = df_invoices_7days_all_accounts.filter(['systemid', \n",
    "                                                                            'invoiceid', \n",
    "                                                                            'signup_date', \n",
    "                                                                            'create_date', \n",
    "                                                                            'created_at',\n",
    "                                                                            'days_to_invoice_creation', \n",
    "                                                                            'avg_wc_description_day_7', \n",
    "                                                                            'avg_wc_notes_day_7', \n",
    "                                                                            'avg_wc_terms_day_7',\n",
    "                                                                            'avg_wc_address_day_7'])  \n",
    "                                                                                                                   \n",
    "# Summing (grouping) all invoices for a 'systemid'\n",
    "df_word_count_7days_all_accounts_total = df_invoices_7days_all_accounts_fil.groupby('systemid').mean()  \n",
    "\n",
    "# Final word count table\n",
    "df_word_count_7days_all_accounts_final = df_word_count_7days_all_accounts_total.filter(['systemid',\n",
    "                                                                            'avg_wc_description_day_7', \n",
    "                                                                            'avg_wc_notes_day_7', \n",
    "                                                                            'avg_wc_terms_day_7',\n",
    "                                                                            'avg_wc_address_day_7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Export as csv file\n",
    "df_word_count_7days_all_accounts_final.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/df_word_count_7days_new_accounts_final.tsv\", \n",
    "                                      sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Invoice within 14 days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL for impoorting all invoices created within 14 days after signup_date\n",
    "sql_invoices_14days_all_accounts = '''WITH invoices_in_a_period AS (\n",
    "    SELECT systemid, signup_date\n",
    "    FROM report_systems rs\n",
    "    WHERE signup_date BETWEEN '2019-08-01' and '2019-10-31'\n",
    "), invoice_created_at AS (\n",
    "    SELECT\n",
    "           pic.systemid,\n",
    "           inv.invoiceid,\n",
    "           pic.signup_date,\n",
    "           inv.create_date,\n",
    "           inv.created_at,\n",
    "           inv.description,\n",
    "           inv.notes,\n",
    "           inv.terms,\n",
    "           inv.address,\n",
    "           DATEDIFF(days, pic.signup_date, inv.created_at) AS days_to_invoice_creation\n",
    "    FROM invoices_in_a_period AS pic\n",
    "    LEFT JOIN coalesced_live_shards.invoice_stable as inv USING (systemid)\n",
    "    WHERE ((days_to_invoice_creation BETWEEN 0 AND 14) OR days_to_invoice_creation IS NULL)\n",
    ")\n",
    "\n",
    "SELECT *\n",
    "FROM invoice_created_at;'''\n",
    "\n",
    "# Import as dataframe from redshift\n",
    "# df_invoices_14days_all_accounts = pd.read_sql_query(sql_invoices_14days_all_accounts, connect_to_db)\n",
    "df_invoices_14days_all_accounts = pig.run_query(sql_invoices_14days_all_accounts, return_data=True)\n",
    "\n",
    "\n",
    "# Words count in invoice's description, notes, terms, address\n",
    "df_invoices_14days_all_accounts['avg_wc_description_day_14'] = df_invoices_14days_all_accounts.apply(lambda x: words_count(x['description']), axis=1)\n",
    "df_invoices_14days_all_accounts['avg_wc_notes_day_14'] = df_invoices_14days_all_accounts.apply(lambda x: words_count(x['notes']), axis=1)\n",
    "df_invoices_14days_all_accounts['avg_wc_terms_day_14'] = df_invoices_14days_all_accounts.apply(lambda x: words_count(x['terms']), axis=1)\n",
    "df_invoices_14days_all_accounts['avg_wc_address_day_14'] = df_invoices_14days_all_accounts.apply(lambda x: words_count(x['address']), axis=1)\n",
    "\n",
    "                                                                                                                   \n",
    "# Filters the text columns from the dataframe\n",
    "df_invoices_14days_all_accounts_fil = df_invoices_14days_all_accounts.filter(['systemid', 'invoiceid', \n",
    "                                                                            'signup_date', \n",
    "                                                                            'create_date', \n",
    "                                                                            'created_at',\n",
    "                                                                            'days_to_invoice_creation', \n",
    "                                                                            'avg_wc_description_day_14', \n",
    "                                                                            'avg_wc_notes_day_14', \n",
    "                                                                            'avg_wc_terms_day_14',\n",
    "                                                                            'avg_wc_address_day_14'])  \n",
    "                                                                                                                   \n",
    "# Summing (grouping) all invoices for a 'systemid'\n",
    "df_word_count_14days_all_accounts_total = df_invoices_14days_all_accounts_fil.groupby('systemid').mean()  \n",
    "\n",
    "# Final word count table\n",
    "df_word_count_14days_all_accounts_final = df_word_count_14days_all_accounts_total.filter(['systemid',\n",
    "                                                                            'avg_wc_description_day_14', \n",
    "                                                                            'avg_wc_notes_day_14', \n",
    "                                                                            'avg_wc_terms_day_14',\n",
    "                                                                            'avg_wc_address_day_14'])\n",
    "\n",
    "# Export as csv file\n",
    "df_word_count_14days_all_accounts_final.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/df_word_count_14days_new_accounts_final.tsv\", \n",
    "                                      sep=\"\\t\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_wc_description_day_14</th>\n",
       "      <th>avg_wc_notes_day_14</th>\n",
       "      <th>avg_wc_terms_day_14</th>\n",
       "      <th>avg_wc_address_day_14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systemid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4504870</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504872</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504874</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504876</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504878</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          avg_wc_description_day_14  avg_wc_notes_day_14  avg_wc_terms_day_14  \\\n",
       "systemid                                                                        \n",
       "4504870                         0.0                  0.0                  0.0   \n",
       "4504872                         1.0                  0.0                  0.0   \n",
       "4504874                         0.0                  0.0                  0.0   \n",
       "4504876                         0.0                  0.0                  0.0   \n",
       "4504878                         0.0                  0.0                  0.0   \n",
       "\n",
       "          avg_wc_address_day_14  \n",
       "systemid                         \n",
       "4504870                     0.0  \n",
       "4504872                     0.0  \n",
       "4504874                     0.0  \n",
       "4504876                     0.0  \n",
       "4504878                     0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_count_14days_all_accounts_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Invoice within 21 days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL for impoorting all invoices created within 21 days after signup_date\n",
    "sql_invoices_21days_all_accounts = '''WITH invoices_in_a_period AS (\n",
    "    SELECT systemid, signup_date\n",
    "    FROM report_systems rs\n",
    "    WHERE signup_date BETWEEN '2019-08-01' and '2019-10-31'\n",
    "), invoice_created_at AS (\n",
    "    SELECT\n",
    "           pic.systemid,\n",
    "           inv.invoiceid,\n",
    "           pic.signup_date,\n",
    "           inv.create_date,\n",
    "           inv.created_at,\n",
    "           inv.description,\n",
    "           inv.notes,\n",
    "           inv.terms,\n",
    "           inv.address,\n",
    "           DATEDIFF(days, pic.signup_date, inv.created_at) AS days_to_invoice_creation\n",
    "    FROM invoices_in_a_period AS pic\n",
    "    LEFT JOIN coalesced_live_shards.invoice_stable as inv USING (systemid)\n",
    "    WHERE ((days_to_invoice_creation BETWEEN 0 AND 21) OR days_to_invoice_creation IS NULL)\n",
    ")\n",
    "\n",
    "SELECT *\n",
    "FROM invoice_created_at;'''\n",
    "\n",
    "# Import as dataframe from redshift\n",
    "df_invoices_21days_all_accounts = pig.run_query(sql_invoices_21days_all_accounts, return_data=True)\n",
    "\n",
    "# Words count in invoice's description, notes, terms, address\n",
    "df_invoices_21days_all_accounts['avg_wc_description_day_21'] = df_invoices_21days_all_accounts.apply(lambda x: words_count(x['description']), axis=1)\n",
    "df_invoices_21days_all_accounts['avg_wc_notes_day_21'] = df_invoices_21days_all_accounts.apply(lambda x: words_count(x['notes']), axis=1)\n",
    "df_invoices_21days_all_accounts['avg_wc_terms_day_21'] = df_invoices_21days_all_accounts.apply(lambda x: words_count(x['terms']), axis=1)\n",
    "df_invoices_21days_all_accounts['avg_wc_address_day_21'] = df_invoices_21days_all_accounts.apply(lambda x: words_count(x['address']), axis=1)\n",
    "\n",
    "                                                                                                                   \n",
    "# Filters the text columns from the dataframe\n",
    "df_invoices_21days_all_accounts_fil = df_invoices_21days_all_accounts.filter(['systemid', 'invoiceid', \n",
    "                                                                            'signup_date', \n",
    "                                                                            'create_date', \n",
    "                                                                            'created_at',\n",
    "                                                                            'days_to_invoice_creation', \n",
    "                                                                            'avg_wc_description_day_21', \n",
    "                                                                            'avg_wc_notes_day_21', \n",
    "                                                                            'avg_wc_terms_day_21',\n",
    "                                                                            'avg_wc_address_day_21'])  \n",
    "                                                                                                                   \n",
    "# Summing (grouping) all invoices for a 'systemid'\n",
    "df_word_count_21days_all_accounts_total = df_invoices_21days_all_accounts_fil.groupby('systemid').mean()  \n",
    "\n",
    "# Final word count table\n",
    "df_word_count_21days_all_accounts_final = df_word_count_21days_all_accounts_total.filter(['systemid',\n",
    "                                                                            'avg_wc_description_day_21', \n",
    "                                                                            'avg_wc_notes_day_21', \n",
    "                                                                            'avg_wc_terms_day_21',\n",
    "                                                                            'avg_wc_address_day_21'])\n",
    "\n",
    "# Export as csv file\n",
    "df_word_count_21days_all_accounts_final.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/df_word_count_21days_new_accounts_final.tsv\", \n",
    "                                      sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_wc_description_day_21</th>\n",
       "      <th>avg_wc_notes_day_21</th>\n",
       "      <th>avg_wc_terms_day_21</th>\n",
       "      <th>avg_wc_address_day_21</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systemid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4504870</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504872</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504874</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504876</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504878</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          avg_wc_description_day_21  avg_wc_notes_day_21  avg_wc_terms_day_21  \\\n",
       "systemid                                                                        \n",
       "4504870                         0.0                  0.0                  0.0   \n",
       "4504872                         1.0                  0.0                  0.0   \n",
       "4504874                         0.0                  0.0                  0.0   \n",
       "4504876                         0.0                  0.0                  0.0   \n",
       "4504878                         0.0                  0.0                  0.0   \n",
       "\n",
       "          avg_wc_address_day_21  \n",
       "systemid                         \n",
       "4504870                     0.0  \n",
       "4504872                     0.0  \n",
       "4504874                     0.0  \n",
       "4504876                     0.0  \n",
       "4504878                     0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_count_21days_all_accounts_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Invoice within 28 days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL for impoorting all invoices created within 28 days after signup_date\n",
    "sql_invoices_28days_all_accounts = '''WITH invoices_in_a_period AS (\n",
    "    SELECT systemid, signup_date\n",
    "    FROM report_systems rs\n",
    "    WHERE signup_date BETWEEN '2019-08-01' and '2019-10-31'\n",
    "), invoice_created_at AS (\n",
    "    SELECT\n",
    "           pic.systemid,\n",
    "           inv.invoiceid,\n",
    "           pic.signup_date,\n",
    "           inv.create_date,\n",
    "           inv.created_at,\n",
    "           inv.description,\n",
    "           inv.notes,\n",
    "           inv.terms,\n",
    "           inv.address,\n",
    "           DATEDIFF(days, pic.signup_date, inv.created_at) AS days_to_invoice_creation\n",
    "    FROM invoices_in_a_period AS pic\n",
    "    LEFT JOIN coalesced_live_shards.invoice_stable as inv USING (systemid)\n",
    "    WHERE ((days_to_invoice_creation BETWEEN 0 AND 28) OR days_to_invoice_creation IS NULL)\n",
    ")\n",
    "\n",
    "SELECT *\n",
    "FROM invoice_created_at;'''\n",
    "\n",
    "# Import as dataframe from redshift\n",
    "df_invoices_28days_all_accounts = pig.run_query(sql_invoices_28days_all_accounts, return_data=True)\n",
    "\n",
    "# Words count in invoice's description, notes, terms, address\n",
    "df_invoices_28days_all_accounts['avg_wc_description_day_28'] = df_invoices_28days_all_accounts.apply(lambda x: words_count(x['description']), axis=1)\n",
    "df_invoices_28days_all_accounts['avg_wc_notes_day_28'] = df_invoices_28days_all_accounts.apply(lambda x: words_count(x['notes']), axis=1)\n",
    "df_invoices_28days_all_accounts['avg_wc_terms_day_28'] = df_invoices_28days_all_accounts.apply(lambda x: words_count(x['terms']), axis=1)\n",
    "df_invoices_28days_all_accounts['avg_wc_address_day_28'] = df_invoices_28days_all_accounts.apply(lambda x: words_count(x['address']), axis=1)\n",
    "\n",
    "                                                                                                                   \n",
    "# Filters the text columns from the dataframe\n",
    "df_invoices_28days_all_accounts_fil = df_invoices_28days_all_accounts.filter(['systemid', 'invoiceid', \n",
    "                                                                            'signup_date', \n",
    "                                                                            'create_date', \n",
    "                                                                            'created_at',\n",
    "                                                                            'days_to_invoice_creation', \n",
    "                                                                            'avg_wc_description_day_28', \n",
    "                                                                            'avg_wc_notes_day_28', \n",
    "                                                                            'avg_wc_terms_day_28',\n",
    "                                                                            'avg_wc_address_day_28'])  \n",
    "                                                                                                                   \n",
    "# Summing (grouping) all invoices for a 'systemid'\n",
    "df_word_count_28days_all_accounts_total = df_invoices_28days_all_accounts_fil.groupby('systemid').mean()  \n",
    "\n",
    "# Final word count table\n",
    "df_word_count_28days_all_accounts_final = df_word_count_28days_all_accounts_total.filter(['systemid',\n",
    "                                                                            'avg_wc_description_day_28', \n",
    "                                                                            'avg_wc_notes_day_28', \n",
    "                                                                            'avg_wc_terms_day_28',\n",
    "                                                                            'avg_wc_address_day_28'])\n",
    "\n",
    "# Export as csv file\n",
    "df_word_count_28days_all_accounts_final.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/df_word_count_28days_new_accounts_final.tsv\", \n",
    "                                      sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_wc_description_day_28</th>\n",
       "      <th>avg_wc_notes_day_28</th>\n",
       "      <th>avg_wc_terms_day_28</th>\n",
       "      <th>avg_wc_address_day_28</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systemid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4504870</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504872</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504874</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504876</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504878</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          avg_wc_description_day_28  avg_wc_notes_day_28  avg_wc_terms_day_28  \\\n",
       "systemid                                                                        \n",
       "4504870                         0.0                  0.0                  0.0   \n",
       "4504872                         1.0                  0.0                  0.0   \n",
       "4504874                         0.0                  0.0                  0.0   \n",
       "4504876                         0.0                  0.0                  0.0   \n",
       "4504878                         0.0                  0.0                  0.0   \n",
       "\n",
       "          avg_wc_address_day_28  \n",
       "systemid                         \n",
       "4504870                     0.0  \n",
       "4504872                     0.0  \n",
       "4504874                     0.0  \n",
       "4504876                     0.0  \n",
       "4504878                     0.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_count_28days_all_accounts_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Invoice within 35 days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL for impoorting all invoices created within 35 days after signup_date\n",
    "sql_invoices_35days_all_accounts = '''WITH invoices_in_a_period AS (\n",
    "    SELECT systemid, signup_date\n",
    "    FROM report_systems rs\n",
    "    WHERE signup_date BETWEEN '2019-08-01' and '2019-10-31'\n",
    "), invoice_created_at AS (\n",
    "    SELECT\n",
    "           pic.systemid,\n",
    "           inv.invoiceid,\n",
    "           pic.signup_date,\n",
    "           inv.create_date,\n",
    "           inv.created_at,\n",
    "           inv.description,\n",
    "           inv.notes,\n",
    "           inv.terms,\n",
    "           inv.address,\n",
    "           DATEDIFF(days, pic.signup_date, inv.created_at) AS days_to_invoice_creation\n",
    "    FROM invoices_in_a_period AS pic\n",
    "    LEFT JOIN coalesced_live_shards.invoice_stable as inv USING (systemid)\n",
    "    WHERE ((days_to_invoice_creation BETWEEN 0 AND 35) OR days_to_invoice_creation IS NULL)\n",
    ")\n",
    "\n",
    "SELECT *\n",
    "FROM invoice_created_at;'''\n",
    "\n",
    "# Import as dataframe from redshift\n",
    "df_invoices_35days_all_accounts = pig.run_query(sql_invoices_35days_all_accounts, return_data=True)\n",
    "\n",
    "# Words count in invoice's description, notes, terms, address\n",
    "df_invoices_35days_all_accounts['avg_wc_description_day_35'] = df_invoices_35days_all_accounts.apply(lambda x: words_count(x['description']), axis=1)\n",
    "df_invoices_35days_all_accounts['avg_wc_notes_day_35'] = df_invoices_35days_all_accounts.apply(lambda x: words_count(x['notes']), axis=1)\n",
    "df_invoices_35days_all_accounts['avg_wc_terms_day_35'] = df_invoices_35days_all_accounts.apply(lambda x: words_count(x['terms']), axis=1)\n",
    "df_invoices_35days_all_accounts['avg_wc_address_day_35'] = df_invoices_35days_all_accounts.apply(lambda x: words_count(x['address']), axis=1)\n",
    "\n",
    "                                                                                                                   \n",
    "# Filters the text columns from the dataframe\n",
    "df_invoices_35days_all_accounts_fil = df_invoices_35days_all_accounts.filter(['systemid', 'invoiceid', \n",
    "                                                                            'signup_date', \n",
    "                                                                            'create_date', \n",
    "                                                                            'created_at',\n",
    "                                                                            'days_to_invoice_creation', \n",
    "                                                                            'avg_wc_description_day_35', \n",
    "                                                                            'avg_wc_notes_day_35', \n",
    "                                                                            'avg_wc_terms_day_35',\n",
    "                                                                            'avg_wc_address_day_35'])  \n",
    "                                                                                                                   \n",
    "# Summing (grouping) all invoices for a 'systemid'\n",
    "df_word_count_35days_all_accounts_total = df_invoices_35days_all_accounts_fil.groupby('systemid').mean()  \n",
    "\n",
    "# Final word count table\n",
    "df_word_count_35days_all_accounts_final = df_word_count_35days_all_accounts_total.filter(['systemid',\n",
    "                                                                            'avg_wc_description_day_35', \n",
    "                                                                            'avg_wc_notes_day_35', \n",
    "                                                                            'avg_wc_terms_day_35',\n",
    "                                                                            'avg_wc_address_day_35'])\n",
    "\n",
    "# Export as csv file\n",
    "df_word_count_35days_all_accounts_final.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/df_word_count_35days_new_accounts_final.tsv\", \n",
    "                                      sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_wc_description_day_35</th>\n",
       "      <th>avg_wc_notes_day_35</th>\n",
       "      <th>avg_wc_terms_day_35</th>\n",
       "      <th>avg_wc_address_day_35</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systemid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4504870</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504872</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504874</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504876</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504878</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          avg_wc_description_day_35  avg_wc_notes_day_35  avg_wc_terms_day_35  \\\n",
       "systemid                                                                        \n",
       "4504870                         0.0                  0.0                  0.0   \n",
       "4504872                         1.0                  0.0                  0.0   \n",
       "4504874                         0.0                  0.0                  0.0   \n",
       "4504876                         0.0                  0.0                  0.0   \n",
       "4504878                         0.0                  0.0                  0.0   \n",
       "\n",
       "          avg_wc_address_day_35  \n",
       "systemid                         \n",
       "4504870                     0.0  \n",
       "4504872                     0.0  \n",
       "4504874                     0.0  \n",
       "4504876                     0.0  \n",
       "4504878                     0.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_count_35days_all_accounts_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Invoice within 42 days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL for impoorting all invoices created within 42 days after signup_date\n",
    "sql_invoices_42days_all_accounts = '''WITH invoices_in_a_period AS (\n",
    "    SELECT systemid, signup_date\n",
    "    FROM report_systems rs\n",
    "    WHERE signup_date BETWEEN '2019-08-01' and '2019-10-31'\n",
    "), invoice_created_at AS (\n",
    "    SELECT\n",
    "           pic.systemid,\n",
    "           inv.invoiceid,\n",
    "           pic.signup_date,\n",
    "           inv.create_date,\n",
    "           inv.created_at,\n",
    "           inv.description,\n",
    "           inv.notes,\n",
    "           inv.terms,\n",
    "           inv.address,\n",
    "           DATEDIFF(days, pic.signup_date, inv.created_at) AS days_to_invoice_creation\n",
    "    FROM invoices_in_a_period AS pic\n",
    "    LEFT JOIN coalesced_live_shards.invoice_stable as inv USING (systemid)\n",
    "    WHERE ((days_to_invoice_creation BETWEEN 0 AND 42) OR days_to_invoice_creation IS NULL)\n",
    ")\n",
    "\n",
    "SELECT *\n",
    "FROM invoice_created_at;'''\n",
    "\n",
    "# Import as dataframe from redshift\n",
    "df_invoices_42days_all_accounts = pig.run_query(sql_invoices_42days_all_accounts, return_data=True)\n",
    "\n",
    "# Words count in invoice's description, notes, terms, address\n",
    "df_invoices_42days_all_accounts['avg_wc_description_day_42'] = df_invoices_42days_all_accounts.apply(lambda x: words_count(x['description']), axis=1)\n",
    "df_invoices_42days_all_accounts['avg_wc_notes_day_42'] = df_invoices_42days_all_accounts.apply(lambda x: words_count(x['notes']), axis=1)\n",
    "df_invoices_42days_all_accounts['avg_wc_terms_day_42'] = df_invoices_42days_all_accounts.apply(lambda x: words_count(x['terms']), axis=1)\n",
    "df_invoices_42days_all_accounts['avg_wc_address_day_42'] = df_invoices_42days_all_accounts.apply(lambda x: words_count(x['address']), axis=1)\n",
    "\n",
    "                                                                                                                   \n",
    "# Filters the text columns from the dataframe\n",
    "df_invoices_42days_all_accounts_fil = df_invoices_42days_all_accounts.filter(['systemid', 'invoiceid', \n",
    "                                                                            'signup_date', \n",
    "                                                                            'create_date', \n",
    "                                                                            'created_at',\n",
    "                                                                            'days_to_invoice_creation', \n",
    "                                                                            'avg_wc_description_day_42', \n",
    "                                                                            'avg_wc_notes_day_42', \n",
    "                                                                            'avg_wc_terms_day_42',\n",
    "                                                                            'avg_wc_address_day_42'])  \n",
    "                                                                                                                   \n",
    "# Summing (grouping) all invoices for a 'systemid'\n",
    "df_word_count_42days_all_accounts_total = df_invoices_42days_all_accounts_fil.groupby('systemid').mean()  \n",
    "\n",
    "# Final word count table\n",
    "df_word_count_42days_all_accounts_final = df_word_count_42days_all_accounts_total.filter(['systemid',\n",
    "                                                                            'avg_wc_description_day_42', \n",
    "                                                                            'avg_wc_notes_day_42', \n",
    "                                                                            'avg_wc_terms_day_42',\n",
    "                                                                            'avg_wc_address_day_42'])\n",
    "\n",
    "# Export as csv file\n",
    "df_word_count_42days_all_accounts_final.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/df_word_count_42days_new_accounts_final.tsv\", \n",
    "                                      sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_wc_description_day_42</th>\n",
       "      <th>avg_wc_notes_day_42</th>\n",
       "      <th>avg_wc_terms_day_42</th>\n",
       "      <th>avg_wc_address_day_42</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systemid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4504870</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504872</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504874</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504876</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504878</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          avg_wc_description_day_42  avg_wc_notes_day_42  avg_wc_terms_day_42  \\\n",
       "systemid                                                                        \n",
       "4504870                         0.0                  0.0                  0.0   \n",
       "4504872                         1.0                  0.0                  0.0   \n",
       "4504874                         0.0                  0.0                  0.0   \n",
       "4504876                         0.0                  0.0                  0.0   \n",
       "4504878                         0.0                  0.0                  0.0   \n",
       "\n",
       "          avg_wc_address_day_42  \n",
       "systemid                         \n",
       "4504870                     0.0  \n",
       "4504872                     0.0  \n",
       "4504874                     0.0  \n",
       "4504876                     0.0  \n",
       "4504878                     0.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_count_42days_all_accounts_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Invoice within 49 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL for impoorting all invoices created within 49 days after signup_date\n",
    "sql_invoices_49days_all_accounts = '''WITH invoices_in_a_period AS (\n",
    "    SELECT systemid, signup_date\n",
    "    FROM report_systems rs\n",
    "    WHERE signup_date BETWEEN '2019-08-01' and '2019-10-31'\n",
    "), invoice_created_at AS (\n",
    "    SELECT\n",
    "           pic.systemid,\n",
    "           inv.invoiceid,\n",
    "           pic.signup_date,\n",
    "           inv.create_date,\n",
    "           inv.created_at,\n",
    "           inv.description,\n",
    "           inv.notes,\n",
    "           inv.terms,\n",
    "           inv.address,\n",
    "           DATEDIFF(days, pic.signup_date, inv.created_at) AS days_to_invoice_creation\n",
    "    FROM invoices_in_a_period AS pic\n",
    "    LEFT JOIN coalesced_live_shards.invoice_stable as inv USING (systemid)\n",
    "    WHERE ((days_to_invoice_creation BETWEEN 0 AND 49) OR days_to_invoice_creation IS NULL)\n",
    ")\n",
    "\n",
    "SELECT *\n",
    "FROM invoice_created_at;'''\n",
    "\n",
    "# Import as dataframe from redshift\n",
    "df_invoices_49days_all_accounts = pig.run_query(sql_invoices_49days_all_accounts, return_data=True)\n",
    "\n",
    "# Words count in invoice's description, notes, terms, address\n",
    "df_invoices_49days_all_accounts['avg_wc_description_day_49'] = df_invoices_49days_all_accounts.apply(lambda x: words_count(x['description']), axis=1)\n",
    "df_invoices_49days_all_accounts['avg_wc_notes_day_49'] = df_invoices_49days_all_accounts.apply(lambda x: words_count(x['notes']), axis=1)\n",
    "df_invoices_49days_all_accounts['avg_wc_terms_day_49'] = df_invoices_49days_all_accounts.apply(lambda x: words_count(x['terms']), axis=1)\n",
    "df_invoices_49days_all_accounts['avg_wc_address_day_49'] = df_invoices_49days_all_accounts.apply(lambda x: words_count(x['address']), axis=1)\n",
    "\n",
    "                                                                                                                   \n",
    "# Filters the text columns from the dataframe\n",
    "df_invoices_49days_all_accounts_fil = df_invoices_49days_all_accounts.filter(['systemid', 'invoiceid', \n",
    "                                                                            'signup_date', \n",
    "                                                                            'create_date', \n",
    "                                                                            'created_at',\n",
    "                                                                            'days_to_invoice_creation', \n",
    "                                                                            'avg_wc_description_day_49', \n",
    "                                                                            'avg_wc_notes_day_49', \n",
    "                                                                            'avg_wc_terms_day_49',\n",
    "                                                                            'avg_wc_address_day_49'])  \n",
    "                                                                                                                   \n",
    "# Summing (grouping) all invoices for a 'systemid'\n",
    "df_word_count_49days_all_accounts_total = df_invoices_49days_all_accounts_fil.groupby('systemid').mean()  \n",
    "\n",
    "# Final word count table\n",
    "df_word_count_49days_all_accounts_final = df_word_count_49days_all_accounts_total.filter(['systemid',\n",
    "                                                                            'avg_wc_description_day_49', \n",
    "                                                                            'avg_wc_notes_day_49', \n",
    "                                                                            'avg_wc_terms_day_49',\n",
    "                                                                            'avg_wc_address_day_49'])\n",
    "\n",
    "# Export as csv file\n",
    "df_word_count_49days_all_accounts_final.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/df_word_count_49days_new_accounts_final.tsv\", \n",
    "                                      sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_wc_description_day_49</th>\n",
       "      <th>avg_wc_notes_day_49</th>\n",
       "      <th>avg_wc_terms_day_49</th>\n",
       "      <th>avg_wc_address_day_49</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systemid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4504870</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504872</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504874</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504876</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504878</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          avg_wc_description_day_49  avg_wc_notes_day_49  avg_wc_terms_day_49  \\\n",
       "systemid                                                                        \n",
       "4504870                         0.0                  0.0                  0.0   \n",
       "4504872                         1.0                  0.0                  0.0   \n",
       "4504874                         0.0                  0.0                  0.0   \n",
       "4504876                         0.0                  0.0                  0.0   \n",
       "4504878                         0.0                  0.0                  0.0   \n",
       "\n",
       "          avg_wc_address_day_49  \n",
       "systemid                         \n",
       "4504870                     0.0  \n",
       "4504872                     0.0  \n",
       "4504874                     0.0  \n",
       "4504876                     0.0  \n",
       "4504878                     0.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_count_49days_all_accounts_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 Invoice within 56 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL for impoorting all invoices created within 56 days after signup_date\n",
    "sql_invoices_56days_all_accounts = '''WITH invoices_in_a_period AS (\n",
    "    SELECT systemid, signup_date\n",
    "    FROM report_systems rs\n",
    "    WHERE signup_date BETWEEN '2019-08-01' and '2019-10-31'\n",
    "), invoice_created_at AS (\n",
    "    SELECT\n",
    "           pic.systemid,\n",
    "           inv.invoiceid,\n",
    "           pic.signup_date,\n",
    "           inv.create_date,\n",
    "           inv.created_at,\n",
    "           inv.description,\n",
    "           inv.notes,\n",
    "           inv.terms,\n",
    "           inv.address,\n",
    "           DATEDIFF(days, pic.signup_date, inv.created_at) AS days_to_invoice_creation\n",
    "    FROM invoices_in_a_period AS pic\n",
    "    LEFT JOIN coalesced_live_shards.invoice_stable as inv USING (systemid)\n",
    "    WHERE ((days_to_invoice_creation BETWEEN 0 AND 56) OR days_to_invoice_creation IS NULL)\n",
    ")\n",
    "\n",
    "SELECT *\n",
    "FROM invoice_created_at;'''\n",
    "\n",
    "# Import as dataframe from redshift\n",
    "df_invoices_56days_all_accounts = pig.run_query(sql_invoices_56days_all_accounts, return_data=True)\n",
    "\n",
    "# Words count in invoice's description, notes, terms, address\n",
    "df_invoices_56days_all_accounts['avg_wc_description_day_56'] = df_invoices_56days_all_accounts.apply(lambda x: words_count(x['description']), axis=1)\n",
    "df_invoices_56days_all_accounts['avg_wc_notes_day_56'] = df_invoices_56days_all_accounts.apply(lambda x: words_count(x['notes']), axis=1)\n",
    "df_invoices_56days_all_accounts['avg_wc_terms_day_56'] = df_invoices_56days_all_accounts.apply(lambda x: words_count(x['terms']), axis=1)\n",
    "df_invoices_56days_all_accounts['avg_wc_address_day_56'] = df_invoices_56days_all_accounts.apply(lambda x: words_count(x['address']), axis=1)\n",
    "\n",
    "                                                                                                                   \n",
    "# Filters the text columns from the dataframe\n",
    "df_invoices_56days_all_accounts_fil = df_invoices_56days_all_accounts.filter(['systemid', 'invoiceid', \n",
    "                                                                            'signup_date', \n",
    "                                                                            'create_date', \n",
    "                                                                            'created_at',\n",
    "                                                                            'days_to_invoice_creation', \n",
    "                                                                            'avg_wc_description_day_56', \n",
    "                                                                            'avg_wc_notes_day_56', \n",
    "                                                                            'avg_wc_terms_day_56',\n",
    "                                                                            'avg_wc_address_day_56'])  \n",
    "                                                                                                                   \n",
    "# Summing (grouping) all invoices for a 'systemid'\n",
    "df_word_count_56days_all_accounts_total = df_invoices_56days_all_accounts_fil.groupby('systemid').mean()  \n",
    "\n",
    "# Final word count table\n",
    "df_word_count_56days_all_accounts_final = df_word_count_56days_all_accounts_total.filter(['systemid',\n",
    "                                                                            'avg_wc_description_day_56', \n",
    "                                                                            'avg_wc_notes_day_56', \n",
    "                                                                            'avg_wc_terms_day_56',\n",
    "                                                                            'avg_wc_address_day_56'])\n",
    "\n",
    "# Export as csv file\n",
    "df_word_count_56days_all_accounts_final.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/df_word_count_56days_new_accounts_final.tsv\", \n",
    "                                      sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_wc_description_day_56</th>\n",
       "      <th>avg_wc_notes_day_56</th>\n",
       "      <th>avg_wc_terms_day_56</th>\n",
       "      <th>avg_wc_address_day_56</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systemid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4504870</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504872</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504874</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504876</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504878</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          avg_wc_description_day_56  avg_wc_notes_day_56  avg_wc_terms_day_56  \\\n",
       "systemid                                                                        \n",
       "4504870                         0.0                  0.0                  0.0   \n",
       "4504872                         1.0                  0.0                  0.0   \n",
       "4504874                         0.0                  0.0                  0.0   \n",
       "4504876                         0.0                  0.0                  0.0   \n",
       "4504878                         0.0                  0.0                  0.0   \n",
       "\n",
       "          avg_wc_address_day_56  \n",
       "systemid                         \n",
       "4504870                     0.0  \n",
       "4504872                     0.0  \n",
       "4504874                     0.0  \n",
       "4504876                     0.0  \n",
       "4504878                     0.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_count_56days_all_accounts_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.9 Invoice within 63 days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL for impoorting all invoices created within 63 days after signup_date\n",
    "sql_invoices_63days_all_accounts = '''WITH invoices_in_a_period AS (\n",
    "    SELECT systemid, signup_date\n",
    "    FROM report_systems rs\n",
    "    WHERE signup_date BETWEEN '2019-08-01' and '2019-10-31'\n",
    "), invoice_created_at AS (\n",
    "    SELECT\n",
    "           pic.systemid,\n",
    "           inv.invoiceid,\n",
    "           pic.signup_date,\n",
    "           inv.create_date,\n",
    "           inv.created_at,\n",
    "           inv.description,\n",
    "           inv.notes,\n",
    "           inv.terms,\n",
    "           inv.address,\n",
    "           DATEDIFF(days, pic.signup_date, inv.created_at) AS days_to_invoice_creation\n",
    "    FROM invoices_in_a_period AS pic\n",
    "    LEFT JOIN coalesced_live_shards.invoice_stable as inv USING (systemid)\n",
    "    WHERE ((days_to_invoice_creation BETWEEN 0 AND 63) OR days_to_invoice_creation IS NULL)\n",
    ")\n",
    "\n",
    "SELECT *\n",
    "FROM invoice_created_at;'''\n",
    "\n",
    "# Import as dataframe from redshift\n",
    "df_invoices_63days_all_accounts = pig.run_query(sql_invoices_63days_all_accounts, return_data=True)\n",
    "\n",
    "# Words count in invoice's description, notes, terms, address\n",
    "df_invoices_63days_all_accounts['avg_wc_description_day_63'] = df_invoices_63days_all_accounts.apply(lambda x: words_count(x['description']), axis=1)\n",
    "df_invoices_63days_all_accounts['avg_wc_notes_day_63'] = df_invoices_63days_all_accounts.apply(lambda x: words_count(x['notes']), axis=1)\n",
    "df_invoices_63days_all_accounts['avg_wc_terms_day_63'] = df_invoices_63days_all_accounts.apply(lambda x: words_count(x['terms']), axis=1)\n",
    "df_invoices_63days_all_accounts['avg_wc_address_day_63'] = df_invoices_63days_all_accounts.apply(lambda x: words_count(x['address']), axis=1)\n",
    "\n",
    "                                                                                                                   \n",
    "# Filters the text columns from the dataframe\n",
    "df_invoices_63days_all_accounts_fil = df_invoices_63days_all_accounts.filter(['systemid', 'invoiceid', \n",
    "                                                                            'signup_date', \n",
    "                                                                            'create_date', \n",
    "                                                                            'created_at',\n",
    "                                                                            'days_to_invoice_creation', \n",
    "                                                                            'avg_wc_description_day_63', \n",
    "                                                                            'avg_wc_notes_day_63', \n",
    "                                                                            'avg_wc_terms_day_63',\n",
    "                                                                            'avg_wc_address_day_63'])  \n",
    "                                                                                                                   \n",
    "# Summing (grouping) all invoices for a 'systemid'\n",
    "df_word_count_63days_all_accounts_total = df_invoices_63days_all_accounts_fil.groupby('systemid').mean()  \n",
    "\n",
    "# Final word count table\n",
    "df_word_count_63days_all_accounts_final = df_word_count_63days_all_accounts_total.filter(['systemid',\n",
    "                                                                            'avg_wc_description_day_63', \n",
    "                                                                            'avg_wc_notes_day_63', \n",
    "                                                                            'avg_wc_terms_day_63',\n",
    "                                                                            'avg_wc_address_day_63'])\n",
    "\n",
    "# Export as csv file\n",
    "df_word_count_63days_all_accounts_final.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/df_word_count_63days_new_accounts_final.tsv\", \n",
    "                                      sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_wc_description_day_63</th>\n",
       "      <th>avg_wc_notes_day_63</th>\n",
       "      <th>avg_wc_terms_day_63</th>\n",
       "      <th>avg_wc_address_day_63</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systemid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4504870</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504872</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504874</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504876</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504878</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          avg_wc_description_day_63  avg_wc_notes_day_63  avg_wc_terms_day_63  \\\n",
       "systemid                                                                        \n",
       "4504870                         0.0                  0.0                  0.0   \n",
       "4504872                         1.0                  0.0                  0.0   \n",
       "4504874                         0.0                  0.0                  0.0   \n",
       "4504876                         0.0                  0.0                  0.0   \n",
       "4504878                         0.0                  0.0                  0.0   \n",
       "\n",
       "          avg_wc_address_day_63  \n",
       "systemid                         \n",
       "4504870                     0.0  \n",
       "4504872                     0.0  \n",
       "4504874                     0.0  \n",
       "4504876                     0.0  \n",
       "4504878                     0.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_count_63days_all_accounts_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.10 Invoice within 70 days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL for impoorting all invoices created within 70 days after signup_date\n",
    "sql_invoices_70days_all_accounts = '''WITH invoices_in_a_period AS (\n",
    "    SELECT systemid, signup_date\n",
    "    FROM report_systems rs\n",
    "    WHERE signup_date BETWEEN '2019-08-01' and '2019-10-31'\n",
    "), invoice_created_at AS (\n",
    "    SELECT\n",
    "           pic.systemid,\n",
    "           inv.invoiceid,\n",
    "           pic.signup_date,\n",
    "           inv.create_date,\n",
    "           inv.created_at,\n",
    "           inv.description,\n",
    "           inv.notes,\n",
    "           inv.terms,\n",
    "           inv.address,\n",
    "           DATEDIFF(days, pic.signup_date, inv.created_at) AS days_to_invoice_creation\n",
    "    FROM invoices_in_a_period AS pic\n",
    "    LEFT JOIN coalesced_live_shards.invoice_stable as inv USING (systemid)\n",
    "    WHERE ((days_to_invoice_creation BETWEEN 0 AND 70) OR days_to_invoice_creation IS NULL)\n",
    ")\n",
    "\n",
    "SELECT *\n",
    "FROM invoice_created_at;'''\n",
    "\n",
    "# Import as dataframe from redshift\n",
    "df_invoices_70days_all_accounts = pig.run_query(sql_invoices_70days_all_accounts, return_data=True)\n",
    "\n",
    "# Words count in invoice's description, notes, terms, address\n",
    "df_invoices_70days_all_accounts['avg_wc_description_day_70'] = df_invoices_70days_all_accounts.apply(lambda x: words_count(x['description']), axis=1)\n",
    "df_invoices_70days_all_accounts['avg_wc_notes_day_70'] = df_invoices_70days_all_accounts.apply(lambda x: words_count(x['notes']), axis=1)\n",
    "df_invoices_70days_all_accounts['avg_wc_terms_day_70'] = df_invoices_70days_all_accounts.apply(lambda x: words_count(x['terms']), axis=1)\n",
    "df_invoices_70days_all_accounts['avg_wc_address_day_70'] = df_invoices_70days_all_accounts.apply(lambda x: words_count(x['address']), axis=1)\n",
    "\n",
    "                                                                                                                   \n",
    "# Filters the text columns from the dataframe\n",
    "df_invoices_70days_all_accounts_fil = df_invoices_70days_all_accounts.filter(['systemid', 'invoiceid', \n",
    "                                                                            'signup_date', \n",
    "                                                                            'create_date', \n",
    "                                                                            'created_at',\n",
    "                                                                            'days_to_invoice_creation', \n",
    "                                                                            'avg_wc_description_day_70', \n",
    "                                                                            'avg_wc_notes_day_70', \n",
    "                                                                            'avg_wc_terms_day_70',\n",
    "                                                                            'avg_wc_address_day_70'])  \n",
    "                                                                                                                   \n",
    "# Summing (grouping) all invoices for a 'systemid'\n",
    "df_word_count_70days_all_accounts_total = df_invoices_70days_all_accounts_fil.groupby('systemid').mean()  \n",
    "\n",
    "# Final word count table\n",
    "df_word_count_70days_all_accounts_final = df_word_count_70days_all_accounts_total.filter(['systemid',\n",
    "                                                                            'avg_wc_description_day_70', \n",
    "                                                                            'avg_wc_notes_day_70', \n",
    "                                                                            'avg_wc_terms_day_70',\n",
    "                                                                            'avg_wc_address_day_70'])\n",
    "\n",
    "# Export as csv file\n",
    "df_word_count_70days_all_accounts_final.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/df_word_count_70days_new_accounts_final.tsv\", \n",
    "                                      sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_wc_description_day_70</th>\n",
       "      <th>avg_wc_notes_day_70</th>\n",
       "      <th>avg_wc_terms_day_70</th>\n",
       "      <th>avg_wc_address_day_70</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systemid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4504870</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504872</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504874</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504876</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504878</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          avg_wc_description_day_70  avg_wc_notes_day_70  avg_wc_terms_day_70  \\\n",
       "systemid                                                                        \n",
       "4504870                         0.0                  0.0                  0.0   \n",
       "4504872                         1.0                  0.0                  0.0   \n",
       "4504874                         0.0                  0.0                  0.0   \n",
       "4504876                         0.0                  0.0                  0.0   \n",
       "4504878                         0.0                  0.0                  0.0   \n",
       "\n",
       "          avg_wc_address_day_70  \n",
       "systemid                         \n",
       "4504870                     0.0  \n",
       "4504872                     0.0  \n",
       "4504874                     0.0  \n",
       "4504876                     0.0  \n",
       "4504878                     0.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_count_70days_all_accounts_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.11 Invoice 77 days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL for impoorting all invoices created within 77 days after signup_date\n",
    "sql_invoices_77days_all_accounts = '''WITH invoices_in_a_period AS (\n",
    "    SELECT systemid, signup_date\n",
    "    FROM report_systems rs\n",
    "    WHERE signup_date BETWEEN '2019-08-01' and '2019-10-31'\n",
    "), invoice_created_at AS (\n",
    "    SELECT\n",
    "           pic.systemid,\n",
    "           inv.invoiceid,\n",
    "           pic.signup_date,\n",
    "           inv.create_date,\n",
    "           inv.created_at,\n",
    "           inv.description,\n",
    "           inv.notes,\n",
    "           inv.terms,\n",
    "           inv.address,\n",
    "           DATEDIFF(days, pic.signup_date, inv.created_at) AS days_to_invoice_creation\n",
    "    FROM invoices_in_a_period AS pic\n",
    "    LEFT JOIN coalesced_live_shards.invoice_stable as inv USING (systemid)\n",
    "    WHERE ((days_to_invoice_creation BETWEEN 0 AND 77) OR days_to_invoice_creation IS NULL)\n",
    ")\n",
    "\n",
    "SELECT *\n",
    "FROM invoice_created_at;'''\n",
    "\n",
    "# Import as dataframe from redshift\n",
    "df_invoices_77days_all_accounts = pig.run_query(sql_invoices_77days_all_accounts, return_data=True)\n",
    "\n",
    "# Words count in invoice's description, notes, terms, address\n",
    "df_invoices_77days_all_accounts['avg_wc_description_day_77'] = df_invoices_77days_all_accounts.apply(lambda x: words_count(x['description']), axis=1)\n",
    "df_invoices_77days_all_accounts['avg_wc_notes_day_77'] = df_invoices_77days_all_accounts.apply(lambda x: words_count(x['notes']), axis=1)\n",
    "df_invoices_77days_all_accounts['avg_wc_terms_day_77'] = df_invoices_77days_all_accounts.apply(lambda x: words_count(x['terms']), axis=1)\n",
    "df_invoices_77days_all_accounts['avg_wc_address_day_77'] = df_invoices_77days_all_accounts.apply(lambda x: words_count(x['address']), axis=1)\n",
    "\n",
    "                                                                                                                   \n",
    "# Filters the text columns from the dataframe\n",
    "df_invoices_77days_all_accounts_fil = df_invoices_77days_all_accounts.filter(['systemid', 'invoiceid', \n",
    "                                                                            'signup_date', \n",
    "                                                                            'create_date', \n",
    "                                                                            'created_at',\n",
    "                                                                            'days_to_invoice_creation', \n",
    "                                                                            'avg_wc_description_day_77', \n",
    "                                                                            'avg_wc_notes_day_77', \n",
    "                                                                            'avg_wc_terms_day_77',\n",
    "                                                                            'avg_wc_address_day_77'])  \n",
    "                                                                                                                   \n",
    "# Summing (grouping) all invoices for a 'systemid'\n",
    "df_word_count_77days_all_accounts_total = df_invoices_77days_all_accounts_fil.groupby('systemid').mean()  \n",
    "\n",
    "# Final word count table\n",
    "df_word_count_77days_all_accounts_final = df_word_count_77days_all_accounts_total.filter(['systemid',\n",
    "                                                                            'avg_wc_description_day_77', \n",
    "                                                                            'avg_wc_notes_day_77', \n",
    "                                                                            'avg_wc_terms_day_77',\n",
    "                                                                            'avg_wc_address_day_77'])\n",
    "\n",
    "# Export as csv file\n",
    "df_word_count_77days_all_accounts_final.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/df_word_count_77days_new_accounts_final.tsv\", \n",
    "                                      sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_wc_description_day_77</th>\n",
       "      <th>avg_wc_notes_day_77</th>\n",
       "      <th>avg_wc_terms_day_77</th>\n",
       "      <th>avg_wc_address_day_77</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systemid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4504870</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504872</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504874</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504876</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504878</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          avg_wc_description_day_77  avg_wc_notes_day_77  avg_wc_terms_day_77  \\\n",
       "systemid                                                                        \n",
       "4504870                         0.0                  0.0                  0.0   \n",
       "4504872                         1.0                  0.0                  0.0   \n",
       "4504874                         0.0                  0.0                  0.0   \n",
       "4504876                         0.0                  0.0                  0.0   \n",
       "4504878                         0.0                  0.0                  0.0   \n",
       "\n",
       "          avg_wc_address_day_77  \n",
       "systemid                         \n",
       "4504870                     0.0  \n",
       "4504872                     0.0  \n",
       "4504874                     0.0  \n",
       "4504876                     0.0  \n",
       "4504878                     0.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_count_77days_all_accounts_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.12 Invoice within 84 days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL for impoorting all invoices created within 84 days after signup_date\n",
    "sql_invoices_84days_all_accounts = '''WITH invoices_in_a_period AS (\n",
    "    SELECT systemid, signup_date\n",
    "    FROM report_systems rs\n",
    "    WHERE signup_date BETWEEN '2019-08-01' and '2019-10-31'\n",
    "), invoice_created_at AS (\n",
    "    SELECT\n",
    "           pic.systemid,\n",
    "           inv.invoiceid,\n",
    "           pic.signup_date,\n",
    "           inv.create_date,\n",
    "           inv.created_at,\n",
    "           inv.description,\n",
    "           inv.notes,\n",
    "           inv.terms,\n",
    "           inv.address,\n",
    "           DATEDIFF(days, pic.signup_date, inv.created_at) AS days_to_invoice_creation\n",
    "    FROM invoices_in_a_period AS pic\n",
    "    LEFT JOIN coalesced_live_shards.invoice_stable as inv USING (systemid)\n",
    "    WHERE ((days_to_invoice_creation BETWEEN 0 AND 84) OR days_to_invoice_creation IS NULL)\n",
    ")\n",
    "\n",
    "SELECT *\n",
    "FROM invoice_created_at;'''\n",
    "\n",
    "# Import as dataframe from redshift\n",
    "df_invoices_84days_all_accounts = pig.run_query(sql_invoices_84days_all_accounts, return_data=True)\n",
    "\n",
    "# Words count in invoice's description, notes, terms, address\n",
    "df_invoices_84days_all_accounts['avg_wc_description_day_84'] = df_invoices_84days_all_accounts.apply(lambda x: words_count(x['description']), axis=1)\n",
    "df_invoices_84days_all_accounts['avg_wc_notes_day_84'] = df_invoices_84days_all_accounts.apply(lambda x: words_count(x['notes']), axis=1)\n",
    "df_invoices_84days_all_accounts['avg_wc_terms_day_84'] = df_invoices_84days_all_accounts.apply(lambda x: words_count(x['terms']), axis=1)\n",
    "df_invoices_84days_all_accounts['avg_wc_address_day_84'] = df_invoices_84days_all_accounts.apply(lambda x: words_count(x['address']), axis=1)\n",
    "\n",
    "                                                                                                                   \n",
    "# Filters the text columns from the dataframe\n",
    "df_invoices_84days_all_accounts_fil = df_invoices_84days_all_accounts.filter(['systemid', 'invoiceid', \n",
    "                                                                            'signup_date', \n",
    "                                                                            'create_date', \n",
    "                                                                            'created_at',\n",
    "                                                                            'days_to_invoice_creation', \n",
    "                                                                            'avg_wc_description_day_84', \n",
    "                                                                            'avg_wc_notes_day_84', \n",
    "                                                                            'avg_wc_terms_day_84',\n",
    "                                                                            'avg_wc_address_day_84'])  \n",
    "                                                                                                                   \n",
    "# Summing (grouping) all invoices for a 'systemid'\n",
    "df_word_count_84days_all_accounts_total = df_invoices_84days_all_accounts_fil.groupby('systemid').mean()  \n",
    "\n",
    "# Final word count table\n",
    "df_word_count_84days_all_accounts_final = df_word_count_84days_all_accounts_total.filter(['systemid',\n",
    "                                                                            'avg_wc_description_day_84', \n",
    "                                                                            'avg_wc_notes_day_84', \n",
    "                                                                            'avg_wc_terms_day_84',\n",
    "                                                                            'avg_wc_address_day_84'])\n",
    "\n",
    "# Export as csv file\n",
    "df_word_count_84days_all_accounts_final.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/df_word_count_84days_new_accounts_final.tsv\", \n",
    "                                      sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_wc_description_day_84</th>\n",
       "      <th>avg_wc_notes_day_84</th>\n",
       "      <th>avg_wc_terms_day_84</th>\n",
       "      <th>avg_wc_address_day_84</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systemid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4504870</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504872</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504874</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504876</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504878</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          avg_wc_description_day_84  avg_wc_notes_day_84  avg_wc_terms_day_84  \\\n",
       "systemid                                                                        \n",
       "4504870                         0.0                  0.0                  0.0   \n",
       "4504872                         1.0                  0.0                  0.0   \n",
       "4504874                         0.0                  0.0                  0.0   \n",
       "4504876                         0.0                  0.0                  0.0   \n",
       "4504878                         0.0                  0.0                  0.0   \n",
       "\n",
       "          avg_wc_address_day_84  \n",
       "systemid                         \n",
       "4504870                     0.0  \n",
       "4504872                     0.0  \n",
       "4504874                     0.0  \n",
       "4504876                     0.0  \n",
       "4504878                     0.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_count_84days_all_accounts_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.13 Invoice within 91 days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL for impoorting all invoices created within 91 days after signup_date\n",
    "sql_invoices_91days_all_accounts = '''WITH invoices_in_a_period AS (\n",
    "    SELECT systemid, signup_date\n",
    "    FROM report_systems rs\n",
    "    WHERE signup_date BETWEEN '2019-08-01' and '2019-10-31'\n",
    "), invoice_created_at AS (\n",
    "    SELECT\n",
    "           pic.systemid,\n",
    "           inv.invoiceid,\n",
    "           pic.signup_date,\n",
    "           inv.create_date,\n",
    "           inv.created_at,\n",
    "           inv.description,\n",
    "           inv.notes,\n",
    "           inv.terms,\n",
    "           inv.address,\n",
    "           DATEDIFF(days, pic.signup_date, inv.created_at) AS days_to_invoice_creation\n",
    "    FROM invoices_in_a_period AS pic\n",
    "    LEFT JOIN coalesced_live_shards.invoice_stable as inv USING (systemid)\n",
    "    WHERE ((days_to_invoice_creation BETWEEN 0 AND 91) OR days_to_invoice_creation IS NULL)\n",
    ")\n",
    "\n",
    "SELECT *\n",
    "FROM invoice_created_at;'''\n",
    "\n",
    "# Import as dataframe from redshift\n",
    "df_invoices_91days_all_accounts = pig.run_query(sql_invoices_91days_all_accounts, return_data=True)\n",
    "\n",
    "# Words count in invoice's description, notes, terms, address\n",
    "df_invoices_91days_all_accounts['avg_wc_description_day_91'] = df_invoices_91days_all_accounts.apply(lambda x: words_count(x['description']), axis=1)\n",
    "df_invoices_91days_all_accounts['avg_wc_notes_day_91'] = df_invoices_91days_all_accounts.apply(lambda x: words_count(x['notes']), axis=1)\n",
    "df_invoices_91days_all_accounts['avg_wc_terms_day_91'] = df_invoices_91days_all_accounts.apply(lambda x: words_count(x['terms']), axis=1)\n",
    "df_invoices_91days_all_accounts['avg_wc_address_day_91'] = df_invoices_91days_all_accounts.apply(lambda x: words_count(x['address']), axis=1)\n",
    "\n",
    "                                                                                                                   \n",
    "# Filters the text columns from the dataframe\n",
    "df_invoices_91days_all_accounts_fil = df_invoices_91days_all_accounts.filter(['systemid', 'invoiceid', \n",
    "                                                                            'signup_date', \n",
    "                                                                            'create_date', \n",
    "                                                                            'created_at',\n",
    "                                                                            'days_to_invoice_creation', \n",
    "                                                                            'avg_wc_description_day_91', \n",
    "                                                                            'avg_wc_notes_day_91', \n",
    "                                                                            'avg_wc_terms_day_91',\n",
    "                                                                            'avg_wc_address_day_91'])  \n",
    "                                                                                                                   \n",
    "# Summing (grouping) all invoices for a 'systemid'\n",
    "df_word_count_91days_all_accounts_total = df_invoices_91days_all_accounts_fil.groupby('systemid').mean()  \n",
    "\n",
    "# Final word count table\n",
    "df_word_count_91days_all_accounts_final = df_word_count_91days_all_accounts_total.filter(['systemid',\n",
    "                                                                            'avg_wc_description_day_91', \n",
    "                                                                            'avg_wc_notes_day_91', \n",
    "                                                                            'avg_wc_terms_day_91',\n",
    "                                                                            'avg_wc_address_day_91'])\n",
    "\n",
    "# Export as csv file\n",
    "df_word_count_91days_all_accounts_final.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/df_word_count_91days_new_accounts_final.tsv\", \n",
    "                                      sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_wc_description_day_91</th>\n",
       "      <th>avg_wc_notes_day_91</th>\n",
       "      <th>avg_wc_terms_day_91</th>\n",
       "      <th>avg_wc_address_day_91</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systemid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4504870</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504872</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504874</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504876</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504878</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          avg_wc_description_day_91  avg_wc_notes_day_91  avg_wc_terms_day_91  \\\n",
       "systemid                                                                        \n",
       "4504870                         0.0                  0.0                  0.0   \n",
       "4504872                         1.0                  0.0                  0.0   \n",
       "4504874                         0.0                  0.0                  0.0   \n",
       "4504876                         0.0                  0.0                  0.0   \n",
       "4504878                         0.0                  0.0                  0.0   \n",
       "\n",
       "          avg_wc_address_day_91  \n",
       "systemid                         \n",
       "4504870                     0.0  \n",
       "4504872                     0.0  \n",
       "4504874                     0.0  \n",
       "4504876                     0.0  \n",
       "4504878                     0.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_count_91days_all_accounts_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.14 Joining All Periodic Average Words Counts Features Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joininig day 7 and day 14 th dataframes\n",
    "df_avg_invoice_word_count = pd.merge(df_word_count_7days_all_accounts_final, df_word_count_14days_all_accounts_final,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# left join day 21 \n",
    "df_avg_invoice_word_count = pd.merge(df_avg_invoice_word_count, df_word_count_21days_all_accounts_final,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# left join day 28\n",
    "df_avg_invoice_word_count = pd.merge(df_avg_invoice_word_count, df_word_count_28days_all_accounts_final,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# left join day 35\n",
    "df_avg_invoice_word_count = pd.merge(df_avg_invoice_word_count, df_word_count_35days_all_accounts_final,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# left join day 42\n",
    "df_avg_invoice_word_count = pd.merge(df_avg_invoice_word_count, df_word_count_42days_all_accounts_final,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# left join day 49\n",
    "df_avg_invoice_word_count = pd.merge(df_avg_invoice_word_count, df_word_count_49days_all_accounts_final,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# left join day 56\n",
    "df_avg_invoice_word_count = pd.merge(df_avg_invoice_word_count, df_word_count_56days_all_accounts_final,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# left join day 63\n",
    "df_avg_invoice_word_count = pd.merge(df_avg_invoice_word_count, df_word_count_63days_all_accounts_final,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# left join day 70\n",
    "df_avg_invoice_word_count = pd.merge(df_avg_invoice_word_count, df_word_count_70days_all_accounts_final,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# left join day 77\n",
    "df_avg_invoice_word_count = pd.merge(df_avg_invoice_word_count, df_word_count_77days_all_accounts_final,\n",
    "                                     on='systemid', how='left')\n",
    "# left join day 84\n",
    "df_avg_invoice_word_count = pd.merge(df_avg_invoice_word_count, df_word_count_84days_all_accounts_final,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# left join day 91\n",
    "df_avg_invoice_word_count = pd.merge(df_avg_invoice_word_count, df_word_count_91days_all_accounts_final,\n",
    "                                     on='systemid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export as csv file\n",
    "df_avg_invoice_word_count.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/df_avg_invoice_word_count.tsv\", \n",
    "                                      sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_wc_description_day_7</th>\n",
       "      <th>avg_wc_notes_day_7</th>\n",
       "      <th>avg_wc_terms_day_7</th>\n",
       "      <th>avg_wc_address_day_7</th>\n",
       "      <th>avg_wc_description_day_14</th>\n",
       "      <th>avg_wc_notes_day_14</th>\n",
       "      <th>avg_wc_terms_day_14</th>\n",
       "      <th>avg_wc_address_day_14</th>\n",
       "      <th>avg_wc_description_day_21</th>\n",
       "      <th>avg_wc_notes_day_21</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_wc_terms_day_77</th>\n",
       "      <th>avg_wc_address_day_77</th>\n",
       "      <th>avg_wc_description_day_84</th>\n",
       "      <th>avg_wc_notes_day_84</th>\n",
       "      <th>avg_wc_terms_day_84</th>\n",
       "      <th>avg_wc_address_day_84</th>\n",
       "      <th>avg_wc_description_day_91</th>\n",
       "      <th>avg_wc_notes_day_91</th>\n",
       "      <th>avg_wc_terms_day_91</th>\n",
       "      <th>avg_wc_address_day_91</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systemid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4735844</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4735846</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4735848</th>\n",
       "      <td>1.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.038462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.038462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.038462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.038462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4735850</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4735852</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          avg_wc_description_day_7  avg_wc_notes_day_7  avg_wc_terms_day_7  \\\n",
       "systemid                                                                     \n",
       "4735844                   0.000000                 0.0                 0.0   \n",
       "4735846                   0.000000                 0.0                 0.0   \n",
       "4735848                   1.055556                 0.0                 0.0   \n",
       "4735850                   0.000000                 0.0                 0.0   \n",
       "4735852                   0.000000                 0.0                 0.0   \n",
       "\n",
       "          avg_wc_address_day_7  avg_wc_description_day_14  \\\n",
       "systemid                                                    \n",
       "4735844                    0.0                   0.000000   \n",
       "4735846                    0.0                   0.000000   \n",
       "4735848                    0.0                   1.038462   \n",
       "4735850                    0.0                   0.000000   \n",
       "4735852                    0.0                  13.000000   \n",
       "\n",
       "          avg_wc_notes_day_14  avg_wc_terms_day_14  avg_wc_address_day_14  \\\n",
       "systemid                                                                    \n",
       "4735844                   0.0                  0.0                    0.0   \n",
       "4735846                   0.0                  0.0                    0.0   \n",
       "4735848                   0.0                  0.0                    0.0   \n",
       "4735850                   0.0                  0.0                    0.0   \n",
       "4735852                  16.0                  0.0                    0.0   \n",
       "\n",
       "          avg_wc_description_day_21  avg_wc_notes_day_21  ...  \\\n",
       "systemid                                                  ...   \n",
       "4735844                    0.000000                  0.0  ...   \n",
       "4735846                    0.000000                  0.0  ...   \n",
       "4735848                    1.038462                  0.0  ...   \n",
       "4735850                    0.000000                  0.0  ...   \n",
       "4735852                   13.000000                 16.0  ...   \n",
       "\n",
       "          avg_wc_terms_day_77  avg_wc_address_day_77  \\\n",
       "systemid                                               \n",
       "4735844                   0.0                    0.0   \n",
       "4735846                   0.0                    0.0   \n",
       "4735848                   0.0                    0.0   \n",
       "4735850                   0.0                    0.0   \n",
       "4735852                   0.0                    0.0   \n",
       "\n",
       "          avg_wc_description_day_84  avg_wc_notes_day_84  avg_wc_terms_day_84  \\\n",
       "systemid                                                                        \n",
       "4735844                    0.000000                  0.0                  0.0   \n",
       "4735846                    0.000000                  0.0                  0.0   \n",
       "4735848                    1.038462                  0.0                  0.0   \n",
       "4735850                    0.000000                  0.0                  0.0   \n",
       "4735852                   13.000000                 16.0                  0.0   \n",
       "\n",
       "          avg_wc_address_day_84  avg_wc_description_day_91  \\\n",
       "systemid                                                     \n",
       "4735844                     0.0                   0.000000   \n",
       "4735846                     0.0                   0.000000   \n",
       "4735848                     0.0                   1.038462   \n",
       "4735850                     0.0                   0.000000   \n",
       "4735852                     0.0                  13.000000   \n",
       "\n",
       "          avg_wc_notes_day_91  avg_wc_terms_day_91  avg_wc_address_day_91  \n",
       "systemid                                                                   \n",
       "4735844                   0.0                  0.0                    0.0  \n",
       "4735846                   0.0                  0.0                    0.0  \n",
       "4735848                   0.0                  0.0                    0.0  \n",
       "4735850                   0.0                  0.0                    0.0  \n",
       "4735852                  16.0                  0.0                    0.0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking\n",
    "df_avg_invoice_word_count.tail()\n",
    "# df_avg_invoice_word_count.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Report Systems, Invoice & Client Counts Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "################# Import RSystems, Periodic Invoices & Client Counts Data ###############\n",
    "\n",
    "# SQL query \n",
    "sql_rs_invoices_clients_activities_all_accounts = '''WITH periodic_report_system_activities AS (\n",
    "    SELECT\n",
    "        systemid,\n",
    "        signup_date,\n",
    "        admin_email,\n",
    "        is_sales_managed,\n",
    "        is_freshbooks_account_active,\n",
    "        is_paying,\n",
    "        signup_ip_address\n",
    "    FROM report_systems rs\n",
    "    WHERE signup_date BETWEEN '2019-08-01' and '2019-10-31'\n",
    "), invoice_create_date AS (\n",
    "    SELECT\n",
    "           pic.systemid,\n",
    "           inv.invoiceid,\n",
    "           inv.create_date,\n",
    "           inv.created_at,\n",
    "           DATEDIFF(days, pic.signup_date, inv.created_at) AS days_to_invoice_creation\n",
    "    FROM periodic_report_system_activities AS pic\n",
    "    LEFT JOIN coalesced_live_shards.invoice_stable as inv USING (systemid)\n",
    "), invoice_grouping AS (\n",
    "    SELECT\n",
    "           systemid,\n",
    "           COUNT(invoiceid) as invoice_count,\n",
    "           SUM(CASE WHEN days_to_invoice_creation BETWEEN 0 AND 7 THEN 1 ELSE 0 END) AS invoice_count_day_7,\n",
    "           SUM(CASE WHEN days_to_invoice_creation BETWEEN 0 AND 14 THEN 1 ELSE 0 END) AS invoice_count_day_14,\n",
    "           SUM(CASE WHEN days_to_invoice_creation BETWEEN 0 AND 21 THEN 1 ELSE 0 END) AS invoice_count_day_21,\n",
    "           SUM(CASE WHEN days_to_invoice_creation BETWEEN 0 AND 28 THEN 1 ELSE 0 END) AS invoice_count_day_28,\n",
    "           SUM(CASE WHEN days_to_invoice_creation BETWEEN 0 AND 35 THEN 1 ELSE 0 END) AS invoice_count_day_35,\n",
    "           SUM(CASE WHEN days_to_invoice_creation BETWEEN 0 AND 42 THEN 1 ELSE 0 END) AS invoice_count_day_42,\n",
    "           SUM(CASE WHEN days_to_invoice_creation BETWEEN 0 AND 49 THEN 1 ELSE 0 END) AS invoice_count_day_49,\n",
    "           SUM(CASE WHEN days_to_invoice_creation BETWEEN 0 AND 56 THEN 1 ELSE 0 END) AS invoice_count_day_56,\n",
    "           SUM(CASE WHEN days_to_invoice_creation BETWEEN 0 AND 63 THEN 1 ELSE 0 END) AS invoice_count_day_63,\n",
    "           SUM(CASE WHEN days_to_invoice_creation BETWEEN 0 AND 70 THEN 1 ELSE 0 END) AS invoice_count_day_70,\n",
    "           SUM(CASE WHEN days_to_invoice_creation BETWEEN 0 AND 77 THEN 1 ELSE 0 END) AS invoice_count_day_77,\n",
    "           SUM(CASE WHEN days_to_invoice_creation BETWEEN 0 AND 84 THEN 1 ELSE 0 END) AS invoice_count_day_84,\n",
    "           SUM(CASE WHEN days_to_invoice_creation BETWEEN 0 AND 91 THEN 1 ELSE 0 END) AS invoice_count_day_91\n",
    "    FROM invoice_create_date\n",
    "    GROUP BY systemid\n",
    "), client_crate_date AS (\n",
    "     SELECT\n",
    "            pic.systemid,\n",
    "            usr.userid,\n",
    "            usr.signup_date,\n",
    "            DATEDIFF(days, pic.signup_date, usr.signup_date) AS days_to_client_creation\n",
    "    FROM periodic_report_system_activities  AS pic\n",
    "    LEFT JOIN coalesced_live_shards.\"user\" as usr USING (systemid)\n",
    "), client_grouping AS (\n",
    "    SELECT\n",
    "           systemid,\n",
    "           count(userid) AS client_count,\n",
    "           SUM(CASE WHEN days_to_client_creation BETWEEN 0 AND 7 THEN 1 ELSE 0 END) AS client_count_day_7,\n",
    "           SUM(CASE WHEN days_to_client_creation BETWEEN 0 AND 14 THEN 1 ELSE 0 END) AS client_count_day_14,\n",
    "           SUM(CASE WHEN days_to_client_creation BETWEEN 0 AND 21 THEN 1 ELSE 0 END) AS client_count_day_21,\n",
    "           SUM(CASE WHEN days_to_client_creation BETWEEN 0 AND 28 THEN 1 ELSE 0 END) AS client_count_day_28,\n",
    "           SUM(CASE WHEN days_to_client_creation BETWEEN 0 AND 35 THEN 1 ELSE 0 END) AS client_count_day_35,\n",
    "           SUM(CASE WHEN days_to_client_creation BETWEEN 0 AND 42 THEN 1 ELSE 0 END) AS client_count_day_42,\n",
    "           SUM(CASE WHEN days_to_client_creation BETWEEN 0 AND 49 THEN 1 ELSE 0 END) AS client_count_day_49,\n",
    "           SUM(CASE WHEN days_to_client_creation BETWEEN 0 AND 56 THEN 1 ELSE 0 END) AS client_count_day_56,\n",
    "           SUM(CASE WHEN days_to_client_creation BETWEEN 0 AND 63 THEN 1 ELSE 0 END) AS client_count_day_63,\n",
    "           SUM(CASE WHEN days_to_client_creation BETWEEN 0 AND 70 THEN 1 ELSE 0 END) AS client_count_day_70,\n",
    "           SUM(CASE WHEN days_to_client_creation BETWEEN 0 AND 77 THEN 1 ELSE 0 END) AS client_count_day_77,\n",
    "           SUM(CASE WHEN days_to_client_creation BETWEEN 0 AND 84 THEN 1 ELSE 0 END) AS client_count_day_84,\n",
    "           SUM(CASE WHEN days_to_client_creation BETWEEN 0 AND 91 THEN 1 ELSE 0 END) AS client_count_day_91\n",
    "    FROM  client_crate_date\n",
    "    GROUP BY systemid\n",
    ")\n",
    "\n",
    "SELECT\n",
    "       systemid,\n",
    "       signup_date,\n",
    "       admin_email,\n",
    "       is_sales_managed,\n",
    "       is_freshbooks_account_active,\n",
    "       is_paying,\n",
    "       signup_ip_address,\n",
    "       inv_gr.invoice_count,\n",
    "       inv_gr.invoice_count_day_7,\n",
    "       inv_gr.invoice_count_day_14,\n",
    "       inv_gr.invoice_count_day_21,\n",
    "       inv_gr.invoice_count_day_28,\n",
    "       inv_gr.invoice_count_day_35,\n",
    "       inv_gr.invoice_count_day_42,\n",
    "       inv_gr.invoice_count_day_49,\n",
    "       inv_gr.invoice_count_day_56,\n",
    "       inv_gr.invoice_count_day_63,\n",
    "       inv_gr.invoice_count_day_70,\n",
    "       inv_gr.invoice_count_day_77,\n",
    "       inv_gr.invoice_count_day_84,\n",
    "       inv_gr.invoice_count_day_91,\n",
    "       cl_gr.client_count,\n",
    "       cl_gr.client_count_day_7,\n",
    "       cl_gr.client_count_day_14,\n",
    "       cl_gr.client_count_day_21,\n",
    "       cl_gr.client_count_day_28,\n",
    "       cl_gr.client_count_day_35,\n",
    "       cl_gr.client_count_day_42,\n",
    "       cl_gr.client_count_day_49,\n",
    "       cl_gr.client_count_day_56,\n",
    "       cl_gr.client_count_day_63,\n",
    "       cl_gr.client_count_day_70,\n",
    "       cl_gr.client_count_day_77,\n",
    "       cl_gr.client_count_day_84,\n",
    "       cl_gr.client_count_day_91\n",
    "FROM periodic_report_system_activities\n",
    "LEFT JOIN invoice_grouping as inv_gr USING (systemid)\n",
    "LEFT JOIN client_grouping AS cl_gr USING (systemid);\n",
    "'''\n",
    "\n",
    "# Import as dataframe from redshift\n",
    "df_rs_invoices_clients_activities_all_accounts = pig.run_query(sql_rs_invoices_clients_activities_all_accounts, return_data=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export as csv file\n",
    "df_rs_invoices_clients_activities_all_accounts.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/df_rs_invoices_clients_activities_new_accounts.tsv\", \n",
    "                                      sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>systemid</th>\n",
       "      <th>signup_date</th>\n",
       "      <th>admin_email</th>\n",
       "      <th>is_sales_managed</th>\n",
       "      <th>is_freshbooks_account_active</th>\n",
       "      <th>is_paying</th>\n",
       "      <th>signup_ip_address</th>\n",
       "      <th>invoice_count</th>\n",
       "      <th>invoice_count_day_7</th>\n",
       "      <th>invoice_count_day_14</th>\n",
       "      <th>...</th>\n",
       "      <th>client_count_day_28</th>\n",
       "      <th>client_count_day_35</th>\n",
       "      <th>client_count_day_42</th>\n",
       "      <th>client_count_day_49</th>\n",
       "      <th>client_count_day_56</th>\n",
       "      <th>client_count_day_63</th>\n",
       "      <th>client_count_day_70</th>\n",
       "      <th>client_count_day_77</th>\n",
       "      <th>client_count_day_84</th>\n",
       "      <th>client_count_day_91</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114965</th>\n",
       "      <td>4666258</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>bill@kleanroute.com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>107.77.207.58</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114966</th>\n",
       "      <td>4695854</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>soraiya.n@gmail.com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>176.249.99.174</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114967</th>\n",
       "      <td>4698906</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>rameylr@gmail.com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>108.202.9.98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114968</th>\n",
       "      <td>4710470</td>\n",
       "      <td>2019-10-21</td>\n",
       "      <td>sapna@littlestepsasia.com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>58.177.129.86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114969</th>\n",
       "      <td>4718224</td>\n",
       "      <td>2019-10-24</td>\n",
       "      <td>menk8@outlook.com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>118.149.144.116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        systemid signup_date                admin_email  is_sales_managed  \\\n",
       "114965   4666258  2019-10-02        bill@kleanroute.com                 0   \n",
       "114966   4695854  2019-10-15        soraiya.n@gmail.com                 0   \n",
       "114967   4698906  2019-10-16          rameylr@gmail.com                 0   \n",
       "114968   4710470  2019-10-21  sapna@littlestepsasia.com                 0   \n",
       "114969   4718224  2019-10-24          menk8@outlook.com                 0   \n",
       "\n",
       "        is_freshbooks_account_active  is_paying signup_ip_address  \\\n",
       "114965                             1          0     107.77.207.58   \n",
       "114966                             1          0    176.249.99.174   \n",
       "114967                             1          0      108.202.9.98   \n",
       "114968                             1          0     58.177.129.86   \n",
       "114969                             1          0   118.149.144.116   \n",
       "\n",
       "        invoice_count  invoice_count_day_7  invoice_count_day_14  ...  \\\n",
       "114965              2                    1                     1  ...   \n",
       "114966              1                    1                     1  ...   \n",
       "114967              1                    1                     1  ...   \n",
       "114968              0                    0                     0  ...   \n",
       "114969              0                    0                     0  ...   \n",
       "\n",
       "        client_count_day_28  client_count_day_35  client_count_day_42  \\\n",
       "114965                    3                    3                    3   \n",
       "114966                    2                    2                    2   \n",
       "114967                    2                    2                    2   \n",
       "114968                    1                    1                    1   \n",
       "114969                    1                    1                    1   \n",
       "\n",
       "        client_count_day_49  client_count_day_56  client_count_day_63  \\\n",
       "114965                    3                    3                    3   \n",
       "114966                    2                    2                    2   \n",
       "114967                    2                    2                    2   \n",
       "114968                    1                    1                    1   \n",
       "114969                    1                    1                    1   \n",
       "\n",
       "        client_count_day_70  client_count_day_77  client_count_day_84  \\\n",
       "114965                    3                    3                    3   \n",
       "114966                    2                    2                    2   \n",
       "114967                    2                    2                    2   \n",
       "114968                    1                    1                    1   \n",
       "114969                    1                    1                    1   \n",
       "\n",
       "        client_count_day_91  \n",
       "114965                    3  \n",
       "114966                    2  \n",
       "114967                    2  \n",
       "114968                    1  \n",
       "114969                    1  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking \n",
    "df_rs_invoices_clients_activities_all_accounts.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114970, 35)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rs_invoices_clients_activities_all_accounts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Join Avg Word counts and Invoice & Client Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Join Avg Word Counts and Invoice & Client Counts ########################\n",
    "\n",
    "# left join invoices' average periodic word counts (description, notes, terms, address) with the invices & client counts\n",
    "df_periodic_invoice_all_counts = pd.merge(df_avg_invoice_word_count, df_rs_invoices_clients_activities_all_accounts,\n",
    "                                     on='systemid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>systemid</th>\n",
       "      <th>avg_wc_description_day_7</th>\n",
       "      <th>avg_wc_notes_day_7</th>\n",
       "      <th>avg_wc_terms_day_7</th>\n",
       "      <th>avg_wc_address_day_7</th>\n",
       "      <th>avg_wc_description_day_14</th>\n",
       "      <th>avg_wc_notes_day_14</th>\n",
       "      <th>avg_wc_terms_day_14</th>\n",
       "      <th>avg_wc_address_day_14</th>\n",
       "      <th>avg_wc_description_day_21</th>\n",
       "      <th>...</th>\n",
       "      <th>client_count_day_28</th>\n",
       "      <th>client_count_day_35</th>\n",
       "      <th>client_count_day_42</th>\n",
       "      <th>client_count_day_49</th>\n",
       "      <th>client_count_day_56</th>\n",
       "      <th>client_count_day_63</th>\n",
       "      <th>client_count_day_70</th>\n",
       "      <th>client_count_day_77</th>\n",
       "      <th>client_count_day_84</th>\n",
       "      <th>client_count_day_91</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112134</th>\n",
       "      <td>4735844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112135</th>\n",
       "      <td>4735846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112136</th>\n",
       "      <td>4735848</td>\n",
       "      <td>1.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.038462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.038462</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112137</th>\n",
       "      <td>4735850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112138</th>\n",
       "      <td>4735852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        systemid  avg_wc_description_day_7  avg_wc_notes_day_7  \\\n",
       "112134   4735844                  0.000000                 0.0   \n",
       "112135   4735846                  0.000000                 0.0   \n",
       "112136   4735848                  1.055556                 0.0   \n",
       "112137   4735850                  0.000000                 0.0   \n",
       "112138   4735852                  0.000000                 0.0   \n",
       "\n",
       "        avg_wc_terms_day_7  avg_wc_address_day_7  avg_wc_description_day_14  \\\n",
       "112134                 0.0                   0.0                   0.000000   \n",
       "112135                 0.0                   0.0                   0.000000   \n",
       "112136                 0.0                   0.0                   1.038462   \n",
       "112137                 0.0                   0.0                   0.000000   \n",
       "112138                 0.0                   0.0                  13.000000   \n",
       "\n",
       "        avg_wc_notes_day_14  avg_wc_terms_day_14  avg_wc_address_day_14  \\\n",
       "112134                  0.0                  0.0                    0.0   \n",
       "112135                  0.0                  0.0                    0.0   \n",
       "112136                  0.0                  0.0                    0.0   \n",
       "112137                  0.0                  0.0                    0.0   \n",
       "112138                 16.0                  0.0                    0.0   \n",
       "\n",
       "        avg_wc_description_day_21  ...  client_count_day_28  \\\n",
       "112134                   0.000000  ...                    1   \n",
       "112135                   0.000000  ...                    1   \n",
       "112136                   1.038462  ...                   25   \n",
       "112137                   0.000000  ...                    1   \n",
       "112138                  13.000000  ...                    3   \n",
       "\n",
       "        client_count_day_35  client_count_day_42  client_count_day_49  \\\n",
       "112134                    1                    1                    1   \n",
       "112135                    1                    1                    1   \n",
       "112136                   25                   25                   25   \n",
       "112137                    1                    1                    1   \n",
       "112138                    3                    3                    3   \n",
       "\n",
       "        client_count_day_56  client_count_day_63  client_count_day_70  \\\n",
       "112134                    1                    1                    1   \n",
       "112135                    1                    1                    1   \n",
       "112136                   25                   25                   25   \n",
       "112137                    1                    1                    1   \n",
       "112138                    3                    3                    3   \n",
       "\n",
       "        client_count_day_77  client_count_day_84  client_count_day_91  \n",
       "112134                    1                    1                    1  \n",
       "112135                    1                    1                    1  \n",
       "112136                   25                   25                   25  \n",
       "112137                    1                    1                    1  \n",
       "112138                    3                    3                    3  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chiecking\n",
    "df_periodic_invoice_all_counts.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112139, 87)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_periodic_invoice_all_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export as csv file\n",
    "df_periodic_invoice_all_counts.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/periodic_invoice_all_counts_new_accounts.csv\", \n",
    "                                      sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV file\n",
    "# df_periodic_invoice_all_counts = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/periodic_invoice_all_counts_new_accounts.csv\", \n",
    "#                                       sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112139, 87)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking\n",
    "df_periodic_invoice_all_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['systemid',\n",
       " 'avg_wc_description_day_7',\n",
       " 'avg_wc_notes_day_7',\n",
       " 'avg_wc_terms_day_7',\n",
       " 'avg_wc_address_day_7',\n",
       " 'avg_wc_description_day_14',\n",
       " 'avg_wc_notes_day_14',\n",
       " 'avg_wc_terms_day_14',\n",
       " 'avg_wc_address_day_14',\n",
       " 'avg_wc_description_day_21',\n",
       " 'avg_wc_notes_day_21',\n",
       " 'avg_wc_terms_day_21',\n",
       " 'avg_wc_address_day_21',\n",
       " 'avg_wc_description_day_28',\n",
       " 'avg_wc_notes_day_28',\n",
       " 'avg_wc_terms_day_28',\n",
       " 'avg_wc_address_day_28',\n",
       " 'avg_wc_description_day_35',\n",
       " 'avg_wc_notes_day_35',\n",
       " 'avg_wc_terms_day_35',\n",
       " 'avg_wc_address_day_35',\n",
       " 'avg_wc_description_day_42',\n",
       " 'avg_wc_notes_day_42',\n",
       " 'avg_wc_terms_day_42',\n",
       " 'avg_wc_address_day_42',\n",
       " 'avg_wc_description_day_49',\n",
       " 'avg_wc_notes_day_49',\n",
       " 'avg_wc_terms_day_49',\n",
       " 'avg_wc_address_day_49',\n",
       " 'avg_wc_description_day_56',\n",
       " 'avg_wc_notes_day_56',\n",
       " 'avg_wc_terms_day_56',\n",
       " 'avg_wc_address_day_56',\n",
       " 'avg_wc_description_day_63',\n",
       " 'avg_wc_notes_day_63',\n",
       " 'avg_wc_terms_day_63',\n",
       " 'avg_wc_address_day_63',\n",
       " 'avg_wc_description_day_70',\n",
       " 'avg_wc_notes_day_70',\n",
       " 'avg_wc_terms_day_70',\n",
       " 'avg_wc_address_day_70',\n",
       " 'avg_wc_description_day_77',\n",
       " 'avg_wc_notes_day_77',\n",
       " 'avg_wc_terms_day_77',\n",
       " 'avg_wc_address_day_77',\n",
       " 'avg_wc_description_day_84',\n",
       " 'avg_wc_notes_day_84',\n",
       " 'avg_wc_terms_day_84',\n",
       " 'avg_wc_address_day_84',\n",
       " 'avg_wc_description_day_91',\n",
       " 'avg_wc_notes_day_91',\n",
       " 'avg_wc_terms_day_91',\n",
       " 'avg_wc_address_day_91',\n",
       " 'signup_date',\n",
       " 'admin_email',\n",
       " 'is_sales_managed',\n",
       " 'is_freshbooks_account_active',\n",
       " 'is_paying',\n",
       " 'signup_ip_address',\n",
       " 'invoice_count',\n",
       " 'invoice_count_day_7',\n",
       " 'invoice_count_day_14',\n",
       " 'invoice_count_day_21',\n",
       " 'invoice_count_day_28',\n",
       " 'invoice_count_day_35',\n",
       " 'invoice_count_day_42',\n",
       " 'invoice_count_day_49',\n",
       " 'invoice_count_day_56',\n",
       " 'invoice_count_day_63',\n",
       " 'invoice_count_day_70',\n",
       " 'invoice_count_day_77',\n",
       " 'invoice_count_day_84',\n",
       " 'invoice_count_day_91',\n",
       " 'client_count',\n",
       " 'client_count_day_7',\n",
       " 'client_count_day_14',\n",
       " 'client_count_day_21',\n",
       " 'client_count_day_28',\n",
       " 'client_count_day_35',\n",
       " 'client_count_day_42',\n",
       " 'client_count_day_49',\n",
       " 'client_count_day_56',\n",
       " 'client_count_day_63',\n",
       " 'client_count_day_70',\n",
       " 'client_count_day_77',\n",
       " 'client_count_day_84',\n",
       " 'client_count_day_91']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_periodic_invoice_all_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Import and Exract Features from Events Data\n",
    "## 4.1 Event data collection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### Event Features Extraction ################################\n",
    "\n",
    "#SQL for events \n",
    "sql_events = '''WITH selected_accounts_events AS (\n",
    "    SELECT systemid,\n",
    "           signup_date,\n",
    "           signup_datetime\n",
    "    FROM report_systems\n",
    "    WHERE signup_date BETWEEN '2019-08-01' and '2019-10-31'\n",
    "), events_activities AS (\n",
    "    SELECT sae.systemid,\n",
    "           signup_date,\n",
    "           dd.date,\n",
    "           datediff(days, signup_date, dd.date) as days_to_event,\n",
    "           lower(e.event) as event,\n",
    "           ec.count\n",
    "    FROM selected_accounts_events AS sae\n",
    "    LEFT JOIN event_counts AS ec USING (systemid)\n",
    "    LEFT JOIN d_date AS dd USING (date_key)\n",
    "    LEFT JOIN d_event e on ec.event_key = e.event_key\n",
    "), event_groupings AS (\n",
    "    SELECT distinct  ea.systemid,\n",
    "                    ea.signup_date,\n",
    "                    ea.date,\n",
    "                    ea.event,\n",
    "                    ea.count,\n",
    "                    (CASE WHEN days_to_event BETWEEN 0 AND 7 THEN ea.count END) AS day_7_event,\n",
    "                    (CASE WHEN days_to_event BETWEEN 0 AND 14 THEN ea.count END) AS day_14_event,\n",
    "                    (CASE WHEN days_to_event BETWEEN 0 AND 21 THEN ea.count END) AS day_21_event,\n",
    "                    (CASE WHEN days_to_event BETWEEN 0 AND 28 THEN ea.count END) AS day_28_event,\n",
    "                    (CASE WHEN days_to_event BETWEEN 0 AND 35 THEN ea.count END) AS day_35_event,\n",
    "                    (CASE WHEN days_to_event BETWEEN 0 AND 42 THEN ea.count END) AS day_42_event,\n",
    "                    (CASE WHEN days_to_event BETWEEN 0 AND 49 THEN ea.count END) AS day_49_event,\n",
    "                    (CASE WHEN days_to_event BETWEEN 0 AND 56 THEN ea.count END) AS day_56_event,\n",
    "                    (CASE WHEN days_to_event BETWEEN 0 AND 63 THEN ea.count END) AS day_63_event,\n",
    "                    (CASE WHEN days_to_event BETWEEN 0 AND 70 THEN ea.count END) AS day_70_event,\n",
    "                    (CASE WHEN days_to_event BETWEEN 0 AND 77 THEN ea.count END) AS day_77_event,\n",
    "                    (CASE WHEN days_to_event BETWEEN 0 AND 84 THEN ea.count END) AS day_84_event,\n",
    "                    (CASE WHEN days_to_event BETWEEN 0 AND 91 THEN ea.count END) AS day_91_event\n",
    "    FROM events_activities AS ea\n",
    ")\n",
    "SELECT systemid,\n",
    "       signup_date,\n",
    "       date,\n",
    "       event,\n",
    "       count,\n",
    "       sum(day_7_event) AS event_count_day_7,\n",
    "       sum(day_14_event) AS event_count_day_14,\n",
    "       sum(day_21_event) AS event_count_day_21,\n",
    "       sum(day_28_event) AS event_count_day_28,\n",
    "       sum(day_35_event) AS event_count_day_35,\n",
    "       sum(day_42_event) AS event_count_day_42,\n",
    "       sum(day_49_event) AS event_count_day_49,\n",
    "       sum(day_56_event) AS event_count_day_56,\n",
    "       sum(day_63_event) AS event_count_day_63,\n",
    "       sum(day_70_event) AS event_count_day_70,\n",
    "       sum(day_77_event) AS event_count_day_77,\n",
    "       sum(day_84_event) AS event_count_day_84,\n",
    "       sum(day_91_event) AS event_count_day_91\n",
    "From event_groupings\n",
    "GROUP BY systemid, signup_date, date, event, count\n",
    "ORDER BY systemid, count DESC;'''\n",
    "\n",
    "# Import as dataframe from redshift\n",
    "# df_events_all_accounts = pd.read_sql_query(sql_events, connect_to_db)\n",
    "df_events_all_accounts = pig.run_query(sql_events, return_data=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>systemid</th>\n",
       "      <th>signup_date</th>\n",
       "      <th>date</th>\n",
       "      <th>event</th>\n",
       "      <th>count</th>\n",
       "      <th>event_count_day_7</th>\n",
       "      <th>event_count_day_14</th>\n",
       "      <th>event_count_day_21</th>\n",
       "      <th>event_count_day_28</th>\n",
       "      <th>event_count_day_35</th>\n",
       "      <th>event_count_day_42</th>\n",
       "      <th>event_count_day_49</th>\n",
       "      <th>event_count_day_56</th>\n",
       "      <th>event_count_day_63</th>\n",
       "      <th>event_count_day_70</th>\n",
       "      <th>event_count_day_77</th>\n",
       "      <th>event_count_day_84</th>\n",
       "      <th>event_count_day_91</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4504870</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>subscription details changed</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4504870</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>update identity</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4504870</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>aria supplemental plan replaced</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4504870</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>2019-08-07</td>\n",
       "      <td>aria subscription suspended</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4504870</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>aria supplemental plan upgraded</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   systemid signup_date        date                            event  count  \\\n",
       "0   4504870  2019-08-01  2019-08-01     subscription details changed   22.0   \n",
       "1   4504870  2019-08-01  2019-08-01                  update identity    4.0   \n",
       "2   4504870  2019-08-01  2019-08-01  aria supplemental plan replaced    3.0   \n",
       "3   4504870  2019-08-01  2019-08-07      aria subscription suspended    1.0   \n",
       "4   4504870  2019-08-01  2019-08-01  aria supplemental plan upgraded    1.0   \n",
       "\n",
       "   event_count_day_7  event_count_day_14  event_count_day_21  \\\n",
       "0               22.0                22.0                22.0   \n",
       "1                4.0                 4.0                 4.0   \n",
       "2                3.0                 3.0                 3.0   \n",
       "3                1.0                 1.0                 1.0   \n",
       "4                1.0                 1.0                 1.0   \n",
       "\n",
       "   event_count_day_28  event_count_day_35  event_count_day_42  \\\n",
       "0                22.0                22.0                22.0   \n",
       "1                 4.0                 4.0                 4.0   \n",
       "2                 3.0                 3.0                 3.0   \n",
       "3                 1.0                 1.0                 1.0   \n",
       "4                 1.0                 1.0                 1.0   \n",
       "\n",
       "   event_count_day_49  event_count_day_56  event_count_day_63  \\\n",
       "0                22.0                22.0                22.0   \n",
       "1                 4.0                 4.0                 4.0   \n",
       "2                 3.0                 3.0                 3.0   \n",
       "3                 1.0                 1.0                 1.0   \n",
       "4                 1.0                 1.0                 1.0   \n",
       "\n",
       "   event_count_day_70  event_count_day_77  event_count_day_84  \\\n",
       "0                22.0                22.0                22.0   \n",
       "1                 4.0                 4.0                 4.0   \n",
       "2                 3.0                 3.0                 3.0   \n",
       "3                 1.0                 1.0                 1.0   \n",
       "4                 1.0                 1.0                 1.0   \n",
       "\n",
       "   event_count_day_91  \n",
       "0                22.0  \n",
       "1                 4.0  \n",
       "2                 3.0  \n",
       "3                 1.0  \n",
       "4                 1.0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking\n",
    "df_events_all_accounts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4068118, 18)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_events_all_accounts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Removing whitespce from the event strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing row if there is 'None' the event cell\n",
    "df_events_all_accounts = df_events_all_accounts[~df_events_all_accounts.astype(str).eq('None').any(1)]\n",
    "\n",
    "# Replace the 'NaN' cell by zero\n",
    "df_events_all_accounts.fillna(0, inplace=True)\n",
    "\n",
    "# Using lambda function to remove the white space in the event string name\n",
    "df_events_all_accounts['event_name'] = df_events_all_accounts.apply(lambda x: x['event'].replace(' ', ''), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4068054, 19)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking\n",
    "df_events_all_accounts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>systemid</th>\n",
       "      <th>signup_date</th>\n",
       "      <th>date</th>\n",
       "      <th>event</th>\n",
       "      <th>count</th>\n",
       "      <th>event_count_day_7</th>\n",
       "      <th>event_count_day_14</th>\n",
       "      <th>event_count_day_21</th>\n",
       "      <th>event_count_day_28</th>\n",
       "      <th>event_count_day_35</th>\n",
       "      <th>event_count_day_42</th>\n",
       "      <th>event_count_day_49</th>\n",
       "      <th>event_count_day_56</th>\n",
       "      <th>event_count_day_63</th>\n",
       "      <th>event_count_day_70</th>\n",
       "      <th>event_count_day_77</th>\n",
       "      <th>event_count_day_84</th>\n",
       "      <th>event_count_day_91</th>\n",
       "      <th>event_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4504870</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>subscription details changed</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>subscriptiondetailschanged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4504870</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>update identity</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>updateidentity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4504870</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>aria supplemental plan replaced</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ariasupplementalplanreplaced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4504870</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>2019-08-07</td>\n",
       "      <td>aria subscription suspended</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ariasubscriptionsuspended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4504870</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>aria supplemental plan upgraded</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ariasupplementalplanupgraded</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   systemid signup_date        date                            event  count  \\\n",
       "0   4504870  2019-08-01  2019-08-01     subscription details changed   22.0   \n",
       "1   4504870  2019-08-01  2019-08-01                  update identity    4.0   \n",
       "2   4504870  2019-08-01  2019-08-01  aria supplemental plan replaced    3.0   \n",
       "3   4504870  2019-08-01  2019-08-07      aria subscription suspended    1.0   \n",
       "4   4504870  2019-08-01  2019-08-01  aria supplemental plan upgraded    1.0   \n",
       "\n",
       "   event_count_day_7  event_count_day_14  event_count_day_21  \\\n",
       "0               22.0                22.0                22.0   \n",
       "1                4.0                 4.0                 4.0   \n",
       "2                3.0                 3.0                 3.0   \n",
       "3                1.0                 1.0                 1.0   \n",
       "4                1.0                 1.0                 1.0   \n",
       "\n",
       "   event_count_day_28  event_count_day_35  event_count_day_42  \\\n",
       "0                22.0                22.0                22.0   \n",
       "1                 4.0                 4.0                 4.0   \n",
       "2                 3.0                 3.0                 3.0   \n",
       "3                 1.0                 1.0                 1.0   \n",
       "4                 1.0                 1.0                 1.0   \n",
       "\n",
       "   event_count_day_49  event_count_day_56  event_count_day_63  \\\n",
       "0                22.0                22.0                22.0   \n",
       "1                 4.0                 4.0                 4.0   \n",
       "2                 3.0                 3.0                 3.0   \n",
       "3                 1.0                 1.0                 1.0   \n",
       "4                 1.0                 1.0                 1.0   \n",
       "\n",
       "   event_count_day_70  event_count_day_77  event_count_day_84  \\\n",
       "0                22.0                22.0                22.0   \n",
       "1                 4.0                 4.0                 4.0   \n",
       "2                 3.0                 3.0                 3.0   \n",
       "3                 1.0                 1.0                 1.0   \n",
       "4                 1.0                 1.0                 1.0   \n",
       "\n",
       "   event_count_day_91                    event_name  \n",
       "0                22.0    subscriptiondetailschanged  \n",
       "1                 4.0                updateidentity  \n",
       "2                 3.0  ariasupplementalplanreplaced  \n",
       "3                 1.0     ariasubscriptionsuspended  \n",
       "4                 1.0  ariasupplementalplanupgraded  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_events_all_accounts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Final Features Extraction: Day 7\n",
    "\n",
    "## 5.1 Filter Only Events for Day 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## Final Features Extraction: Day 7 ##############################\n",
    "\n",
    "# Filtered the events columns for day 7 period\n",
    "df_events_all_accounts_day_7 = df_events_all_accounts[['systemid', 'event_count_day_7', 'event_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>systemid</th>\n",
       "      <th>event_count_day_7</th>\n",
       "      <th>event_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4068113</th>\n",
       "      <td>4735852</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ariatrialsubscriptioncreated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4068114</th>\n",
       "      <td>4735852</td>\n",
       "      <td>1.0</td>\n",
       "      <td>refreshtokenused</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4068115</th>\n",
       "      <td>4735852</td>\n",
       "      <td>1.0</td>\n",
       "      <td>createfirstinvoice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4068116</th>\n",
       "      <td>4735852</td>\n",
       "      <td>1.0</td>\n",
       "      <td>createartifactcomment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4068117</th>\n",
       "      <td>4735852</td>\n",
       "      <td>1.0</td>\n",
       "      <td>teamsizeset</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         systemid  event_count_day_7                    event_name\n",
       "4068113   4735852                1.0  ariatrialsubscriptioncreated\n",
       "4068114   4735852                1.0              refreshtokenused\n",
       "4068115   4735852                1.0            createfirstinvoice\n",
       "4068116   4735852                1.0         createartifactcomment\n",
       "4068117   4735852                1.0                   teamsizeset"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_events_all_accounts_day_7.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4068054, 3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_events_all_accounts_day_7.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Pivote the Day 7 Events (Each Unique Event Become a Column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pivote the Day 7 Events (Each Unique Event Become a Column)###\n",
    "# Pivot table based on the unique column value in 'event_name'\n",
    "df_events_all_accounts_day_7 = df_events_all_accounts_day_7.pivot_table(values='event_count_day_7', columns='event_name', index='systemid', aggfunc=np.sum,  fill_value=0)\n",
    "\n",
    "# Drop the old column name\n",
    "df_events_all_accounts_day_7.columns.name = None\n",
    "\n",
    "# Reset the index\n",
    "df_events_all_accounts_day_7 = df_events_all_accounts_day_7.reset_index()\n",
    "\n",
    "# Replace 'NaN' with zero\n",
    "df_events_all_accounts_day_7.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>systemid</th>\n",
       "      <th>acceptestimate</th>\n",
       "      <th>accesstokencreated</th>\n",
       "      <th>activateclient</th>\n",
       "      <th>activatecontractor</th>\n",
       "      <th>activateestimate</th>\n",
       "      <th>activateexpense</th>\n",
       "      <th>activateinvoice</th>\n",
       "      <th>activateitem</th>\n",
       "      <th>activateotherincome</th>\n",
       "      <th>...</th>\n",
       "      <th>upgradeform-submitted</th>\n",
       "      <th>uploadexpensereceipt</th>\n",
       "      <th>uploadhi-reslogo</th>\n",
       "      <th>verifymigration</th>\n",
       "      <th>viewedcreupgradepage</th>\n",
       "      <th>viewestimate</th>\n",
       "      <th>viewinvoice</th>\n",
       "      <th>welcomeaccount</th>\n",
       "      <th>zendesksupporte-mail</th>\n",
       "      <th>zero-amountinvoicefromrecurringprofile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114901</th>\n",
       "      <td>4735844</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114902</th>\n",
       "      <td>4735846</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114903</th>\n",
       "      <td>4735848</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114904</th>\n",
       "      <td>4735850</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114905</th>\n",
       "      <td>4735852</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 393 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        systemid  acceptestimate  accesstokencreated  activateclient  \\\n",
       "114901   4735844               0                   0               0   \n",
       "114902   4735846               0                   1               0   \n",
       "114903   4735848               0                   7               0   \n",
       "114904   4735850               0                   0               0   \n",
       "114905   4735852               0                   0               0   \n",
       "\n",
       "        activatecontractor  activateestimate  activateexpense  \\\n",
       "114901                   0                 0                0   \n",
       "114902                   0                 0                0   \n",
       "114903                   0                 0                0   \n",
       "114904                   0                 0                0   \n",
       "114905                   0                 0                0   \n",
       "\n",
       "        activateinvoice  activateitem  activateotherincome  ...  \\\n",
       "114901                0             0                    0  ...   \n",
       "114902                0             0                    0  ...   \n",
       "114903                0             0                    0  ...   \n",
       "114904                0             0                    0  ...   \n",
       "114905                0             0                    0  ...   \n",
       "\n",
       "        upgradeform-submitted  uploadexpensereceipt  uploadhi-reslogo  \\\n",
       "114901                      0                     0                 0   \n",
       "114902                      0                     0                 0   \n",
       "114903                      0                     0                 0   \n",
       "114904                      0                     0                 0   \n",
       "114905                      0                     0                 0   \n",
       "\n",
       "        verifymigration  viewedcreupgradepage  viewestimate  viewinvoice  \\\n",
       "114901                0                     0             0            0   \n",
       "114902                0                     0             0            0   \n",
       "114903                0                     0             0            0   \n",
       "114904                0                     0             0            0   \n",
       "114905                0                     0             0            7   \n",
       "\n",
       "        welcomeaccount  zendesksupporte-mail  \\\n",
       "114901               1                     0   \n",
       "114902               0                     0   \n",
       "114903               1                     0   \n",
       "114904               1                     0   \n",
       "114905               1                     0   \n",
       "\n",
       "        zero-amountinvoicefromrecurringprofile  \n",
       "114901                                       0  \n",
       "114902                                       0  \n",
       "114903                                       0  \n",
       "114904                                       0  \n",
       "114905                                       0  \n",
       "\n",
       "[5 rows x 393 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking\n",
    "df_events_all_accounts_day_7.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114906, 393)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_events_all_accounts_day_7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking duplicate systemid presense \n",
    "# duplicateSystemID = pd.concat(g for _, g in df_events_all_accounts_day_7.groupby('systemid') if len(g) > 1)\n",
    "# duplicateSystemID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV export \n",
    "df_events_all_accounts_day_7.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/events_new_accounts_day_7.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_events_all_accounts_day_7 = pd.read_csv(\"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/events_new_accounts_day_7.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Events Important Features Selection\n",
    "\n",
    "### 5.3.1 Adding missing features columns in the event features dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing importing features list\n",
    "important_features = pd.read_csv( \n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/important_features.csv\", sep=\"\\n,\")\n",
    "\n",
    "# Get the important feature as a list\n",
    "imp_features_list = list(important_features['important_feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking\n",
    "# important_features.head()\n",
    "# imp_features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding missing important feature column \n",
    "for i in range(len(imp_features_list)):\n",
    "    if imp_features_list[i] in df_events_all_accounts_day_7.columns:\n",
    "        print(\"True\")\n",
    "    else:\n",
    "        print(\"False\")\n",
    "        df_events_all_accounts_day_7[imp_features_list[i]] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking\n",
    "# df_events_all_accounts_day_7.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 Fitering only important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering only important features \n",
    "df_events_imp_features_all_accounts_day_7 = \\\n",
    "            df_events_all_accounts_day_7.loc[:, df_events_all_accounts_day_7.columns.str.contains('|'.join(imp_features_list))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>systemid</th>\n",
       "      <th>acceptestimate</th>\n",
       "      <th>accesstokencreated</th>\n",
       "      <th>activateclient</th>\n",
       "      <th>activateestimate</th>\n",
       "      <th>activateexpense</th>\n",
       "      <th>activateinvoice</th>\n",
       "      <th>activateotherincome</th>\n",
       "      <th>activatepayment</th>\n",
       "      <th>activateproject</th>\n",
       "      <th>...</th>\n",
       "      <th>zendesksupporte-mail</th>\n",
       "      <th>activatestaff</th>\n",
       "      <th>clientimportcsvsucceeded</th>\n",
       "      <th>convertpaymenttocredit</th>\n",
       "      <th>createbanktransfer</th>\n",
       "      <th>createfolder</th>\n",
       "      <th>emailcreditnote</th>\n",
       "      <th>exportjournalentries</th>\n",
       "      <th>updatefolderpermissions</th>\n",
       "      <th>verifycallback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4504870</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4504872</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4504874</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4504876</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4504878</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 232 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   systemid  acceptestimate  accesstokencreated  activateclient  \\\n",
       "0   4504870               0                   1               0   \n",
       "1   4504872               0                   2               0   \n",
       "2   4504874               0                   0               0   \n",
       "3   4504876               0                   0               0   \n",
       "4   4504878               0                   0               0   \n",
       "\n",
       "   activateestimate  activateexpense  activateinvoice  activateotherincome  \\\n",
       "0                 0                0                0                    0   \n",
       "1                 0                0                0                    0   \n",
       "2                 0                0                0                    0   \n",
       "3                 0                0                0                    0   \n",
       "4                 0                0                0                    0   \n",
       "\n",
       "   activatepayment  activateproject  ...  zendesksupporte-mail  activatestaff  \\\n",
       "0                0                0  ...                     0              0   \n",
       "1                0                0  ...                     0              0   \n",
       "2                0                0  ...                     0              0   \n",
       "3                0                0  ...                     0              0   \n",
       "4                0                0  ...                     0              0   \n",
       "\n",
       "   clientimportcsvsucceeded  convertpaymenttocredit  createbanktransfer  \\\n",
       "0                         0                       0                   0   \n",
       "1                         0                       0                   0   \n",
       "2                         0                       0                   0   \n",
       "3                         0                       0                   0   \n",
       "4                         0                       0                   0   \n",
       "\n",
       "   createfolder  emailcreditnote  exportjournalentries  \\\n",
       "0             0                0                     0   \n",
       "1             0                0                     0   \n",
       "2             0                0                     0   \n",
       "3             0                0                     0   \n",
       "4             0                0                     0   \n",
       "\n",
       "   updatefolderpermissions  verifycallback  \n",
       "0                        0               0  \n",
       "1                        0               0  \n",
       "2                        0               0  \n",
       "3                        0               0  \n",
       "4                        0               0  \n",
       "\n",
       "[5 rows x 232 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking\n",
    "df_events_imp_features_all_accounts_day_7.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Filtering avgerage word counts features from invoice data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filtering average word counts features from the invoice data\n",
    "# Invoice features at day 7\n",
    "df_invoice_features_all_accounts_day_7 = df_periodic_invoice_all_counts[[\n",
    "        'systemid',\n",
    "        'admin_email',\n",
    "        'is_sales_managed', \n",
    "        'is_freshbooks_account_active',\n",
    "        'is_paying',\n",
    "        'avg_wc_description_day_7',\n",
    "        'avg_wc_notes_day_7',\n",
    "        'avg_wc_terms_day_7',\n",
    "        'avg_wc_address_day_7',\n",
    "        'invoice_count_day_7',\n",
    "        'client_count_day_7'\n",
    "        ]]\n",
    "\n",
    "# CSV export\n",
    "df_invoice_features_all_accounts_day_7.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/invoice_features_new_accounts_day_7.csv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_invoice_features_all_accounts_day_7 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/invoice_features_new_accounts_day_7.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking\n",
    "# df_invoice_features_all_accounts_day_7.shape\n",
    "# list(df_periodic_invoice_all_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Merging events' and Invoice features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging events' and invoice features\n",
    "df_final_features_day_7 = pd.merge(df_events_imp_features_all_accounts_day_7, \n",
    "                                   df_invoice_features_all_accounts_day_7,\n",
    "                                     on='systemid', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>systemid</th>\n",
       "      <th>acceptestimate</th>\n",
       "      <th>accesstokencreated</th>\n",
       "      <th>activateclient</th>\n",
       "      <th>activateestimate</th>\n",
       "      <th>activateexpense</th>\n",
       "      <th>activateinvoice</th>\n",
       "      <th>activateotherincome</th>\n",
       "      <th>activatepayment</th>\n",
       "      <th>activateproject</th>\n",
       "      <th>...</th>\n",
       "      <th>admin_email</th>\n",
       "      <th>is_sales_managed</th>\n",
       "      <th>is_freshbooks_account_active</th>\n",
       "      <th>is_paying</th>\n",
       "      <th>avg_wc_description_day_7</th>\n",
       "      <th>avg_wc_notes_day_7</th>\n",
       "      <th>avg_wc_terms_day_7</th>\n",
       "      <th>avg_wc_address_day_7</th>\n",
       "      <th>invoice_count_day_7</th>\n",
       "      <th>client_count_day_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4504870</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>gdfggdgd12@gmail.com</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4504872</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>jamaicahamilton71@gmail.com</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4504874</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>lillosnx@gmail.com</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4504876</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>solutions@okanaganorganizer.com</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4504878</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>reed.bianca26@gmail.com</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 242 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   systemid  acceptestimate  accesstokencreated  activateclient  \\\n",
       "0   4504870               0                   1               0   \n",
       "1   4504872               0                   2               0   \n",
       "2   4504874               0                   0               0   \n",
       "3   4504876               0                   0               0   \n",
       "4   4504878               0                   0               0   \n",
       "\n",
       "   activateestimate  activateexpense  activateinvoice  activateotherincome  \\\n",
       "0                 0                0                0                    0   \n",
       "1                 0                0                0                    0   \n",
       "2                 0                0                0                    0   \n",
       "3                 0                0                0                    0   \n",
       "4                 0                0                0                    0   \n",
       "\n",
       "   activatepayment  activateproject  ...                      admin_email  \\\n",
       "0                0                0  ...             gdfggdgd12@gmail.com   \n",
       "1                0                0  ...      jamaicahamilton71@gmail.com   \n",
       "2                0                0  ...               lillosnx@gmail.com   \n",
       "3                0                0  ...  solutions@okanaganorganizer.com   \n",
       "4                0                0  ...          reed.bianca26@gmail.com   \n",
       "\n",
       "   is_sales_managed  is_freshbooks_account_active  is_paying  \\\n",
       "0               0.0                           0.0        0.0   \n",
       "1               0.0                           1.0        0.0   \n",
       "2               0.0                           1.0        0.0   \n",
       "3               0.0                           1.0        0.0   \n",
       "4               0.0                           1.0        0.0   \n",
       "\n",
       "   avg_wc_description_day_7  avg_wc_notes_day_7  avg_wc_terms_day_7  \\\n",
       "0                       0.0                 0.0                 0.0   \n",
       "1                       1.0                 0.0                 0.0   \n",
       "2                       0.0                 0.0                 0.0   \n",
       "3                       0.0                 0.0                 0.0   \n",
       "4                       0.0                 0.0                 0.0   \n",
       "\n",
       "   avg_wc_address_day_7  invoice_count_day_7  client_count_day_7  \n",
       "0                   0.0                  0.0                 1.0  \n",
       "1                   0.0                  1.0                 2.0  \n",
       "2                   0.0                  0.0                 1.0  \n",
       "3                   0.0                  0.0                 1.0  \n",
       "4                   0.0                  0.0                 1.0  \n",
       "\n",
       "[5 rows x 242 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Head of the dataframe\n",
    "df_final_features_day_7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114906, 242)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the dimension \n",
    "df_final_features_day_7.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Filtering FreshBooks test accounts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Filtering FreshBooks Test Accounts #############################################################\n",
    "\n",
    "# Import Freshbooks test accounts email from CSV file (non-freshbooks email)\n",
    "fb_test_emails = pd.read_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_fb_test_email/non-fb-testing-emails.tsv\", \n",
    "                                      sep=\"\\t\")\n",
    "fb_test_email_list = list(fb_test_emails['email'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fb_test_email_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Filtering FB test account by using admin email\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def email_match(em, email_list):\n",
    "    \n",
    "    L = len(email_list)\n",
    "#     print('L', L)\n",
    "#     print('em-before-loop: ', em)\n",
    "    match_score = 0\n",
    "#     x = float(em)\n",
    "    \n",
    "    for i in range(0, L):\n",
    "#         if math.isnan(x):\n",
    "#             match_score = 0\n",
    "#             break;\n",
    "        if pd.isnull(em):\n",
    "            match_score = 0\n",
    "            break;\n",
    "        else: \n",
    "            match_score =  max(match_score, SequenceMatcher(None,em, email_list[i]).ratio())\n",
    "            print(i, em, email_list[i], match_score)\n",
    "\n",
    "    return match_score\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering final data from the FreshBooks Test emails\n",
    "# df_final_features_day_7 = df_final_features_day_7[\n",
    "#     df_final_features_day_7.apply(lambda x: email_match(x['admin_email'], fb_test_email_list) > 0.9, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV export \n",
    "df_final_features_day_7.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new_final/new_final_features_day_7.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_final_features_day_7 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new_final/new_final_features_day_7.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114906, 242)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking\n",
    "df_final_features_day_7.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Final Features Data: Day 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Final Features Data: Day 14 Model ###########\n",
    "\n",
    "# Filtered the events columns for day 14 period\n",
    "df_events_all_accounts_day_14 = df_events_all_accounts[['systemid', 'event_count_day_14', 'event_name']]\n",
    "\n",
    "### Pivote the Day 14 Events (Each Unique Event Become a Column)###\n",
    "# Pivot table based on the unique column value in 'event_name'\n",
    "df_events_all_accounts_day_14 = df_events_all_accounts_day_14.pivot_table(values='event_count_day_14', columns='event_name', index='systemid', aggfunc=np.sum,  fill_value=0)\n",
    "\n",
    "# Drop the old column name\n",
    "df_events_all_accounts_day_14.columns.name = None\n",
    "\n",
    "# Reset the index\n",
    "df_events_all_accounts_day_14 = df_events_all_accounts_day_14.reset_index()\n",
    "\n",
    "# Replace 'NaN' with zero\n",
    "df_events_all_accounts_day_14.fillna(0, inplace=True)\n",
    "\n",
    "# CSV export \n",
    "df_events_all_accounts_day_14.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/events_new_accounts_day_14.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_events_all_accounts_day_14 = pd.read_csv(\"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/events_new_accounts_day_14.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Importing importing features list\n",
    "important_features = pd.read_csv( \n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/important_features.csv\", sep=\"\\n,\")\n",
    "\n",
    "# Get the important feature as a list\n",
    "imp_features_list = list(important_features['important_feature'])\n",
    "\n",
    "# Adding missing important feature column \n",
    "for i in range(len(imp_features_list)):\n",
    "    if imp_features_list[i] in df_events_all_accounts_day_14.columns:\n",
    "        print(\"True\")\n",
    "    else:\n",
    "        print(\"False\")\n",
    "        df_events_all_accounts_day_14[imp_features_list[i]] = 0\n",
    "\n",
    "# Filtering only important features \n",
    "df_events_imp_features_all_accounts_day_14 = \\\n",
    "            df_events_all_accounts_day_14.loc[:, df_events_all_accounts_day_14.columns.str.contains('|'.join(imp_features_list))]\n",
    "\n",
    "\n",
    "### Filtering average word counts features from the invoice data\n",
    "# Invoice features at day 14\n",
    "df_invoice_features_all_accounts_day_14 = df_periodic_invoice_all_counts[[\n",
    "        'systemid',\n",
    "        'admin_email',\n",
    "        'is_sales_managed', \n",
    "        'is_freshbooks_account_active',\n",
    "        'is_paying',\n",
    "        'avg_wc_description_day_14',\n",
    "        'avg_wc_notes_day_14',\n",
    "        'avg_wc_terms_day_14',\n",
    "        'avg_wc_address_day_14',\n",
    "        'invoice_count_day_14',\n",
    "        'client_count_day_14'\n",
    "        ]]\n",
    "\n",
    "# CSV export\n",
    "df_invoice_features_all_accounts_day_14.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/invoice_features_new_accounts_day_14.csv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_invoice_features_all_accounts_day_14 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_14.csv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Merging events' and invoice features\n",
    "df_final_features_day_14 = pd.merge(df_events_imp_features_all_accounts_day_14, \n",
    "                                   df_invoice_features_all_accounts_day_14,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "\n",
    "# Filtering final data from the FreshBooks Test emails\n",
    "# df_final_features_day_14 = df_final_features_day_14[\n",
    "#     df_final_features_day_14.apply(lambda x: email_match(x['admin_email'], fb_test_email_list) > 0.9, axis=1)]\n",
    "\n",
    "# CSV export \n",
    "df_final_features_day_14.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new_final/new_final_features_day_14.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_final_features_day_14 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new_final/new_final_features_day_14.tsv\", sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Final Featues Data: Day 21\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Final Features Data: Day 21 Model ###########\n",
    "\n",
    "# Filtered the events columns for day 21 period\n",
    "df_events_all_accounts_day_21 = df_events_all_accounts[['systemid', 'event_count_day_21', 'event_name']]\n",
    "\n",
    "### Pivote the Day 21 Events (Each Unique Event Become a Column)###\n",
    "# Pivot table based on the unique column value in 'event_name'\n",
    "df_events_all_accounts_day_21 = df_events_all_accounts_day_21.pivot_table(values='event_count_day_21', columns='event_name', index='systemid', aggfunc=np.sum,  fill_value=0)\n",
    "\n",
    "# Drop the old column name\n",
    "df_events_all_accounts_day_21.columns.name = None\n",
    "\n",
    "# Reset the index\n",
    "df_events_all_accounts_day_21 = df_events_all_accounts_day_21.reset_index()\n",
    "\n",
    "# Replace 'NaN' with zero\n",
    "df_events_all_accounts_day_21.fillna(0, inplace=True)\n",
    "\n",
    "# CSV export \n",
    "df_events_all_accounts_day_21.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/events_new_accounts_day_21.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_events_all_accounts_day_21 = pd.read_csv(\"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_21.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Importing importing features list\n",
    "important_features = pd.read_csv( \n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/important_features.csv\", sep=\"\\n,\")\n",
    "\n",
    "# Get the important feature as a list\n",
    "imp_features_list = list(important_features['important_feature'])\n",
    "\n",
    "# Adding missing important feature column \n",
    "for i in range(len(imp_features_list)):\n",
    "    if imp_features_list[i] in df_events_all_accounts_day_21.columns:\n",
    "        print(\"True\")\n",
    "    else:\n",
    "        print(\"False\")\n",
    "        df_events_all_accounts_day_21[imp_features_list[i]] = 0\n",
    "\n",
    "# Filtering only important features \n",
    "df_events_imp_features_all_accounts_day_21 = \\\n",
    "            df_events_all_accounts_day_21.loc[:, df_events_all_accounts_day_21.columns.str.contains('|'.join(imp_features_list))]\n",
    "\n",
    "\n",
    "### Filtering average word counts features from the invoice data\n",
    "# Invoice features at day 21\n",
    "df_invoice_features_all_accounts_day_21 = df_periodic_invoice_all_counts[[\n",
    "        'systemid',\n",
    "        'admin_email',\n",
    "        'is_sales_managed', \n",
    "        'is_freshbooks_account_active',\n",
    "        'is_paying',\n",
    "        'avg_wc_description_day_21',\n",
    "        'avg_wc_notes_day_21',\n",
    "        'avg_wc_terms_day_21',\n",
    "        'avg_wc_address_day_21',\n",
    "        'invoice_count_day_21',\n",
    "        'client_count_day_21'\n",
    "        ]]\n",
    "\n",
    "# CSV export\n",
    "df_invoice_features_all_accounts_day_21.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/invoice_features_new_accounts_day_21.csv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_invoice_features_all_accounts_day_21 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_21.csv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Merging events' and invoice features\n",
    "df_final_features_day_21 = pd.merge(df_events_imp_features_all_accounts_day_21, \n",
    "                                   df_invoice_features_all_accounts_day_21,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "\n",
    "# Filtering final data from the FreshBooks Test emails\n",
    "# df_final_features_day_21 = df_final_features_day_21[\n",
    "#     df_final_features_day_21.apply(lambda x: email_match(x['admin_email'], fb_test_email_list) > 0.9, axis=1)]\n",
    "\n",
    "# CSV export \n",
    "df_final_features_day_21.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new_final/new_final_features_day_21.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_final_features_day_21 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_21.tsv\", sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Final Features Extraction: Day 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Final Features Data: Day 28 Model ###########\n",
    "\n",
    "# Filtered the events columns for day 28 period\n",
    "df_events_all_accounts_day_28 = df_events_all_accounts[['systemid', 'event_count_day_28', 'event_name']]\n",
    "\n",
    "### Pivote the Day 28 Events (Each Unique Event Become a Column)###\n",
    "# Pivot table based on the unique column value in 'event_name'\n",
    "df_events_all_accounts_day_28 = df_events_all_accounts_day_28.pivot_table(values='event_count_day_28', columns='event_name', index='systemid', aggfunc=np.sum,  fill_value=0)\n",
    "\n",
    "# Drop the old column name\n",
    "df_events_all_accounts_day_28.columns.name = None\n",
    "\n",
    "# Reset the index\n",
    "df_events_all_accounts_day_28 = df_events_all_accounts_day_28.reset_index()\n",
    "\n",
    "# Replace 'NaN' with zero\n",
    "df_events_all_accounts_day_28.fillna(0, inplace=True)\n",
    "\n",
    "# CSV export \n",
    "df_events_all_accounts_day_28.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/events_new_accounts_day_28.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_events_all_accounts_day_28 = pd.read_csv(\"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_28.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Importing importing features list\n",
    "important_features = pd.read_csv( \n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/important_features.csv\", sep=\"\\n,\")\n",
    "\n",
    "# Get the important feature as a list\n",
    "imp_features_list = list(important_features['important_feature'])\n",
    "\n",
    "# Adding missing important feature column \n",
    "for i in range(len(imp_features_list)):\n",
    "    if imp_features_list[i] in df_events_all_accounts_day_28.columns:\n",
    "        print(\"True\")\n",
    "    else:\n",
    "        print(\"False\")\n",
    "        df_events_all_accounts_day_28[imp_features_list[i]] = 0\n",
    "\n",
    "# Filtering only important features \n",
    "df_events_imp_features_all_accounts_day_28 = \\\n",
    "            df_events_all_accounts_day_28.loc[:, df_events_all_accounts_day_28.columns.str.contains('|'.join(imp_features_list))]\n",
    "\n",
    "\n",
    "### Filtering average word counts features from the invoice data\n",
    "# Invoice features at day 28\n",
    "df_invoice_features_all_accounts_day_28 = df_periodic_invoice_all_counts[[\n",
    "        'systemid',\n",
    "        'admin_email', \n",
    "        'is_sales_managed', \n",
    "        'is_freshbooks_account_active',\n",
    "        'is_paying',\n",
    "        'avg_wc_description_day_28',\n",
    "        'avg_wc_notes_day_28',\n",
    "        'avg_wc_terms_day_28',\n",
    "        'avg_wc_address_day_28',\n",
    "        'invoice_count_day_28',\n",
    "        'client_count_day_28'\n",
    "        ]]\n",
    "\n",
    "# CSV export\n",
    "df_invoice_features_all_accounts_day_28.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/invoice_features_new_accounts_day_28.csv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_invoice_features_all_accounts_day_28 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_28.csv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Merging events' and invoice features\n",
    "df_final_features_day_28 = pd.merge(df_events_imp_features_all_accounts_day_28, \n",
    "                                   df_invoice_features_all_accounts_day_28,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# Filtering final data from the FreshBooks Test emails\n",
    "# df_final_features_day_28 = df_final_features_day_28[\n",
    "#     df_final_features_day_28.apply(lambda x: email_match(x['admin_email'], fb_test_email_list) > 0.9, axis=1)]\n",
    "\n",
    "# CSV export \n",
    "df_final_features_day_28.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new_final/new_final_features_day_28.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_final_features_day_28 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_28.tsv\", sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Final Features Extraction: Day 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Final Features Data: Day 35 Model ###########\n",
    "\n",
    "# Filtered the events columns for day 35 period\n",
    "df_events_all_accounts_day_35 = df_events_all_accounts[['systemid', 'event_count_day_35', 'event_name']]\n",
    "\n",
    "### Pivote the Day 35 Events (Each Unique Event Become a Column)###\n",
    "# Pivot table based on the unique column value in 'event_name'\n",
    "df_events_all_accounts_day_35 = df_events_all_accounts_day_35.pivot_table(values='event_count_day_35', columns='event_name', index='systemid', aggfunc=np.sum,  fill_value=0)\n",
    "\n",
    "# Drop the old column name\n",
    "df_events_all_accounts_day_35.columns.name = None\n",
    "\n",
    "# Reset the index\n",
    "df_events_all_accounts_day_35 = df_events_all_accounts_day_35.reset_index()\n",
    "\n",
    "# Replace 'NaN' with zero\n",
    "df_events_all_accounts_day_35.fillna(0, inplace=True)\n",
    "\n",
    "# CSV export \n",
    "df_events_all_accounts_day_35.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/events_new_accounts_day_35.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_events_all_accounts_day_35 = pd.read_csv(\"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_35.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Importing importing features list\n",
    "important_features = pd.read_csv( \n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/important_features.csv\", sep=\"\\n,\")\n",
    "\n",
    "# Get the important feature as a list\n",
    "imp_features_list = list(important_features['important_feature'])\n",
    "\n",
    "# Adding missing important feature column \n",
    "for i in range(len(imp_features_list)):\n",
    "    if imp_features_list[i] in df_events_all_accounts_day_35.columns:\n",
    "        print(\"True\")\n",
    "    else:\n",
    "        print(\"False\")\n",
    "        df_events_all_accounts_day_35[imp_features_list[i]] = 0\n",
    "\n",
    "# Filtering only important features \n",
    "df_events_imp_features_all_accounts_day_35 = \\\n",
    "            df_events_all_accounts_day_35.loc[:, df_events_all_accounts_day_35.columns.str.contains('|'.join(imp_features_list))]\n",
    "\n",
    "\n",
    "### Filtering average word counts features from the invoice data\n",
    "# Invoice features at day 35\n",
    "df_invoice_features_all_accounts_day_35 = df_periodic_invoice_all_counts[[\n",
    "        'systemid',\n",
    "        'admin_email',\n",
    "        'is_sales_managed', \n",
    "        'is_freshbooks_account_active',\n",
    "        'is_paying',\n",
    "        'avg_wc_description_day_35',\n",
    "        'avg_wc_notes_day_35',\n",
    "        'avg_wc_terms_day_35',\n",
    "        'avg_wc_address_day_35',\n",
    "        'invoice_count_day_35',\n",
    "        'client_count_day_35'\n",
    "        ]]\n",
    "\n",
    "# CSV export\n",
    "df_invoice_features_all_accounts_day_35.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/invoice_features_new_accounts_day_35.csv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_invoice_features_all_accounts_day_35 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_35.csv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Merging events' and invoice features\n",
    "df_final_features_day_35 = pd.merge(df_events_imp_features_all_accounts_day_35, \n",
    "                                   df_invoice_features_all_accounts_day_35,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# Filtering final data from the FreshBooks Test emails\n",
    "# df_final_features_day_35 = df_final_features_day_35[\n",
    "#     df_final_features_day_35.apply(lambda x: email_match(x['admin_email'], fb_test_email_list) > 0.9, axis=1)]\n",
    "\n",
    "# CSV export \n",
    "df_final_features_day_35.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new_final/new_final_features_day_35.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_final_features_day_35 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_35.tsv\", sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Final Features Extraction: Day 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Final Features Data: Day 42 Model ###########\n",
    "\n",
    "# Filtered the events columns for day 42 period\n",
    "df_events_all_accounts_day_42 = df_events_all_accounts[['systemid', 'event_count_day_42', 'event_name']]\n",
    "\n",
    "### Pivote the Day 42 Events (Each Unique Event Become a Column)###\n",
    "# Pivot table based on the unique column value in 'event_name'\n",
    "df_events_all_accounts_day_42 = df_events_all_accounts_day_42.pivot_table(values='event_count_day_42', columns='event_name', index='systemid', aggfunc=np.sum,  fill_value=0)\n",
    "\n",
    "# Drop the old column name\n",
    "df_events_all_accounts_day_42.columns.name = None\n",
    "\n",
    "# Reset the index\n",
    "df_events_all_accounts_day_42 = df_events_all_accounts_day_42.reset_index()\n",
    "\n",
    "# Replace 'NaN' with zero\n",
    "df_events_all_accounts_day_42.fillna(0, inplace=True)\n",
    "\n",
    "# CSV export \n",
    "df_events_all_accounts_day_42.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/events_new_accounts_day_42.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_events_all_accounts_day_42 = pd.read_csv(\"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_42.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Importing importing features list\n",
    "important_features = pd.read_csv( \n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/important_features.csv\", sep=\"\\n,\")\n",
    "\n",
    "# Get the important feature as a list\n",
    "imp_features_list = list(important_features['important_feature'])\n",
    "\n",
    "# Adding missing important feature column \n",
    "for i in range(len(imp_features_list)):\n",
    "    if imp_features_list[i] in df_events_all_accounts_day_42.columns:\n",
    "        print(\"True\")\n",
    "    else:\n",
    "        print(\"False\")\n",
    "        df_events_all_accounts_day_42[imp_features_list[i]] = 0\n",
    "\n",
    "# Filtering only important features \n",
    "df_events_imp_features_all_accounts_day_42 = \\\n",
    "            df_events_all_accounts_day_42.loc[:, df_events_all_accounts_day_42.columns.str.contains('|'.join(imp_features_list))]\n",
    "\n",
    "\n",
    "### Filtering average word counts features from the invoice data\n",
    "# Invoice features at day 42\n",
    "df_invoice_features_all_accounts_day_42 = df_periodic_invoice_all_counts[[\n",
    "        'systemid',\n",
    "        'admin_email',\n",
    "        'is_sales_managed', \n",
    "        'is_freshbooks_account_active',\n",
    "        'is_paying',\n",
    "        'avg_wc_description_day_42',\n",
    "        'avg_wc_notes_day_42',\n",
    "        'avg_wc_terms_day_42',\n",
    "        'avg_wc_address_day_42',\n",
    "        'invoice_count_day_42',\n",
    "        'client_count_day_42'\n",
    "        ]]\n",
    "\n",
    "# CSV export\n",
    "df_invoice_features_all_accounts_day_42.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/invoice_features_new_accounts_day_42.csv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_invoice_features_all_accounts_day_42 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_42.csv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Merging events' and invoice features\n",
    "df_final_features_day_42 = pd.merge(df_events_imp_features_all_accounts_day_42, \n",
    "                                   df_invoice_features_all_accounts_day_42,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# Filtering final data from the FreshBooks Test emails\n",
    "# df_final_features_day_42 = df_final_features_day_42[\n",
    "#     df_final_features_day_42.apply(lambda x: email_match(x['admin_email'], fb_test_email_list) > 0.9, axis=1)]\n",
    "\n",
    "# CSV export \n",
    "df_final_features_day_42.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new_final/new_final_features_day_42.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_final_features_day_42 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_42.tsv\", sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Final Features Data: Day 49 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Final Features Data: Day 49 Model ###########\n",
    "\n",
    "# Filtered the events columns for day 49 period\n",
    "df_events_all_accounts_day_49 = df_events_all_accounts[['systemid', 'event_count_day_49', 'event_name']]\n",
    "\n",
    "### Pivote the Day 49 Events (Each Unique Event Become a Column)###\n",
    "# Pivot table based on the unique column value in 'event_name'\n",
    "df_events_all_accounts_day_49 = df_events_all_accounts_day_49.pivot_table(values='event_count_day_49', columns='event_name', index='systemid', aggfunc=np.sum,  fill_value=0)\n",
    "\n",
    "# Drop the old column name\n",
    "df_events_all_accounts_day_49.columns.name = None\n",
    "\n",
    "# Reset the index\n",
    "df_events_all_accounts_day_49 = df_events_all_accounts_day_49.reset_index()\n",
    "\n",
    "# Replace 'NaN' with zero\n",
    "df_events_all_accounts_day_49.fillna(0, inplace=True)\n",
    "\n",
    "# CSV export \n",
    "df_events_all_accounts_day_49.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/events_new_accounts_day_49.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_events_all_accounts_day_49 = pd.read_csv(\"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_49.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Importing importing features list\n",
    "important_features = pd.read_csv( \n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/important_features.csv\", sep=\"\\n,\")\n",
    "\n",
    "# Get the important feature as a list\n",
    "imp_features_list = list(important_features['important_feature'])\n",
    "\n",
    "# Adding missing important feature column \n",
    "for i in range(len(imp_features_list)):\n",
    "    if imp_features_list[i] in df_events_all_accounts_day_49.columns:\n",
    "        print(\"True\")\n",
    "    else:\n",
    "        print(\"False\")\n",
    "        df_events_all_accounts_day_49[imp_features_list[i]] = 0\n",
    "\n",
    "# Filtering only important features \n",
    "df_events_imp_features_all_accounts_day_49 = \\\n",
    "            df_events_all_accounts_day_49.loc[:, df_events_all_accounts_day_49.columns.str.contains('|'.join(imp_features_list))]\n",
    "\n",
    "\n",
    "### Filtering average word counts features from the invoice data\n",
    "# Invoice features at day 49\n",
    "df_invoice_features_all_accounts_day_49 = df_periodic_invoice_all_counts[[\n",
    "        'systemid',\n",
    "        'admin_email',\n",
    "        'is_sales_managed', \n",
    "        'is_freshbooks_account_active',\n",
    "        'is_paying',\n",
    "        'avg_wc_description_day_49',\n",
    "        'avg_wc_notes_day_49',\n",
    "        'avg_wc_terms_day_49',\n",
    "        'avg_wc_address_day_49',\n",
    "        'invoice_count_day_49',\n",
    "        'client_count_day_49'\n",
    "        ]]\n",
    "\n",
    "# CSV export\n",
    "df_invoice_features_all_accounts_day_49.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/invoice_features_new_accounts_day_49.csv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_invoice_features_all_accounts_day_49 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_49.csv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Merging events' and invoice features\n",
    "df_final_features_day_49 = pd.merge(df_events_imp_features_all_accounts_day_49, \n",
    "                                   df_invoice_features_all_accounts_day_49,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# Filtering final data from the FreshBooks Test emails\n",
    "# df_final_features_day_49 = df_final_features_day_49[\n",
    "#     df_final_features_day_49.apply(lambda x: email_match(x['admin_email'], fb_test_email_list) > 0.9, axis=1)]\n",
    "\n",
    "# CSV export \n",
    "df_final_features_day_49.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new_final/new_final_features_day_49.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_final_features_day_49 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_49.tsv\", sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Final Feature Data: Day 56 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Final Features Data: Day 56 Model ###########\n",
    "\n",
    "# Filtered the events columns for day 56 period\n",
    "df_events_all_accounts_day_56 = df_events_all_accounts[['systemid', 'event_count_day_56', 'event_name']]\n",
    "\n",
    "### Pivote the Day 56 Events (Each Unique Event Become a Column)###\n",
    "# Pivot table based on the unique column value in 'event_name'\n",
    "df_events_all_accounts_day_56 = df_events_all_accounts_day_56.pivot_table(values='event_count_day_56', columns='event_name', index='systemid', aggfunc=np.sum,  fill_value=0)\n",
    "\n",
    "# Drop the old column name\n",
    "df_events_all_accounts_day_56.columns.name = None\n",
    "\n",
    "# Reset the index\n",
    "df_events_all_accounts_day_56 = df_events_all_accounts_day_56.reset_index()\n",
    "\n",
    "# Replace 'NaN' with zero\n",
    "df_events_all_accounts_day_56.fillna(0, inplace=True)\n",
    "\n",
    "# CSV export \n",
    "df_events_all_accounts_day_56.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/events_new_accounts_day_56.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_events_all_accounts_day_56 = pd.read_csv(\"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_56.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Importing importing features list\n",
    "important_features = pd.read_csv( \n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/important_features.csv\", sep=\"\\n,\")\n",
    "\n",
    "# Get the important feature as a list\n",
    "imp_features_list = list(important_features['important_feature'])\n",
    "\n",
    "# Adding missing important feature column \n",
    "for i in range(len(imp_features_list)):\n",
    "    if imp_features_list[i] in df_events_all_accounts_day_56.columns:\n",
    "        print(\"True\")\n",
    "    else:\n",
    "        print(\"False\")\n",
    "        df_events_all_accounts_day_56[imp_features_list[i]] = 0\n",
    "\n",
    "# Filtering only important features \n",
    "df_events_imp_features_all_accounts_day_56 = \\\n",
    "            df_events_all_accounts_day_56.loc[:, df_events_all_accounts_day_56.columns.str.contains('|'.join(imp_features_list))]\n",
    "\n",
    "\n",
    "### Filtering average word counts features from the invoice data\n",
    "# Invoice features at day 56\n",
    "df_invoice_features_all_accounts_day_56 = df_periodic_invoice_all_counts[[\n",
    "        'systemid',\n",
    "        'admin_email',\n",
    "        'is_sales_managed', \n",
    "        'is_freshbooks_account_active',\n",
    "        'is_paying',\n",
    "        'avg_wc_description_day_56',\n",
    "        'avg_wc_notes_day_56',\n",
    "        'avg_wc_terms_day_56',\n",
    "        'avg_wc_address_day_56',\n",
    "        'invoice_count_day_56',\n",
    "        'client_count_day_56'\n",
    "        ]]\n",
    "\n",
    "# CSV export\n",
    "df_invoice_features_all_accounts_day_56.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/invoice_features_new_accounts_day_56.csv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_invoice_features_all_accounts_day_56 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_56.csv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Merging events' and invoice features\n",
    "df_final_features_day_56 = pd.merge(df_events_imp_features_all_accounts_day_56, \n",
    "                                   df_invoice_features_all_accounts_day_56,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# Filtering final data from the FreshBooks Test emails\n",
    "df_final_features_day_56 = df_final_features_day_56[\n",
    "    df_final_features_day_56.apply(lambda x: email_match(x['admin_email'], fb_test_email_list) > 0.9, axis=1)]\n",
    "\n",
    "# CSV export \n",
    "df_final_features_day_56.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new_final/new_final_features_day_56.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_final_features_day_56 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_56.tsv\", sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Final Features Data: Day 63 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Final Features Data: Day 63 Model ###########\n",
    "\n",
    "# Filtered the events columns for day 63 period\n",
    "df_events_all_accounts_day_63 = df_events_all_accounts[['systemid', 'event_count_day_63', 'event_name']]\n",
    "\n",
    "### Pivote the Day 63 Events (Each Unique Event Become a Column)###\n",
    "# Pivot table based on the unique column value in 'event_name'\n",
    "df_events_all_accounts_day_63 = df_events_all_accounts_day_63.pivot_table(values='event_count_day_63', columns='event_name', index='systemid', aggfunc=np.sum,  fill_value=0)\n",
    "\n",
    "# Drop the old column name\n",
    "df_events_all_accounts_day_63.columns.name = None\n",
    "\n",
    "# Reset the index\n",
    "df_events_all_accounts_day_63 = df_events_all_accounts_day_63.reset_index()\n",
    "\n",
    "# Replace 'NaN' with zero\n",
    "df_events_all_accounts_day_63.fillna(0, inplace=True)\n",
    "\n",
    "# CSV export \n",
    "df_events_all_accounts_day_63.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/events_new_accounts_day_63.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_events_all_accounts_day_63 = pd.read_csv(\"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_63.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Importing importing features list\n",
    "important_features = pd.read_csv( \n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/important_features.csv\", sep=\"\\n,\")\n",
    "\n",
    "# Get the important feature as a list\n",
    "imp_features_list = list(important_features['important_feature'])\n",
    "\n",
    "# Adding missing important feature column \n",
    "for i in range(len(imp_features_list)):\n",
    "    if imp_features_list[i] in df_events_all_accounts_day_63.columns:\n",
    "        print(\"True\")\n",
    "    else:\n",
    "        print(\"False\")\n",
    "        df_events_all_accounts_day_63[imp_features_list[i]] = 0\n",
    "\n",
    "# Filtering only important features \n",
    "df_events_imp_features_all_accounts_day_63 = \\\n",
    "            df_events_all_accounts_day_63.loc[:, df_events_all_accounts_day_63.columns.str.contains('|'.join(imp_features_list))]\n",
    "\n",
    "\n",
    "### Filtering average word counts features from the invoice data\n",
    "# Invoice features at day 63\n",
    "df_invoice_features_all_accounts_day_63 = df_periodic_invoice_all_counts[[\n",
    "        'systemid',\n",
    "        'admin_email',\n",
    "        'is_sales_managed', \n",
    "        'is_freshbooks_account_active',\n",
    "        'is_paying',\n",
    "        'avg_wc_description_day_63',\n",
    "        'avg_wc_notes_day_63',\n",
    "        'avg_wc_terms_day_63',\n",
    "        'avg_wc_address_day_63',\n",
    "        'invoice_count_day_63',\n",
    "        'client_count_day_63'\n",
    "        ]]\n",
    "\n",
    "# CSV export\n",
    "df_invoice_features_all_accounts_day_63.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/invoice_features_new_accounts_day_63.csv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_invoice_features_all_accounts_day_63 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_63.csv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Merging events' and invoice features\n",
    "df_final_features_day_63 = pd.merge(df_events_imp_features_all_accounts_day_63, \n",
    "                                   df_invoice_features_all_accounts_day_63,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# Filtering final data from the FreshBooks Test emails\n",
    "df_final_features_day_63 = df_final_features_day_63[\n",
    "    df_final_features_day_63.apply(lambda x: email_match(x['admin_email'], fb_test_email_list) > 0.9, axis=1)]\n",
    "\n",
    "# CSV export \n",
    "df_final_features_day_63.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new_final/new_final_features_day_63.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_final_features_day_63 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_63.tsv\", sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. Final Features Data: Day 70 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Final Features Data: Day 70 Model ###########\n",
    "\n",
    "# Filtered the events columns for day 70 period\n",
    "df_events_all_accounts_day_70 = df_events_all_accounts[['systemid', 'event_count_day_70', 'event_name']]\n",
    "\n",
    "### Pivote the Day 70 Events (Each Unique Event Become a Column)###\n",
    "# Pivot table based on the unique column value in 'event_name'\n",
    "df_events_all_accounts_day_70 = df_events_all_accounts_day_70.pivot_table(values='event_count_day_70', columns='event_name', index='systemid', aggfunc=np.sum,  fill_value=0)\n",
    "\n",
    "# Drop the old column name\n",
    "df_events_all_accounts_day_70.columns.name = None\n",
    "\n",
    "# Reset the index\n",
    "df_events_all_accounts_day_70 = df_events_all_accounts_day_70.reset_index()\n",
    "\n",
    "# Replace 'NaN' with zero\n",
    "df_events_all_accounts_day_70.fillna(0, inplace=True)\n",
    "\n",
    "# CSV export \n",
    "df_events_all_accounts_day_70.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/events_new_accounts_day_70.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_events_all_accounts_day_70 = pd.read_csv(\"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_70.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Importing importing features list\n",
    "important_features = pd.read_csv( \n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/important_features.csv\", sep=\"\\n,\")\n",
    "\n",
    "# Get the important feature as a list\n",
    "imp_features_list = list(important_features['important_feature'])\n",
    "\n",
    "# Adding missing important feature column \n",
    "for i in range(len(imp_features_list)):\n",
    "    if imp_features_list[i] in df_events_all_accounts_day_70.columns:\n",
    "        print(\"True\")\n",
    "    else:\n",
    "        print(\"False\")\n",
    "        df_events_all_accounts_day_70[imp_features_list[i]] = 0\n",
    "\n",
    "# Filtering only important features \n",
    "df_events_imp_features_all_accounts_day_70 = \\\n",
    "            df_events_all_accounts_day_70.loc[:, df_events_all_accounts_day_70.columns.str.contains('|'.join(imp_features_list))]\n",
    "\n",
    "\n",
    "### Filtering average word counts features from the invoice data\n",
    "# Invoice features at day 70\n",
    "df_invoice_features_all_accounts_day_70 = df_periodic_invoice_all_counts[[\n",
    "        'systemid',\n",
    "        'admin_email',\n",
    "        'is_sales_managed', \n",
    "        'is_freshbooks_account_active',\n",
    "        'is_paying',\n",
    "        'avg_wc_description_day_70',\n",
    "        'avg_wc_notes_day_70',\n",
    "        'avg_wc_terms_day_70',\n",
    "        'avg_wc_address_day_70',\n",
    "        'invoice_count_day_70',\n",
    "        'client_count_day_70'\n",
    "        ]]\n",
    "\n",
    "# CSV export\n",
    "df_invoice_features_all_accounts_day_70.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/invoice_features_new_accounts_day_70.csv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_invoice_features_all_accounts_day_70 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_70.csv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Merging events' and invoice features\n",
    "df_final_features_day_70 = pd.merge(df_events_imp_features_all_accounts_day_70, \n",
    "                                   df_invoice_features_all_accounts_day_70,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# Filtering final data from the FreshBooks Test emails\n",
    "df_final_features_day_70 = df_final_features_day_70[\n",
    "    df_final_features_day_70.apply(lambda x: email_match(x['admin_email'], fb_test_email_list) > 0.9, axis=1)]\n",
    "\n",
    "# CSV export \n",
    "df_final_features_day_70.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new_final/new_final_features_day_70.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_final_features_day_70 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_70.tsv\", sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. Final Features Data: Day 77 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Final Features Data: Day 77 Model ###########\n",
    "\n",
    "# Filtered the events columns for day 77 period\n",
    "df_events_all_accounts_day_77 = df_events_all_accounts[['systemid', 'event_count_day_77', 'event_name']]\n",
    "\n",
    "### Pivote the Day 77 Events (Each Unique Event Become a Column)###\n",
    "# Pivot table based on the unique column value in 'event_name'\n",
    "df_events_all_accounts_day_77 = df_events_all_accounts_day_77.pivot_table(values='event_count_day_77', columns='event_name', index='systemid', aggfunc=np.sum,  fill_value=0)\n",
    "\n",
    "# Drop the old column name\n",
    "df_events_all_accounts_day_77.columns.name = None\n",
    "\n",
    "# Reset the index\n",
    "df_events_all_accounts_day_77 = df_events_all_accounts_day_77.reset_index()\n",
    "\n",
    "# Replace 'NaN' with zero\n",
    "df_events_all_accounts_day_77.fillna(0, inplace=True)\n",
    "\n",
    "# CSV export \n",
    "df_events_all_accounts_day_77.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/events_new_accounts_day_77.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_events_all_accounts_day_77 = pd.read_csv(\"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_77.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Importing importing features list\n",
    "important_features = pd.read_csv( \n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/important_features.csv\", sep=\"\\n,\")\n",
    "\n",
    "# Get the important feature as a list\n",
    "imp_features_list = list(important_features['important_feature'])\n",
    "\n",
    "# Adding missing important feature column \n",
    "for i in range(len(imp_features_list)):\n",
    "    if imp_features_list[i] in df_events_all_accounts_day_77.columns:\n",
    "        print(\"True\")\n",
    "    else:\n",
    "        print(\"False\")\n",
    "        df_events_all_accounts_day_77[imp_features_list[i]] = 0\n",
    "\n",
    "# Filtering only important features \n",
    "df_events_imp_features_all_accounts_day_77 = \\\n",
    "            df_events_all_accounts_day_77.loc[:, df_events_all_accounts_day_77.columns.str.contains('|'.join(imp_features_list))]\n",
    "\n",
    "\n",
    "### Filtering average word counts features from the invoice data\n",
    "# Invoice features at day 77\n",
    "df_invoice_features_all_accounts_day_77 = df_periodic_invoice_all_counts[[\n",
    "        'systemid',\n",
    "        'admin_email',\n",
    "        'is_sales_managed', \n",
    "        'is_freshbooks_account_active',\n",
    "        'is_paying',\n",
    "        'avg_wc_description_day_77',\n",
    "        'avg_wc_notes_day_77',\n",
    "        'avg_wc_terms_day_77',\n",
    "        'avg_wc_address_day_77',\n",
    "        'invoice_count_day_77',\n",
    "        'client_count_day_77'\n",
    "        ]]\n",
    "\n",
    "# CSV export\n",
    "df_invoice_features_all_accounts_day_77.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/invoice_features_new_accounts_day_77.csv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_invoice_features_all_accounts_day_77 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_77.csv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Merging events' and invoice features\n",
    "df_final_features_day_77 = pd.merge(df_events_imp_features_all_accounts_day_77, \n",
    "                                   df_invoice_features_all_accounts_day_77,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# Filtering final data from the FreshBooks Test emails\n",
    "df_final_features_day_77 = df_final_features_day_77[\n",
    "    df_final_features_day_77.apply(lambda x: email_match(x['admin_email'], fb_test_email_list) > 0.9, axis=1)]\n",
    "\n",
    "# CSV export \n",
    "df_final_features_day_77.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new_final/new_final_features_day_77.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_final_features_day_77 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_77.tsv\", sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Final Features Data: Day 84 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Final Features Data: Day 84 Model ###########\n",
    "\n",
    "# Filtered the events columns for day 84 period\n",
    "df_events_all_accounts_day_84 = df_events_all_accounts[['systemid', 'event_count_day_84', 'event_name']]\n",
    "\n",
    "### Pivote the Day 84 Events (Each Unique Event Become a Column)###\n",
    "# Pivot table based on the unique column value in 'event_name'\n",
    "df_events_all_accounts_day_84 = df_events_all_accounts_day_84.pivot_table(values='event_count_day_84', columns='event_name', index='systemid', aggfunc=np.sum,  fill_value=0)\n",
    "\n",
    "# Drop the old column name\n",
    "df_events_all_accounts_day_84.columns.name = None\n",
    "\n",
    "# Reset the index\n",
    "df_events_all_accounts_day_84 = df_events_all_accounts_day_84.reset_index()\n",
    "\n",
    "# Replace 'NaN' with zero\n",
    "df_events_all_accounts_day_84.fillna(0, inplace=True)\n",
    "\n",
    "# CSV export \n",
    "df_events_all_accounts_day_84.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/events_new_accounts_day_84.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_events_all_accounts_day_84 = pd.read_csv(\"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_84.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Importing importing features list\n",
    "important_features = pd.read_csv( \n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/important_features.csv\", sep=\"\\n,\")\n",
    "\n",
    "# Get the important feature as a list\n",
    "imp_features_list = list(important_features['important_feature'])\n",
    "\n",
    "# Adding missing important feature column \n",
    "for i in range(len(imp_features_list)):\n",
    "    if imp_features_list[i] in df_events_all_accounts_day_84.columns:\n",
    "        print(\"True\")\n",
    "    else:\n",
    "        print(\"False\")\n",
    "        df_events_all_accounts_day_84[imp_features_list[i]] = 0\n",
    "\n",
    "# Filtering only important features \n",
    "df_events_imp_features_all_accounts_day_84 = \\\n",
    "            df_events_all_accounts_day_84.loc[:, df_events_all_accounts_day_84.columns.str.contains('|'.join(imp_features_list))]\n",
    "\n",
    "\n",
    "### Filtering average word counts features from the invoice data\n",
    "# Invoice features at day 84\n",
    "df_invoice_features_all_accounts_day_84 = df_periodic_invoice_all_counts[[\n",
    "        'systemid',\n",
    "        'admin_email', \n",
    "        'is_sales_managed', \n",
    "        'is_freshbooks_account_active',\n",
    "        'is_paying',\n",
    "        'avg_wc_description_day_84',\n",
    "        'avg_wc_notes_day_84',\n",
    "        'avg_wc_terms_day_84',\n",
    "        'avg_wc_address_day_84',\n",
    "        'invoice_count_day_84',\n",
    "        'client_count_day_84'\n",
    "        ]]\n",
    "\n",
    "# CSV export\n",
    "df_invoice_features_all_accounts_day_84.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/invoice_features_new_accounts_day_84.csv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_invoice_features_all_accounts_day_84 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_84.csv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Merging events' and invoice features\n",
    "df_final_features_day_84 = pd.merge(df_events_imp_features_all_accounts_day_84, \n",
    "                                   df_invoice_features_all_accounts_day_84,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# Filtering final data from the FreshBooks Test emails\n",
    "df_final_features_day_84 = df_final_features_day_84[\n",
    "    df_final_features_day_84.apply(lambda x: email_match(x['admin_email'], fb_test_email_list) > 0.9, axis=1)]\n",
    "\n",
    "# CSV export \n",
    "df_final_features_day_84.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new_final/new_final_features_day_84.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_final_features_day_84 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_84.tsv\", sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20. Final Features Data: Day 91 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Final Features Data: Day 91 Model ###########\n",
    "\n",
    "# Filtered the events columns for day 91 period\n",
    "df_events_all_accounts_day_91 = df_events_all_accounts[['systemid', 'event_count_day_91', 'event_name']]\n",
    "\n",
    "### Pivote the Day 91 Events (Each Unique Event Become a Column)###\n",
    "# Pivot table based on the unique column value in 'event_name'\n",
    "df_events_all_accounts_day_91 = df_events_all_accounts_day_91.pivot_table(values='event_count_day_91', columns='event_name', index='systemid', aggfunc=np.sum,  fill_value=0)\n",
    "\n",
    "# Drop the old column name\n",
    "df_events_all_accounts_day_91.columns.name = None\n",
    "\n",
    "# Reset the index\n",
    "df_events_all_accounts_day_91 = df_events_all_accounts_day_91.reset_index()\n",
    "\n",
    "# Replace 'NaN' with zero\n",
    "df_events_all_accounts_day_91.fillna(0, inplace=True)\n",
    "\n",
    "# CSV export \n",
    "df_events_all_accounts_day_91.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/events_new_accounts_day_91.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_events_all_accounts_day_91 = pd.read_csv(\"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_91.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Importing importing features list\n",
    "important_features = pd.read_csv( \n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/important_features.csv\", sep=\"\\n,\")\n",
    "\n",
    "# Get the important feature as a list\n",
    "imp_features_list = list(important_features['important_feature'])\n",
    "\n",
    "# Adding missing important feature column \n",
    "for i in range(len(imp_features_list)):\n",
    "    if imp_features_list[i] in df_events_all_accounts_day_91.columns:\n",
    "        print(\"True\")\n",
    "    else:\n",
    "        print(\"False\")\n",
    "        df_events_all_accounts_day_91[imp_features_list[i]] = 0\n",
    "\n",
    "# Filtering only important features \n",
    "df_events_imp_features_all_accounts_day_91 = \\\n",
    "            df_events_all_accounts_day_91.loc[:, df_events_all_accounts_day_91.columns.str.contains('|'.join(imp_features_list))]\n",
    "\n",
    "\n",
    "### Filtering average word counts features from the invoice data\n",
    "# Invoice features at day 91\n",
    "df_invoice_features_all_accounts_day_91 = df_periodic_invoice_all_counts[[\n",
    "        'systemid',\n",
    "        'admin_email',\n",
    "        'is_sales_managed', \n",
    "        'is_freshbooks_account_active',\n",
    "        'is_paying',\n",
    "        'avg_wc_description_day_91',\n",
    "        'avg_wc_notes_day_91',\n",
    "        'avg_wc_terms_day_91',\n",
    "        'avg_wc_address_day_91',\n",
    "        'invoice_count_day_91',\n",
    "        'client_count_day_91'\n",
    "        ]]\n",
    "\n",
    "# CSV export\n",
    "df_invoice_features_all_accounts_day_91.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new/invoice_features_new_accounts_day_91.csv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_invoice_features_all_accounts_day_91 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_91.csv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Merging events' and invoice features\n",
    "df_final_features_day_91 = pd.merge(df_events_imp_features_all_accounts_day_91, \n",
    "                                   df_invoice_features_all_accounts_day_91,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# Filtering final data from the FreshBooks Test emails\n",
    "df_final_features_day_91 = df_final_features_day_91[\n",
    "    df_final_features_day_91.apply(lambda x: email_match(x['admin_email'], fb_test_email_list) > 0.9, axis=1)]\n",
    "\n",
    "# CSV export \n",
    "df_final_features_day_91.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_new_final/new_final_features_day_91.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_final_features_day_91 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_91.tsv\", sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
