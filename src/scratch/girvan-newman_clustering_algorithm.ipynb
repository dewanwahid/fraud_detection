{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newman-Girvan Community Detection Algorithm \n",
    "## (Edge Betweenness Centrality Based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from networkx import edge_betweenness_centrality\n",
    "from random import random\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read weighted graph from csv file\n",
    "df = pd.read_csv('/Users/dwahid/Documents/GitHub/fraud_detection/data_networkx/zachary_w.csv')\n",
    "Graphtype = nx.Graph()\n",
    "G = nx.from_pandas_edgelist(df, edge_attr='weight', create_using=Graphtype)\n",
    "# G = nx.from_pandas_edgelist(df, create_using=Graphtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing graph\n",
    "# nx.draw_circular(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Edge list \n",
    "# G.edges.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the nodes list\n",
    "# G.nodes.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G = nx.path_graph(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## Girvan-Newman Algoirthm #############################################\n",
    "\n",
    "_all__ = ['girvan_newman']\n",
    "\n",
    "\n",
    "def girvan_newman(G, most_valuable_edge=None):\n",
    "    \"\"\"Finds communities in a graph using the Girvan–Newman method.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G : NetworkX graph\n",
    "\n",
    "    most_valuable_edge : function\n",
    "        Function that takes a graph as input and outputs an edge. The\n",
    "        edge returned by this function will be recomputed and removed at\n",
    "        each iteration of the algorithm.\n",
    "\n",
    "        If not specified, the edge with the highest\n",
    "        :func:`networkx.edge_betweenness_centrality` will be used.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    iterator\n",
    "        Iterator over tuples of sets of nodes in `G`. Each set of node\n",
    "        is a community, each tuple is a sequence of communities at a\n",
    "        particular level of the algorithm.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    To get the first pair of communities::\n",
    "\n",
    "        >>> G = nx.path_graph(10)\n",
    "        >>> comp = girvan_newman(G)\n",
    "        >>> tuple(sorted(c) for c in next(comp))\n",
    "        ([0, 1, 2, 3, 4], [5, 6, 7, 8, 9])\n",
    "\n",
    "    To get only the first *k* tuples of communities, use\n",
    "    :func:`itertools.islice`::\n",
    "\n",
    "        >>> import itertools\n",
    "        >>> G = nx.path_graph(8)\n",
    "        >>> k = 2\n",
    "        >>> comp = girvan_newman(G)\n",
    "        >>> for communities in itertools.islice(comp, k):\n",
    "        ...     print(tuple(sorted(c) for c in communities)) # doctest: +SKIP\n",
    "        ...\n",
    "        ([0, 1, 2, 3], [4, 5, 6, 7])\n",
    "        ([0, 1], [2, 3], [4, 5, 6, 7])\n",
    "\n",
    "    To stop getting tuples of communities once the number of communities\n",
    "    is greater than *k*, use :func:`itertools.takewhile`::\n",
    "\n",
    "        >>> import itertools\n",
    "        >>> G = nx.path_graph(8)\n",
    "        >>> k = 4\n",
    "        >>> comp = girvan_newman(G)\n",
    "        >>> limited = itertools.takewhile(lambda c: len(c) <= k, comp)\n",
    "        >>> for communities in limited:\n",
    "        ...     print(tuple(sorted(c) for c in communities)) # doctest: +SKIP\n",
    "        ...\n",
    "        ([0, 1, 2, 3], [4, 5, 6, 7])\n",
    "        ([0, 1], [2, 3], [4, 5, 6, 7])\n",
    "        ([0, 1], [2, 3], [4, 5], [6, 7])\n",
    "\n",
    "    To just choose an edge to remove based on the weight::\n",
    "\n",
    "        >>> from operator import itemgetter\n",
    "        >>> G = nx.path_graph(10)\n",
    "        >>> edges = G.edges()\n",
    "        >>> nx.set_edge_attributes(G, {(u, v): v for u, v in edges}, 'weight')\n",
    "        >>> def heaviest(G):\n",
    "        ...     u, v, w = max(G.edges(data='weight'), key=itemgetter(2))\n",
    "        ...     return (u, v)\n",
    "        ...\n",
    "        >>> comp = girvan_newman(G, most_valuable_edge=heaviest)\n",
    "        >>> tuple(sorted(c) for c in next(comp))\n",
    "        ([0, 1, 2, 3, 4, 5, 6, 7, 8], [9])\n",
    "\n",
    "    To utilize edge weights when choosing an edge with, for example, the\n",
    "    highest betweenness centrality::\n",
    "\n",
    "        >>> from networkx import edge_betweenness_centrality as betweenness\n",
    "        >>> def most_central_edge(G):\n",
    "        ...     centrality = betweenness(G, weight='weight')\n",
    "        ...     return max(centrality, key=centrality.get)\n",
    "        ...\n",
    "        >>> G = nx.path_graph(10)\n",
    "        >>> comp = girvan_newman(G, most_valuable_edge=most_central_edge)\n",
    "        >>> tuple(sorted(c) for c in next(comp))\n",
    "        ([0, 1, 2, 3, 4], [5, 6, 7, 8, 9])\n",
    "\n",
    "    To specify a different ranking algorithm for edges, use the\n",
    "    `most_valuable_edge` keyword argument::\n",
    "\n",
    "        >>> from networkx import edge_betweenness_centrality\n",
    "        >>> from random import random\n",
    "        >>> def most_central_edge(G):\n",
    "        ...     centrality = edge_betweenness_centrality(G)\n",
    "        ...     max_cent = max(centrality.values())\n",
    "        ...     # Scale the centrality values so they are between 0 and 1,\n",
    "        ...     # and add some random noise.\n",
    "        ...     centrality = {e: c / max_cent for e, c in centrality.items()}\n",
    "        ...     # Add some random noise.\n",
    "        ...     centrality = {e: c + random() for e, c in centrality.items()}\n",
    "        ...     return max(centrality, key=centrality.get)\n",
    "        ...\n",
    "        >>> G = nx.path_graph(10)\n",
    "        >>> comp = girvan_newman(G, most_valuable_edge=most_central_edge)\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The Girvan–Newman algorithm detects communities by progressively\n",
    "    removing edges from the original graph. The algorithm removes the\n",
    "    \"most valuable\" edge, traditionally the edge with the highest\n",
    "    betweenness centrality, at each step. As the graph breaks down into\n",
    "    pieces, the tightly knit community structure is exposed and the\n",
    "    result can be depicted as a dendrogram.\n",
    "\n",
    "    \"\"\"\n",
    "    # If the graph is already empty, simply return its connected\n",
    "    # components.\n",
    "    if G.number_of_edges() == 0:\n",
    "        yield tuple(nx.connected_components(G))\n",
    "        return\n",
    "    # If no function is provided for computing the most valuable edge,\n",
    "    # use the edge betweenness centrality.\n",
    "    if most_valuable_edge is None:\n",
    "        def most_valuable_edge(G):\n",
    "            \"\"\"Returns the edge with the highest betweenness centrality\n",
    "            in the graph `G`.\n",
    "\n",
    "            \"\"\"\n",
    "            # We have guaranteed that the graph is non-empty, so this\n",
    "            # dictionary will never be empty.\n",
    "            betweenness = nx.edge_betweenness_centrality(G)\n",
    "            return max(betweenness, key=betweenness.get)\n",
    "    # The copy of G here must include the edge weight data.\n",
    "    g = G.copy().to_undirected()\n",
    "    # Self-loops must be removed because their removal has no effect on\n",
    "    # the connected components of the graph.\n",
    "    g.remove_edges_from(nx.selfloop_edges(g))\n",
    "    while g.number_of_edges() > 0:\n",
    "        yield _without_most_central_edges(g, most_valuable_edge)\n",
    "\n",
    "\n",
    "\n",
    "def _without_most_central_edges(G, most_valuable_edge):\n",
    "    \"\"\"Returns the connected components of the graph that results from\n",
    "    repeatedly removing the most \"valuable\" edge in the graph.\n",
    "\n",
    "    `G` must be a non-empty graph. This function modifies the graph `G`\n",
    "    in-place; that is, it removes edges on the graph `G`.\n",
    "\n",
    "    `most_valuable_edge` is a function that takes the graph `G` as input\n",
    "    (or a subgraph with one or more edges of `G` removed) and returns an\n",
    "    edge. That edge will be removed and this process will be repeated\n",
    "    until the number of connected components in the graph increases.\n",
    "\n",
    "    \"\"\"\n",
    "    original_num_components = nx.number_connected_components(G)\n",
    "    num_new_components = original_num_components\n",
    "    while num_new_components <= original_num_components:\n",
    "        edge = most_valuable_edge(G)\n",
    "        G.remove_edge(*edge)\n",
    "        new_components = tuple(nx.connected_components(G))\n",
    "        num_new_components = len(new_components)\n",
    "    return new_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ Girvan-Newman Clustering Using Edge Centrality ######################################\n",
    "\n",
    "# The weighted betweenness centrality of each edges\n",
    "def most_central_edge(G):\n",
    "    centrality = edge_betweenness_centrality(G)\n",
    "    max_cent = max(centrality.values())\n",
    "\n",
    "    # Scale the centrality values so they are between 0 and 1,\n",
    "    # and add some random noise.\n",
    "    centrality = {e: c / max_cent for e, c in centrality.items()}\n",
    "\n",
    "    # Add some random noise.\n",
    "    centrality = {e: c + random() for e, c in centrality.items()}\n",
    "    return max(centrality, key=centrality.get)\n",
    "\n",
    "# Newman-Girvan clustering\n",
    "comp = girvan_newman(G, most_valuable_edge=most_central_edge)\n",
    "\n",
    "\n",
    "# Printing communities\n",
    "communities = tuple(sorted(c) for c in next(comp))\n",
    "\n",
    "\n",
    "################################### Write Clusters in the CSV file ############################################\n",
    "\n",
    "# Output file\n",
    "output_file = open('/Users/dwahid/Documents/GitHub/fraud_detection/data_networkx/nodes_clusters_edgebetw.csv','w')\n",
    "output_file2 = open('/Users/dwahid/Documents/GitHub/fraud_detection/data_networkx/nodes_clusters_size_edgebetw.csv','w')\n",
    "\n",
    "# Write heading to the output file\n",
    "output_file.write('node,cluster_id \\n')\n",
    "output_file2.write('cluster_id,size \\n')\n",
    "\n",
    "# Total number of clusters/communities\n",
    "L = len(communities)\n",
    "\n",
    "# Iterate through each element of the \n",
    "for i in range(0, L): \n",
    "    \n",
    "    # the i-th cluster\n",
    "    cls_i = communities[i]\n",
    "    len_cls_i = len(cls_i) # length of this cluster\n",
    "    \n",
    "    # writing cluster id and it's corresponding size\n",
    "    output_file2.write(str(i) + ',' + str(len_cls_i) + '\\n')\n",
    "\n",
    "    # writing each node in i-th cluster and their corresponding cluster id\n",
    "    for j in range(0, len_cls_i):\n",
    "        \n",
    "        # j-the node in the i-th cluster\n",
    "        node = cls_i[j] \n",
    "        \n",
    "        # write the node in the output file\n",
    "        output_file.write(str(node) + ',' + str(i) + '\\n')\n",
    "\n",
    "# closing the output files\n",
    "output_file.close()\n",
    "output_file2.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ Girvan-Newman Clustering Using Edge Weight ######################################\n",
    "\n",
    "# The weighted betweenness centrality of each edges\n",
    "def min_weight(G):\n",
    "    u, v, w = min(G.edges(data='weight'), key=itemgetter(2))\n",
    "    return (u, v)\n",
    "\n",
    "# Girvan-newman clustering\n",
    "comp = girvan_newman(G, most_valuable_edge=min_weight)\n",
    "\n",
    "# Printing communities\n",
    "communities = tuple(sorted(c) for c in next(comp))\n",
    "\n",
    "\n",
    "################################### Write Clusters in the CSV file3 ############################################\n",
    "\n",
    "# Output file3\n",
    "output_file3 = open('/Users/dwahid/Documents/GitHub/fraud_detection/data_networkx/nodes_clusters_edgeweight.csv','w')\n",
    "output_file4 = open('/Users/dwahid/Documents/GitHub/fraud_detection/data_networkx/nodes_clusters_size_edgeweight.csv','w')\n",
    "\n",
    "# Write heading to the output file3\n",
    "output_file3.write('node,cluster_id \\n')\n",
    "output_file4.write('cluster_id,size \\n')\n",
    "\n",
    "# Total number of clusters/communities\n",
    "L = len(communities)\n",
    "\n",
    "# Iterate through each element of the \n",
    "for i in range(0, L): \n",
    "    \n",
    "    # the i-th cluster\n",
    "    cls_i = communities[i]\n",
    "    len_cls_i = len(cls_i) # length of this cluster\n",
    "    \n",
    "    # writing cluster id and it's corresponding size\n",
    "    output_file4.write(str(i) + ',' + str(len_cls_i) + '\\n')\n",
    "\n",
    "    # writing each node in i-th cluster and their corresponding cluster id\n",
    "    for j in range(0, len_cls_i):\n",
    "        \n",
    "        # j-the node in the i-th cluster\n",
    "        node = cls_i[j] \n",
    "        \n",
    "        # write the node in the output file3\n",
    "        output_file3.write(str(node) + ',' + str(i) + '\\n')\n",
    "\n",
    "# closing the output file3s\n",
    "output_file3.close()\n",
    "output_file4.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
