{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Counts: Periodic Invoices - All Accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from scipy import stats\n",
    "get_ipython().magic(u'config IPCompleter.greedy=True')\n",
    "\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install simplejson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect with the Redshift Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import closing\n",
    "\n",
    "\n",
    "import psycopg2\n",
    "import simplejson\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')\n",
    "\n",
    "DEFAULT_DB = 'data_depot'\n",
    "DEFAULT_HOST = 'freshbooks-data.c8exzn6geij3.us-east-1.redshift.amazonaws.com'\n",
    "DEFAULT_PORT = 5439\n",
    "\n",
    "\n",
    "class PsycopgConnector:\n",
    "    '''\n",
    "    A database connector that uses Psycopg to connect to Redshift.\n",
    "\n",
    "    How to play:\n",
    "\n",
    "        psy_conn = PsycopgConnector(username, password)\n",
    "        df = psy_conn.run_query(sql=sql, return_data=True)\n",
    "\n",
    "    NOTE: This class commits queries to redshift if return_data=False.\n",
    "    This means INSERT, DROP, TRUNCATE, etc. all work against the DB.\n",
    "    '''\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        username=None,\n",
    "        password=None,\n",
    "        db=DEFAULT_DB,\n",
    "        host=DEFAULT_HOST,\n",
    "        port=DEFAULT_PORT,\n",
    "    ):\n",
    "\n",
    "        self.db = DEFAULT_DB\n",
    "        self.host = DEFAULT_HOST\n",
    "        self.port = DEFAULT_PORT\n",
    "\n",
    "        self.username = username\n",
    "        self.password = password\n",
    "\n",
    "    def _get_connection(self):\n",
    "\n",
    "        self.conn = psycopg2.connect(\n",
    "            dbname=self.db,\n",
    "            user=self.username,\n",
    "            password=self.password,\n",
    "            host=self.host,\n",
    "            port=self.port\n",
    "        )\n",
    "\n",
    "        return self.conn\n",
    "\n",
    "    def run_query(self, sql, return_data=False):\n",
    "\n",
    "        with closing(self._get_connection()) as conn:\n",
    "            with conn, conn.cursor() as cur:\n",
    "                if return_data:\n",
    "                    return pd.read_sql(sql=sql, con=conn)\n",
    "                else:\n",
    "                    cur.execute(sql)\n",
    "                    \n",
    "\n",
    "# Read the Redshift's credentials file \n",
    "with open(\"redshift_creds.json.nogit\") as fh:\n",
    "    creds = simplejson.loads(fh.read())\n",
    "    \n",
    "username = creds.get(\"user_name\")\n",
    "password = creds.get(\"password\")\n",
    "\n",
    "pig = PsycopgConnector(username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing connection\n",
    "sql_test = '''SELECT * FROM report_systems LIMIT 5'''\n",
    "df_test = pig.run_query(sql_test, return_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>systemid</th>\n",
       "      <th>business_id</th>\n",
       "      <th>admin_identity_id</th>\n",
       "      <th>subdomain</th>\n",
       "      <th>is_freshbooks_account_active</th>\n",
       "      <th>is_modern</th>\n",
       "      <th>most_recent_migrated_to_smux_at</th>\n",
       "      <th>is_contractor</th>\n",
       "      <th>currency_code</th>\n",
       "      <th>timezone</th>\n",
       "      <th>...</th>\n",
       "      <th>staff_count</th>\n",
       "      <th>staff_deleted_count</th>\n",
       "      <th>contractor_count</th>\n",
       "      <th>contractor_deleted_count</th>\n",
       "      <th>user_contact_count</th>\n",
       "      <th>enabled_gateway_count</th>\n",
       "      <th>google_sso_first_linked_date</th>\n",
       "      <th>google_sso_most_recent_linked_date</th>\n",
       "      <th>google_sso_first_removal_date</th>\n",
       "      <th>google_sso_most_recent_removal_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://BluefuseTechnology.freshbooks.com</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>CAD</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://jeffgmck.freshbooks.com</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>USD</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4222</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://msol.freshbooks.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Europe/London</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6624</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://loricae.freshbooks.com</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>USD</td>\n",
       "      <td>US/Central</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7736</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://members.billingarm.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>USD</td>\n",
       "      <td>Asia/Kolkata</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   systemid business_id admin_identity_id  \\\n",
       "0        23        None              None   \n",
       "1       103        None              None   \n",
       "2      4222        None              None   \n",
       "3      6624        None              None   \n",
       "4      7736        None              None   \n",
       "\n",
       "                                   subdomain  is_freshbooks_account_active  \\\n",
       "0  https://BluefuseTechnology.freshbooks.com                             1   \n",
       "1            https://jeffgmck.freshbooks.com                             1   \n",
       "2                https://msol.freshbooks.com                             0   \n",
       "3             https://loricae.freshbooks.com                             1   \n",
       "4             https://members.billingarm.com                             0   \n",
       "\n",
       "   is_modern most_recent_migrated_to_smux_at  is_contractor currency_code  \\\n",
       "0          0                            None              0           CAD   \n",
       "1          0                            None              0           USD   \n",
       "2          0                            None              0           EUR   \n",
       "3          0                            None              1           USD   \n",
       "4          0                            None              0           USD   \n",
       "\n",
       "        timezone  ...  staff_count staff_deleted_count contractor_count  \\\n",
       "0     US/Eastern  ...            0                   0                0   \n",
       "1     US/Eastern  ...            0                   0                0   \n",
       "2  Europe/London  ...            0                   0                0   \n",
       "3     US/Central  ...            0                   0                4   \n",
       "4   Asia/Kolkata  ...            0                   0                0   \n",
       "\n",
       "  contractor_deleted_count user_contact_count enabled_gateway_count  \\\n",
       "0                        0                  0                     0   \n",
       "1                        0                  0                     1   \n",
       "2                        0                  0                     1   \n",
       "3                        0                  9                     1   \n",
       "4                        0                  0                     1   \n",
       "\n",
       "  google_sso_first_linked_date google_sso_most_recent_linked_date  \\\n",
       "0                         None                               None   \n",
       "1                         None                               None   \n",
       "2                         None                               None   \n",
       "3                         None                               None   \n",
       "4                         None                               None   \n",
       "\n",
       "  google_sso_first_removal_date google_sso_most_recent_removal_date  \n",
       "0                          None                                None  \n",
       "1                          None                                None  \n",
       "2                          None                                None  \n",
       "3                          None                                None  \n",
       "4                          None                                None  \n",
       "\n",
       "[5 rows x 132 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word count fuction\n",
    "import re\n",
    "def words_count (strg):\n",
    "    \n",
    "    #print(strg)\n",
    "    \n",
    "    if strg == '' or pd.isnull(strg):\n",
    "        no_of_words = 0\n",
    "        #print('NaN')\n",
    "    else:\n",
    "        strg_words_list = re.findall(r\"[\\w']+\", strg)\n",
    "        no_of_words = len(strg_words_list)\n",
    "\n",
    "        \n",
    "        #print(strg_words_list)\n",
    "    \n",
    "    return no_of_words \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Invoice Data & Extract Avg Word Counts Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.01 Invoice within 7 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL for impoorting all invoices created within 7 days after signup_date\n",
    "sql_invoices_7days_all_accounts = '''WITH invoices_in_a_period AS (\n",
    "    SELECT \n",
    "            systemid, \n",
    "            signup_date\n",
    "    FROM report_systems rs\n",
    "    WHERE signup_date BETWEEN '2018-08-01' and '2019-07-30'\n",
    "), invoice_created_at AS (\n",
    "    SELECT\n",
    "           pic.systemid,\n",
    "           pic.signup_date,\n",
    "           inv.invoiceid,\n",
    "           inv.create_date,\n",
    "           inv.created_at,\n",
    "           inv.description,\n",
    "           inv.notes,\n",
    "           inv.terms,\n",
    "           inv.address,\n",
    "           DATEDIFF(days, pic.signup_date, inv.created_at) AS days_to_invoice_creation\n",
    "    FROM invoices_in_a_period AS pic\n",
    "    LEFT JOIN coalesced_live_shards.invoice_stable as inv USING (systemid)\n",
    "    WHERE ((days_to_invoice_creation BETWEEN 0 AND 7) OR days_to_invoice_creation IS NULL)\n",
    ")\n",
    "\n",
    "SELECT *\n",
    "FROM invoice_created_at;'''\n",
    "\n",
    "# Import as dataframe from redshift\n",
    "# df_invoices_7days_all_accounts = pd.read_sql_query(sql_invoices_7days_all_accounts, connect_to_db)\n",
    "df_invoices_7days_all_accounts = pig.run_query(sql_invoices_7days_all_accounts, return_data=True)\n",
    "\n",
    "\n",
    "# Words count in invoice's description, notes, terms, address\n",
    "df_invoices_7days_all_accounts['avg_wc_description_day_7'] = df_invoices_7days_all_accounts.apply(lambda x: words_count(x['description']), axis=1)\n",
    "df_invoices_7days_all_accounts['avg_wc_notes_day_7'] = df_invoices_7days_all_accounts.apply(lambda x: words_count(x['notes']), axis=1)\n",
    "df_invoices_7days_all_accounts['avg_wc_terms_day_7'] = df_invoices_7days_all_accounts.apply(lambda x: words_count(x['terms']), axis=1)\n",
    "df_invoices_7days_all_accounts['avg_wc_address_day_7'] = df_invoices_7days_all_accounts.apply(lambda x: words_count(x['address']), axis=1)\n",
    "\n",
    "                                                                                                                   \n",
    "# Filters the text columns from the dataframe\n",
    "df_invoices_7days_all_accounts_fil = df_invoices_7days_all_accounts.filter(['systemid', \n",
    "                                                                            'invoiceid', \n",
    "                                                                            'signup_date', \n",
    "                                                                            'create_date', \n",
    "                                                                            'created_at',\n",
    "                                                                            'days_to_invoice_creation', \n",
    "                                                                            'avg_wc_description_day_7', \n",
    "                                                                            'avg_wc_notes_day_7', \n",
    "                                                                            'avg_wc_terms_day_7',\n",
    "                                                                            'avg_wc_address_day_7'])  \n",
    "                                                                                                                   \n",
    "# Summing (grouping) all invoices for a 'systemid'\n",
    "df_word_count_7days_all_accounts_total = df_invoices_7days_all_accounts_fil.groupby('systemid').mean()  \n",
    "\n",
    "# Final word count table\n",
    "df_word_count_7days_all_accounts_final = df_word_count_7days_all_accounts_total.filter(['systemid',\n",
    "                                                                            'avg_wc_description_day_7', \n",
    "                                                                            'avg_wc_notes_day_7', \n",
    "                                                                            'avg_wc_terms_day_7',\n",
    "                                                                            'avg_wc_address_day_7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Export as csv file\n",
    "df_word_count_7days_all_accounts_final.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/df_word_count_7days_all_accounts_final.tsv\", \n",
    "                                      sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Invoice within 14 days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL for impoorting all invoices created within 14 days after signup_date\n",
    "sql_invoices_14days_all_accounts = '''WITH invoices_in_a_period AS (\n",
    "    SELECT systemid, signup_date\n",
    "    FROM report_systems rs\n",
    "    WHERE signup_date BETWEEN '2018-08-01' and '2019-07-30'\n",
    "), invoice_created_at AS (\n",
    "    SELECT\n",
    "           pic.systemid,\n",
    "           inv.invoiceid,\n",
    "           pic.signup_date,\n",
    "           inv.create_date,\n",
    "           inv.created_at,\n",
    "           inv.description,\n",
    "           inv.notes,\n",
    "           inv.terms,\n",
    "           inv.address,\n",
    "           DATEDIFF(days, pic.signup_date, inv.created_at) AS days_to_invoice_creation\n",
    "    FROM invoices_in_a_period AS pic\n",
    "    LEFT JOIN coalesced_live_shards.invoice_stable as inv USING (systemid)\n",
    "    WHERE ((days_to_invoice_creation BETWEEN 0 AND 14) OR days_to_invoice_creation IS NULL)\n",
    ")\n",
    "\n",
    "SELECT *\n",
    "FROM invoice_created_at;'''\n",
    "\n",
    "# Import as dataframe from redshift\n",
    "# df_invoices_14days_all_accounts = pd.read_sql_query(sql_invoices_14days_all_accounts, connect_to_db)\n",
    "df_invoices_14days_all_accounts = pig.run_query(sql_invoices_14days_all_accounts, return_data=True)\n",
    "\n",
    "\n",
    "# Words count in invoice's description, notes, terms, address\n",
    "df_invoices_14days_all_accounts['avg_wc_description_day_14'] = df_invoices_14days_all_accounts.apply(lambda x: words_count(x['description']), axis=1)\n",
    "df_invoices_14days_all_accounts['avg_wc_notes_day_14'] = df_invoices_14days_all_accounts.apply(lambda x: words_count(x['notes']), axis=1)\n",
    "df_invoices_14days_all_accounts['avg_wc_terms_day_14'] = df_invoices_14days_all_accounts.apply(lambda x: words_count(x['terms']), axis=1)\n",
    "df_invoices_14days_all_accounts['avg_wc_address_day_14'] = df_invoices_14days_all_accounts.apply(lambda x: words_count(x['address']), axis=1)\n",
    "\n",
    "                                                                                                                   \n",
    "# Filters the text columns from the dataframe\n",
    "df_invoices_14days_all_accounts_fil = df_invoices_14days_all_accounts.filter(['systemid', 'invoiceid', \n",
    "                                                                            'signup_date', \n",
    "                                                                            'create_date', \n",
    "                                                                            'created_at',\n",
    "                                                                            'days_to_invoice_creation', \n",
    "                                                                            'avg_wc_description_day_14', \n",
    "                                                                            'avg_wc_notes_day_14', \n",
    "                                                                            'avg_wc_terms_day_14',\n",
    "                                                                            'avg_wc_address_day_14'])  \n",
    "                                                                                                                   \n",
    "# Summing (grouping) all invoices for a 'systemid'\n",
    "df_word_count_14days_all_accounts_total = df_invoices_14days_all_accounts_fil.groupby('systemid').mean()  \n",
    "\n",
    "# Final word count table\n",
    "df_word_count_14days_all_accounts_final = df_word_count_14days_all_accounts_total.filter(['systemid',\n",
    "                                                                            'avg_wc_description_day_14', \n",
    "                                                                            'avg_wc_notes_day_14', \n",
    "                                                                            'avg_wc_terms_day_14',\n",
    "                                                                            'avg_wc_address_day_14'])\n",
    "\n",
    "# Export as csv file\n",
    "df_word_count_14days_all_accounts_final.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/df_word_count_14days_all_accounts_final.tsv\", \n",
    "                                      sep=\"\\t\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_wc_description_day_14</th>\n",
       "      <th>avg_wc_notes_day_14</th>\n",
       "      <th>avg_wc_terms_day_14</th>\n",
       "      <th>avg_wc_address_day_14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systemid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3592461</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592463</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592465</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592467</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592469</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          avg_wc_description_day_14  avg_wc_notes_day_14  avg_wc_terms_day_14  \\\n",
       "systemid                                                                        \n",
       "3592461                         2.0                  6.0                  0.0   \n",
       "3592463                         0.0                  0.0                  0.0   \n",
       "3592465                         0.0                  0.0                  0.0   \n",
       "3592467                         0.0                  0.0                  0.0   \n",
       "3592469                         0.0                  0.0                  0.0   \n",
       "\n",
       "          avg_wc_address_day_14  \n",
       "systemid                         \n",
       "3592461                     0.0  \n",
       "3592463                     0.0  \n",
       "3592465                     0.0  \n",
       "3592467                     0.0  \n",
       "3592469                     0.0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_count_14days_all_accounts_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Invoice within 21 days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL for impoorting all invoices created within 21 days after signup_date\n",
    "sql_invoices_21days_all_accounts = '''WITH invoices_in_a_period AS (\n",
    "    SELECT systemid, signup_date\n",
    "    FROM report_systems rs\n",
    "    WHERE signup_date BETWEEN '2018-08-01' and '2019-07-30'\n",
    "), invoice_created_at AS (\n",
    "    SELECT\n",
    "           pic.systemid,\n",
    "           inv.invoiceid,\n",
    "           pic.signup_date,\n",
    "           inv.create_date,\n",
    "           inv.created_at,\n",
    "           inv.description,\n",
    "           inv.notes,\n",
    "           inv.terms,\n",
    "           inv.address,\n",
    "           DATEDIFF(days, pic.signup_date, inv.created_at) AS days_to_invoice_creation\n",
    "    FROM invoices_in_a_period AS pic\n",
    "    LEFT JOIN coalesced_live_shards.invoice_stable as inv USING (systemid)\n",
    "    WHERE ((days_to_invoice_creation BETWEEN 0 AND 21) OR days_to_invoice_creation IS NULL)\n",
    ")\n",
    "\n",
    "SELECT *\n",
    "FROM invoice_created_at;'''\n",
    "\n",
    "# Import as dataframe from redshift\n",
    "df_invoices_21days_all_accounts = pig.run_query(sql_invoices_21days_all_accounts, return_data=True)\n",
    "\n",
    "# Words count in invoice's description, notes, terms, address\n",
    "df_invoices_21days_all_accounts['avg_wc_description_day_21'] = df_invoices_21days_all_accounts.apply(lambda x: words_count(x['description']), axis=1)\n",
    "df_invoices_21days_all_accounts['avg_wc_notes_day_21'] = df_invoices_21days_all_accounts.apply(lambda x: words_count(x['notes']), axis=1)\n",
    "df_invoices_21days_all_accounts['avg_wc_terms_day_21'] = df_invoices_21days_all_accounts.apply(lambda x: words_count(x['terms']), axis=1)\n",
    "df_invoices_21days_all_accounts['avg_wc_address_day_21'] = df_invoices_21days_all_accounts.apply(lambda x: words_count(x['address']), axis=1)\n",
    "\n",
    "                                                                                                                   \n",
    "# Filters the text columns from the dataframe\n",
    "df_invoices_21days_all_accounts_fil = df_invoices_21days_all_accounts.filter(['systemid', 'invoiceid', \n",
    "                                                                            'signup_date', \n",
    "                                                                            'create_date', \n",
    "                                                                            'created_at',\n",
    "                                                                            'days_to_invoice_creation', \n",
    "                                                                            'avg_wc_description_day_21', \n",
    "                                                                            'avg_wc_notes_day_21', \n",
    "                                                                            'avg_wc_terms_day_21',\n",
    "                                                                            'avg_wc_address_day_21'])  \n",
    "                                                                                                                   \n",
    "# Summing (grouping) all invoices for a 'systemid'\n",
    "df_word_count_21days_all_accounts_total = df_invoices_21days_all_accounts_fil.groupby('systemid').mean()  \n",
    "\n",
    "# Final word count table\n",
    "df_word_count_21days_all_accounts_final = df_word_count_21days_all_accounts_total.filter(['systemid',\n",
    "                                                                            'avg_wc_description_day_21', \n",
    "                                                                            'avg_wc_notes_day_21', \n",
    "                                                                            'avg_wc_terms_day_21',\n",
    "                                                                            'avg_wc_address_day_21'])\n",
    "\n",
    "# Export as csv file\n",
    "df_word_count_21days_all_accounts_final.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/df_word_count_21days_all_accounts_final.tsv\", \n",
    "                                      sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_wc_description_day_21</th>\n",
       "      <th>avg_wc_notes_day_21</th>\n",
       "      <th>avg_wc_terms_day_21</th>\n",
       "      <th>avg_wc_address_day_21</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systemid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3592461</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592463</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592465</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592467</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592469</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          avg_wc_description_day_21  avg_wc_notes_day_21  avg_wc_terms_day_21  \\\n",
       "systemid                                                                        \n",
       "3592461                         2.0                  6.0                  0.0   \n",
       "3592463                         0.0                  0.0                  0.0   \n",
       "3592465                         0.0                  0.0                  0.0   \n",
       "3592467                         0.0                  0.0                  0.0   \n",
       "3592469                         0.0                  0.0                  0.0   \n",
       "\n",
       "          avg_wc_address_day_21  \n",
       "systemid                         \n",
       "3592461                     0.0  \n",
       "3592463                     0.0  \n",
       "3592465                     0.0  \n",
       "3592467                     0.0  \n",
       "3592469                     0.0  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_count_21days_all_accounts_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Invoice within 28 days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL for impoorting all invoices created within 28 days after signup_date\n",
    "sql_invoices_28days_all_accounts = '''WITH invoices_in_a_period AS (\n",
    "    SELECT systemid, signup_date\n",
    "    FROM report_systems rs\n",
    "    WHERE signup_date BETWEEN '2018-08-01' and '2019-07-30'\n",
    "), invoice_created_at AS (\n",
    "    SELECT\n",
    "           pic.systemid,\n",
    "           inv.invoiceid,\n",
    "           pic.signup_date,\n",
    "           inv.create_date,\n",
    "           inv.created_at,\n",
    "           inv.description,\n",
    "           inv.notes,\n",
    "           inv.terms,\n",
    "           inv.address,\n",
    "           DATEDIFF(days, pic.signup_date, inv.created_at) AS days_to_invoice_creation\n",
    "    FROM invoices_in_a_period AS pic\n",
    "    LEFT JOIN coalesced_live_shards.invoice_stable as inv USING (systemid)\n",
    "    WHERE ((days_to_invoice_creation BETWEEN 0 AND 28) OR days_to_invoice_creation IS NULL)\n",
    ")\n",
    "\n",
    "SELECT *\n",
    "FROM invoice_created_at;'''\n",
    "\n",
    "# Import as dataframe from redshift\n",
    "df_invoices_28days_all_accounts = pig.run_query(sql_invoices_28days_all_accounts, return_data=True)\n",
    "\n",
    "# Words count in invoice's description, notes, terms, address\n",
    "df_invoices_28days_all_accounts['avg_wc_description_day_28'] = df_invoices_28days_all_accounts.apply(lambda x: words_count(x['description']), axis=1)\n",
    "df_invoices_28days_all_accounts['avg_wc_notes_day_28'] = df_invoices_28days_all_accounts.apply(lambda x: words_count(x['notes']), axis=1)\n",
    "df_invoices_28days_all_accounts['avg_wc_terms_day_28'] = df_invoices_28days_all_accounts.apply(lambda x: words_count(x['terms']), axis=1)\n",
    "df_invoices_28days_all_accounts['avg_wc_address_day_28'] = df_invoices_28days_all_accounts.apply(lambda x: words_count(x['address']), axis=1)\n",
    "\n",
    "                                                                                                                   \n",
    "# Filters the text columns from the dataframe\n",
    "df_invoices_28days_all_accounts_fil = df_invoices_28days_all_accounts.filter(['systemid', 'invoiceid', \n",
    "                                                                            'signup_date', \n",
    "                                                                            'create_date', \n",
    "                                                                            'created_at',\n",
    "                                                                            'days_to_invoice_creation', \n",
    "                                                                            'avg_wc_description_day_28', \n",
    "                                                                            'avg_wc_notes_day_28', \n",
    "                                                                            'avg_wc_terms_day_28',\n",
    "                                                                            'avg_wc_address_day_28'])  \n",
    "                                                                                                                   \n",
    "# Summing (grouping) all invoices for a 'systemid'\n",
    "df_word_count_28days_all_accounts_total = df_invoices_28days_all_accounts_fil.groupby('systemid').mean()  \n",
    "\n",
    "# Final word count table\n",
    "df_word_count_28days_all_accounts_final = df_word_count_28days_all_accounts_total.filter(['systemid',\n",
    "                                                                            'avg_wc_description_day_28', \n",
    "                                                                            'avg_wc_notes_day_28', \n",
    "                                                                            'avg_wc_terms_day_28',\n",
    "                                                                            'avg_wc_address_day_28'])\n",
    "\n",
    "# Export as csv file\n",
    "df_word_count_28days_all_accounts_final.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/df_word_count_28days_all_accounts_final.tsv\", \n",
    "                                      sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_wc_description_day_28</th>\n",
       "      <th>avg_wc_notes_day_28</th>\n",
       "      <th>avg_wc_terms_day_28</th>\n",
       "      <th>avg_wc_address_day_28</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systemid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3592461</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592463</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592465</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592467</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592469</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          avg_wc_description_day_28  avg_wc_notes_day_28  avg_wc_terms_day_28  \\\n",
       "systemid                                                                        \n",
       "3592461                         2.0                  6.0                  0.0   \n",
       "3592463                         0.0                  0.0                  0.0   \n",
       "3592465                         0.0                  0.0                  0.0   \n",
       "3592467                         0.0                  0.0                  0.0   \n",
       "3592469                         0.0                  0.0                  0.0   \n",
       "\n",
       "          avg_wc_address_day_28  \n",
       "systemid                         \n",
       "3592461                     0.0  \n",
       "3592463                     0.0  \n",
       "3592465                     0.0  \n",
       "3592467                     0.0  \n",
       "3592469                     0.0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_count_28days_all_accounts_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Invoice within 35 days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL for impoorting all invoices created within 35 days after signup_date\n",
    "sql_invoices_35days_all_accounts = '''WITH invoices_in_a_period AS (\n",
    "    SELECT systemid, signup_date\n",
    "    FROM report_systems rs\n",
    "    WHERE signup_date BETWEEN '2018-08-01' and '2019-07-30'\n",
    "), invoice_created_at AS (\n",
    "    SELECT\n",
    "           pic.systemid,\n",
    "           inv.invoiceid,\n",
    "           pic.signup_date,\n",
    "           inv.create_date,\n",
    "           inv.created_at,\n",
    "           inv.description,\n",
    "           inv.notes,\n",
    "           inv.terms,\n",
    "           inv.address,\n",
    "           DATEDIFF(days, pic.signup_date, inv.created_at) AS days_to_invoice_creation\n",
    "    FROM invoices_in_a_period AS pic\n",
    "    LEFT JOIN coalesced_live_shards.invoice_stable as inv USING (systemid)\n",
    "    WHERE ((days_to_invoice_creation BETWEEN 0 AND 35) OR days_to_invoice_creation IS NULL)\n",
    ")\n",
    "\n",
    "SELECT *\n",
    "FROM invoice_created_at;'''\n",
    "\n",
    "# Import as dataframe from redshift\n",
    "df_invoices_35days_all_accounts = pig.run_query(sql_invoices_35days_all_accounts, return_data=True)\n",
    "\n",
    "# Words count in invoice's description, notes, terms, address\n",
    "df_invoices_35days_all_accounts['avg_wc_description_day_35'] = df_invoices_35days_all_accounts.apply(lambda x: words_count(x['description']), axis=1)\n",
    "df_invoices_35days_all_accounts['avg_wc_notes_day_35'] = df_invoices_35days_all_accounts.apply(lambda x: words_count(x['notes']), axis=1)\n",
    "df_invoices_35days_all_accounts['avg_wc_terms_day_35'] = df_invoices_35days_all_accounts.apply(lambda x: words_count(x['terms']), axis=1)\n",
    "df_invoices_35days_all_accounts['avg_wc_address_day_35'] = df_invoices_35days_all_accounts.apply(lambda x: words_count(x['address']), axis=1)\n",
    "\n",
    "                                                                                                                   \n",
    "# Filters the text columns from the dataframe\n",
    "df_invoices_35days_all_accounts_fil = df_invoices_35days_all_accounts.filter(['systemid', 'invoiceid', \n",
    "                                                                            'signup_date', \n",
    "                                                                            'create_date', \n",
    "                                                                            'created_at',\n",
    "                                                                            'days_to_invoice_creation', \n",
    "                                                                            'avg_wc_description_day_35', \n",
    "                                                                            'avg_wc_notes_day_35', \n",
    "                                                                            'avg_wc_terms_day_35',\n",
    "                                                                            'avg_wc_address_day_35'])  \n",
    "                                                                                                                   \n",
    "# Summing (grouping) all invoices for a 'systemid'\n",
    "df_word_count_35days_all_accounts_total = df_invoices_35days_all_accounts_fil.groupby('systemid').mean()  \n",
    "\n",
    "# Final word count table\n",
    "df_word_count_35days_all_accounts_final = df_word_count_35days_all_accounts_total.filter(['systemid',\n",
    "                                                                            'avg_wc_description_day_35', \n",
    "                                                                            'avg_wc_notes_day_35', \n",
    "                                                                            'avg_wc_terms_day_35',\n",
    "                                                                            'avg_wc_address_day_35'])\n",
    "\n",
    "# Export as csv file\n",
    "df_word_count_35days_all_accounts_final.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/df_word_count_35days_all_accounts_final.tsv\", \n",
    "                                      sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_wc_description_day_35</th>\n",
       "      <th>avg_wc_notes_day_35</th>\n",
       "      <th>avg_wc_terms_day_35</th>\n",
       "      <th>avg_wc_address_day_35</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systemid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3592461</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592463</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592465</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592467</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592469</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          avg_wc_description_day_35  avg_wc_notes_day_35  avg_wc_terms_day_35  \\\n",
       "systemid                                                                        \n",
       "3592461                         2.0                  6.0                  0.0   \n",
       "3592463                         0.0                  0.0                  0.0   \n",
       "3592465                         0.0                  0.0                  0.0   \n",
       "3592467                         0.0                  0.0                  0.0   \n",
       "3592469                         0.0                  0.0                  0.0   \n",
       "\n",
       "          avg_wc_address_day_35  \n",
       "systemid                         \n",
       "3592461                     0.0  \n",
       "3592463                     0.0  \n",
       "3592465                     0.0  \n",
       "3592467                     0.0  \n",
       "3592469                     0.0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_count_35days_all_accounts_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Invoice within 42 days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL for impoorting all invoices created within 42 days after signup_date\n",
    "sql_invoices_42days_all_accounts = '''WITH invoices_in_a_period AS (\n",
    "    SELECT systemid, signup_date\n",
    "    FROM report_systems rs\n",
    "    WHERE signup_date BETWEEN '2018-08-01' and '2019-07-30'\n",
    "), invoice_created_at AS (\n",
    "    SELECT\n",
    "           pic.systemid,\n",
    "           inv.invoiceid,\n",
    "           pic.signup_date,\n",
    "           inv.create_date,\n",
    "           inv.created_at,\n",
    "           inv.description,\n",
    "           inv.notes,\n",
    "           inv.terms,\n",
    "           inv.address,\n",
    "           DATEDIFF(days, pic.signup_date, inv.created_at) AS days_to_invoice_creation\n",
    "    FROM invoices_in_a_period AS pic\n",
    "    LEFT JOIN coalesced_live_shards.invoice_stable as inv USING (systemid)\n",
    "    WHERE ((days_to_invoice_creation BETWEEN 0 AND 42) OR days_to_invoice_creation IS NULL)\n",
    ")\n",
    "\n",
    "SELECT *\n",
    "FROM invoice_created_at;'''\n",
    "\n",
    "# Import as dataframe from redshift\n",
    "df_invoices_42days_all_accounts = pig.run_query(sql_invoices_42days_all_accounts, return_data=True)\n",
    "\n",
    "# Words count in invoice's description, notes, terms, address\n",
    "df_invoices_42days_all_accounts['avg_wc_description_day_42'] = df_invoices_42days_all_accounts.apply(lambda x: words_count(x['description']), axis=1)\n",
    "df_invoices_42days_all_accounts['avg_wc_notes_day_42'] = df_invoices_42days_all_accounts.apply(lambda x: words_count(x['notes']), axis=1)\n",
    "df_invoices_42days_all_accounts['avg_wc_terms_day_42'] = df_invoices_42days_all_accounts.apply(lambda x: words_count(x['terms']), axis=1)\n",
    "df_invoices_42days_all_accounts['avg_wc_address_day_42'] = df_invoices_42days_all_accounts.apply(lambda x: words_count(x['address']), axis=1)\n",
    "\n",
    "                                                                                                                   \n",
    "# Filters the text columns from the dataframe\n",
    "df_invoices_42days_all_accounts_fil = df_invoices_42days_all_accounts.filter(['systemid', 'invoiceid', \n",
    "                                                                            'signup_date', \n",
    "                                                                            'create_date', \n",
    "                                                                            'created_at',\n",
    "                                                                            'days_to_invoice_creation', \n",
    "                                                                            'avg_wc_description_day_42', \n",
    "                                                                            'avg_wc_notes_day_42', \n",
    "                                                                            'avg_wc_terms_day_42',\n",
    "                                                                            'avg_wc_address_day_42'])  \n",
    "                                                                                                                   \n",
    "# Summing (grouping) all invoices for a 'systemid'\n",
    "df_word_count_42days_all_accounts_total = df_invoices_42days_all_accounts_fil.groupby('systemid').mean()  \n",
    "\n",
    "# Final word count table\n",
    "df_word_count_42days_all_accounts_final = df_word_count_42days_all_accounts_total.filter(['systemid',\n",
    "                                                                            'avg_wc_description_day_42', \n",
    "                                                                            'avg_wc_notes_day_42', \n",
    "                                                                            'avg_wc_terms_day_42',\n",
    "                                                                            'avg_wc_address_day_42'])\n",
    "\n",
    "# Export as csv file\n",
    "df_word_count_42days_all_accounts_final.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/df_word_count_42days_all_accounts_final.tsv\", \n",
    "                                      sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_wc_description_day_42</th>\n",
       "      <th>avg_wc_notes_day_42</th>\n",
       "      <th>avg_wc_terms_day_42</th>\n",
       "      <th>avg_wc_address_day_42</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systemid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3592461</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592463</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592465</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592467</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592469</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          avg_wc_description_day_42  avg_wc_notes_day_42  avg_wc_terms_day_42  \\\n",
       "systemid                                                                        \n",
       "3592461                         2.0                  6.0                  0.0   \n",
       "3592463                         0.0                  0.0                  0.0   \n",
       "3592465                         0.0                  0.0                  0.0   \n",
       "3592467                         0.0                  0.0                  0.0   \n",
       "3592469                         0.0                  0.0                  0.0   \n",
       "\n",
       "          avg_wc_address_day_42  \n",
       "systemid                         \n",
       "3592461                     0.0  \n",
       "3592463                     0.0  \n",
       "3592465                     0.0  \n",
       "3592467                     0.0  \n",
       "3592469                     0.0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_count_42days_all_accounts_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Invoice within 49 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL for impoorting all invoices created within 49 days after signup_date\n",
    "sql_invoices_49days_all_accounts = '''WITH invoices_in_a_period AS (\n",
    "    SELECT systemid, signup_date\n",
    "    FROM report_systems rs\n",
    "    WHERE signup_date BETWEEN '2018-08-01' and '2019-07-30'\n",
    "), invoice_created_at AS (\n",
    "    SELECT\n",
    "           pic.systemid,\n",
    "           inv.invoiceid,\n",
    "           pic.signup_date,\n",
    "           inv.create_date,\n",
    "           inv.created_at,\n",
    "           inv.description,\n",
    "           inv.notes,\n",
    "           inv.terms,\n",
    "           inv.address,\n",
    "           DATEDIFF(days, pic.signup_date, inv.created_at) AS days_to_invoice_creation\n",
    "    FROM invoices_in_a_period AS pic\n",
    "    LEFT JOIN coalesced_live_shards.invoice_stable as inv USING (systemid)\n",
    "    WHERE ((days_to_invoice_creation BETWEEN 0 AND 49) OR days_to_invoice_creation IS NULL)\n",
    ")\n",
    "\n",
    "SELECT *\n",
    "FROM invoice_created_at;'''\n",
    "\n",
    "# Import as dataframe from redshift\n",
    "df_invoices_49days_all_accounts = pig.run_query(sql_invoices_49days_all_accounts, return_data=True)\n",
    "\n",
    "# Words count in invoice's description, notes, terms, address\n",
    "df_invoices_49days_all_accounts['avg_wc_description_day_49'] = df_invoices_49days_all_accounts.apply(lambda x: words_count(x['description']), axis=1)\n",
    "df_invoices_49days_all_accounts['avg_wc_notes_day_49'] = df_invoices_49days_all_accounts.apply(lambda x: words_count(x['notes']), axis=1)\n",
    "df_invoices_49days_all_accounts['avg_wc_terms_day_49'] = df_invoices_49days_all_accounts.apply(lambda x: words_count(x['terms']), axis=1)\n",
    "df_invoices_49days_all_accounts['avg_wc_address_day_49'] = df_invoices_49days_all_accounts.apply(lambda x: words_count(x['address']), axis=1)\n",
    "\n",
    "                                                                                                                   \n",
    "# Filters the text columns from the dataframe\n",
    "df_invoices_49days_all_accounts_fil = df_invoices_49days_all_accounts.filter(['systemid', 'invoiceid', \n",
    "                                                                            'signup_date', \n",
    "                                                                            'create_date', \n",
    "                                                                            'created_at',\n",
    "                                                                            'days_to_invoice_creation', \n",
    "                                                                            'avg_wc_description_day_49', \n",
    "                                                                            'avg_wc_notes_day_49', \n",
    "                                                                            'avg_wc_terms_day_49',\n",
    "                                                                            'avg_wc_address_day_49'])  \n",
    "                                                                                                                   \n",
    "# Summing (grouping) all invoices for a 'systemid'\n",
    "df_word_count_49days_all_accounts_total = df_invoices_49days_all_accounts_fil.groupby('systemid').mean()  \n",
    "\n",
    "# Final word count table\n",
    "df_word_count_49days_all_accounts_final = df_word_count_49days_all_accounts_total.filter(['systemid',\n",
    "                                                                            'avg_wc_description_day_49', \n",
    "                                                                            'avg_wc_notes_day_49', \n",
    "                                                                            'avg_wc_terms_day_49',\n",
    "                                                                            'avg_wc_address_day_49'])\n",
    "\n",
    "# Export as csv file\n",
    "df_word_count_49days_all_accounts_final.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/df_word_count_49days_all_accounts_final.tsv\", \n",
    "                                      sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_wc_description_day_49</th>\n",
       "      <th>avg_wc_notes_day_49</th>\n",
       "      <th>avg_wc_terms_day_49</th>\n",
       "      <th>avg_wc_address_day_49</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systemid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3592461</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592463</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592465</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592467</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592469</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          avg_wc_description_day_49  avg_wc_notes_day_49  avg_wc_terms_day_49  \\\n",
       "systemid                                                                        \n",
       "3592461                         2.0                  6.0                  0.0   \n",
       "3592463                         0.0                  0.0                  0.0   \n",
       "3592465                         0.0                  0.0                  0.0   \n",
       "3592467                         0.0                  0.0                  0.0   \n",
       "3592469                         0.0                  0.0                  0.0   \n",
       "\n",
       "          avg_wc_address_day_49  \n",
       "systemid                         \n",
       "3592461                     0.0  \n",
       "3592463                     0.0  \n",
       "3592465                     0.0  \n",
       "3592467                     0.0  \n",
       "3592469                     0.0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_count_49days_all_accounts_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 Invoice within 56 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL for impoorting all invoices created within 56 days after signup_date\n",
    "sql_invoices_56days_all_accounts = '''WITH invoices_in_a_period AS (\n",
    "    SELECT systemid, signup_date\n",
    "    FROM report_systems rs\n",
    "    WHERE signup_date BETWEEN '2018-08-01' and '2019-07-30'\n",
    "), invoice_created_at AS (\n",
    "    SELECT\n",
    "           pic.systemid,\n",
    "           inv.invoiceid,\n",
    "           pic.signup_date,\n",
    "           inv.create_date,\n",
    "           inv.created_at,\n",
    "           inv.description,\n",
    "           inv.notes,\n",
    "           inv.terms,\n",
    "           inv.address,\n",
    "           DATEDIFF(days, pic.signup_date, inv.created_at) AS days_to_invoice_creation\n",
    "    FROM invoices_in_a_period AS pic\n",
    "    LEFT JOIN coalesced_live_shards.invoice_stable as inv USING (systemid)\n",
    "    WHERE ((days_to_invoice_creation BETWEEN 0 AND 56) OR days_to_invoice_creation IS NULL)\n",
    ")\n",
    "\n",
    "SELECT *\n",
    "FROM invoice_created_at;'''\n",
    "\n",
    "# Import as dataframe from redshift\n",
    "df_invoices_56days_all_accounts = pig.run_query(sql_invoices_56days_all_accounts, return_data=True)\n",
    "\n",
    "# Words count in invoice's description, notes, terms, address\n",
    "df_invoices_56days_all_accounts['avg_wc_description_day_56'] = df_invoices_56days_all_accounts.apply(lambda x: words_count(x['description']), axis=1)\n",
    "df_invoices_56days_all_accounts['avg_wc_notes_day_56'] = df_invoices_56days_all_accounts.apply(lambda x: words_count(x['notes']), axis=1)\n",
    "df_invoices_56days_all_accounts['avg_wc_terms_day_56'] = df_invoices_56days_all_accounts.apply(lambda x: words_count(x['terms']), axis=1)\n",
    "df_invoices_56days_all_accounts['avg_wc_address_day_56'] = df_invoices_56days_all_accounts.apply(lambda x: words_count(x['address']), axis=1)\n",
    "\n",
    "                                                                                                                   \n",
    "# Filters the text columns from the dataframe\n",
    "df_invoices_56days_all_accounts_fil = df_invoices_56days_all_accounts.filter(['systemid', 'invoiceid', \n",
    "                                                                            'signup_date', \n",
    "                                                                            'create_date', \n",
    "                                                                            'created_at',\n",
    "                                                                            'days_to_invoice_creation', \n",
    "                                                                            'avg_wc_description_day_56', \n",
    "                                                                            'avg_wc_notes_day_56', \n",
    "                                                                            'avg_wc_terms_day_56',\n",
    "                                                                            'avg_wc_address_day_56'])  \n",
    "                                                                                                                   \n",
    "# Summing (grouping) all invoices for a 'systemid'\n",
    "df_word_count_56days_all_accounts_total = df_invoices_56days_all_accounts_fil.groupby('systemid').mean()  \n",
    "\n",
    "# Final word count table\n",
    "df_word_count_56days_all_accounts_final = df_word_count_56days_all_accounts_total.filter(['systemid',\n",
    "                                                                            'avg_wc_description_day_56', \n",
    "                                                                            'avg_wc_notes_day_56', \n",
    "                                                                            'avg_wc_terms_day_56',\n",
    "                                                                            'avg_wc_address_day_56'])\n",
    "\n",
    "# Export as csv file\n",
    "df_word_count_56days_all_accounts_final.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/df_word_count_56days_all_accounts_final.tsv\", \n",
    "                                      sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_wc_description_day_56</th>\n",
       "      <th>avg_wc_notes_day_56</th>\n",
       "      <th>avg_wc_terms_day_56</th>\n",
       "      <th>avg_wc_address_day_56</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systemid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3592461</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592463</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592465</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592467</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592469</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          avg_wc_description_day_56  avg_wc_notes_day_56  avg_wc_terms_day_56  \\\n",
       "systemid                                                                        \n",
       "3592461                         2.0                  6.0                  0.0   \n",
       "3592463                         0.0                  0.0                  0.0   \n",
       "3592465                         0.0                  0.0                  0.0   \n",
       "3592467                         0.0                  0.0                  0.0   \n",
       "3592469                         0.0                  0.0                  0.0   \n",
       "\n",
       "          avg_wc_address_day_56  \n",
       "systemid                         \n",
       "3592461                     0.0  \n",
       "3592463                     0.0  \n",
       "3592465                     0.0  \n",
       "3592467                     0.0  \n",
       "3592469                     0.0  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_count_56days_all_accounts_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.9 Invoice within 63 days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL for impoorting all invoices created within 63 days after signup_date\n",
    "sql_invoices_63days_all_accounts = '''WITH invoices_in_a_period AS (\n",
    "    SELECT systemid, signup_date\n",
    "    FROM report_systems rs\n",
    "    WHERE signup_date BETWEEN '2018-08-01' and '2019-07-30'\n",
    "), invoice_created_at AS (\n",
    "    SELECT\n",
    "           pic.systemid,\n",
    "           inv.invoiceid,\n",
    "           pic.signup_date,\n",
    "           inv.create_date,\n",
    "           inv.created_at,\n",
    "           inv.description,\n",
    "           inv.notes,\n",
    "           inv.terms,\n",
    "           inv.address,\n",
    "           DATEDIFF(days, pic.signup_date, inv.created_at) AS days_to_invoice_creation\n",
    "    FROM invoices_in_a_period AS pic\n",
    "    LEFT JOIN coalesced_live_shards.invoice_stable as inv USING (systemid)\n",
    "    WHERE ((days_to_invoice_creation BETWEEN 0 AND 63) OR days_to_invoice_creation IS NULL)\n",
    ")\n",
    "\n",
    "SELECT *\n",
    "FROM invoice_created_at;'''\n",
    "\n",
    "# Import as dataframe from redshift\n",
    "df_invoices_63days_all_accounts = pig.run_query(sql_invoices_63days_all_accounts, return_data=True)\n",
    "\n",
    "# Words count in invoice's description, notes, terms, address\n",
    "df_invoices_63days_all_accounts['avg_wc_description_day_63'] = df_invoices_63days_all_accounts.apply(lambda x: words_count(x['description']), axis=1)\n",
    "df_invoices_63days_all_accounts['avg_wc_notes_day_63'] = df_invoices_63days_all_accounts.apply(lambda x: words_count(x['notes']), axis=1)\n",
    "df_invoices_63days_all_accounts['avg_wc_terms_day_63'] = df_invoices_63days_all_accounts.apply(lambda x: words_count(x['terms']), axis=1)\n",
    "df_invoices_63days_all_accounts['avg_wc_address_day_63'] = df_invoices_63days_all_accounts.apply(lambda x: words_count(x['address']), axis=1)\n",
    "\n",
    "                                                                                                                   \n",
    "# Filters the text columns from the dataframe\n",
    "df_invoices_63days_all_accounts_fil = df_invoices_63days_all_accounts.filter(['systemid', 'invoiceid', \n",
    "                                                                            'signup_date', \n",
    "                                                                            'create_date', \n",
    "                                                                            'created_at',\n",
    "                                                                            'days_to_invoice_creation', \n",
    "                                                                            'avg_wc_description_day_63', \n",
    "                                                                            'avg_wc_notes_day_63', \n",
    "                                                                            'avg_wc_terms_day_63',\n",
    "                                                                            'avg_wc_address_day_63'])  \n",
    "                                                                                                                   \n",
    "# Summing (grouping) all invoices for a 'systemid'\n",
    "df_word_count_63days_all_accounts_total = df_invoices_63days_all_accounts_fil.groupby('systemid').mean()  \n",
    "\n",
    "# Final word count table\n",
    "df_word_count_63days_all_accounts_final = df_word_count_63days_all_accounts_total.filter(['systemid',\n",
    "                                                                            'avg_wc_description_day_63', \n",
    "                                                                            'avg_wc_notes_day_63', \n",
    "                                                                            'avg_wc_terms_day_63',\n",
    "                                                                            'avg_wc_address_day_63'])\n",
    "\n",
    "# Export as csv file\n",
    "df_word_count_63days_all_accounts_final.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/df_word_count_63days_all_accounts_final.tsv\", \n",
    "                                      sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_wc_description_day_63</th>\n",
       "      <th>avg_wc_notes_day_63</th>\n",
       "      <th>avg_wc_terms_day_63</th>\n",
       "      <th>avg_wc_address_day_63</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systemid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3592461</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592463</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592465</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592467</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592469</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          avg_wc_description_day_63  avg_wc_notes_day_63  avg_wc_terms_day_63  \\\n",
       "systemid                                                                        \n",
       "3592461                         2.0                  6.0                  0.0   \n",
       "3592463                         0.0                  0.0                  0.0   \n",
       "3592465                         0.0                  0.0                  0.0   \n",
       "3592467                         0.0                  0.0                  0.0   \n",
       "3592469                         0.0                  0.0                  0.0   \n",
       "\n",
       "          avg_wc_address_day_63  \n",
       "systemid                         \n",
       "3592461                     0.0  \n",
       "3592463                     0.0  \n",
       "3592465                     0.0  \n",
       "3592467                     0.0  \n",
       "3592469                     0.0  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_count_63days_all_accounts_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.10 Invoice within 70 days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL for impoorting all invoices created within 70 days after signup_date\n",
    "sql_invoices_70days_all_accounts = '''WITH invoices_in_a_period AS (\n",
    "    SELECT systemid, signup_date\n",
    "    FROM report_systems rs\n",
    "    WHERE signup_date BETWEEN '2018-08-01' and '2019-07-30'\n",
    "), invoice_created_at AS (\n",
    "    SELECT\n",
    "           pic.systemid,\n",
    "           inv.invoiceid,\n",
    "           pic.signup_date,\n",
    "           inv.create_date,\n",
    "           inv.created_at,\n",
    "           inv.description,\n",
    "           inv.notes,\n",
    "           inv.terms,\n",
    "           inv.address,\n",
    "           DATEDIFF(days, pic.signup_date, inv.created_at) AS days_to_invoice_creation\n",
    "    FROM invoices_in_a_period AS pic\n",
    "    LEFT JOIN coalesced_live_shards.invoice_stable as inv USING (systemid)\n",
    "    WHERE ((days_to_invoice_creation BETWEEN 0 AND 70) OR days_to_invoice_creation IS NULL)\n",
    ")\n",
    "\n",
    "SELECT *\n",
    "FROM invoice_created_at;'''\n",
    "\n",
    "# Import as dataframe from redshift\n",
    "df_invoices_70days_all_accounts = pig.run_query(sql_invoices_70days_all_accounts, return_data=True)\n",
    "\n",
    "# Words count in invoice's description, notes, terms, address\n",
    "df_invoices_70days_all_accounts['avg_wc_description_day_70'] = df_invoices_70days_all_accounts.apply(lambda x: words_count(x['description']), axis=1)\n",
    "df_invoices_70days_all_accounts['avg_wc_notes_day_70'] = df_invoices_70days_all_accounts.apply(lambda x: words_count(x['notes']), axis=1)\n",
    "df_invoices_70days_all_accounts['avg_wc_terms_day_70'] = df_invoices_70days_all_accounts.apply(lambda x: words_count(x['terms']), axis=1)\n",
    "df_invoices_70days_all_accounts['avg_wc_address_day_70'] = df_invoices_70days_all_accounts.apply(lambda x: words_count(x['address']), axis=1)\n",
    "\n",
    "                                                                                                                   \n",
    "# Filters the text columns from the dataframe\n",
    "df_invoices_70days_all_accounts_fil = df_invoices_70days_all_accounts.filter(['systemid', 'invoiceid', \n",
    "                                                                            'signup_date', \n",
    "                                                                            'create_date', \n",
    "                                                                            'created_at',\n",
    "                                                                            'days_to_invoice_creation', \n",
    "                                                                            'avg_wc_description_day_70', \n",
    "                                                                            'avg_wc_notes_day_70', \n",
    "                                                                            'avg_wc_terms_day_70',\n",
    "                                                                            'avg_wc_address_day_70'])  \n",
    "                                                                                                                   \n",
    "# Summing (grouping) all invoices for a 'systemid'\n",
    "df_word_count_70days_all_accounts_total = df_invoices_70days_all_accounts_fil.groupby('systemid').mean()  \n",
    "\n",
    "# Final word count table\n",
    "df_word_count_70days_all_accounts_final = df_word_count_70days_all_accounts_total.filter(['systemid',\n",
    "                                                                            'avg_wc_description_day_70', \n",
    "                                                                            'avg_wc_notes_day_70', \n",
    "                                                                            'avg_wc_terms_day_70',\n",
    "                                                                            'avg_wc_address_day_70'])\n",
    "\n",
    "# Export as csv file\n",
    "df_word_count_70days_all_accounts_final.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/df_word_count_70days_all_accounts_final.tsv\", \n",
    "                                      sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_wc_description_day_70</th>\n",
       "      <th>avg_wc_notes_day_70</th>\n",
       "      <th>avg_wc_terms_day_70</th>\n",
       "      <th>avg_wc_address_day_70</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systemid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3592461</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592463</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592465</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592467</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592469</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          avg_wc_description_day_70  avg_wc_notes_day_70  avg_wc_terms_day_70  \\\n",
       "systemid                                                                        \n",
       "3592461                         2.0                  6.0                  0.0   \n",
       "3592463                         0.0                  0.0                  0.0   \n",
       "3592465                         0.0                  0.0                  0.0   \n",
       "3592467                         0.0                  0.0                  0.0   \n",
       "3592469                         0.0                  0.0                  0.0   \n",
       "\n",
       "          avg_wc_address_day_70  \n",
       "systemid                         \n",
       "3592461                     0.0  \n",
       "3592463                     0.0  \n",
       "3592465                     0.0  \n",
       "3592467                     0.0  \n",
       "3592469                     0.0  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_count_70days_all_accounts_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.11 Invoice 77 days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL for impoorting all invoices created within 77 days after signup_date\n",
    "sql_invoices_77days_all_accounts = '''WITH invoices_in_a_period AS (\n",
    "    SELECT systemid, signup_date\n",
    "    FROM report_systems rs\n",
    "    WHERE signup_date BETWEEN '2018-08-01' and '2019-07-30'\n",
    "), invoice_created_at AS (\n",
    "    SELECT\n",
    "           pic.systemid,\n",
    "           inv.invoiceid,\n",
    "           pic.signup_date,\n",
    "           inv.create_date,\n",
    "           inv.created_at,\n",
    "           inv.description,\n",
    "           inv.notes,\n",
    "           inv.terms,\n",
    "           inv.address,\n",
    "           DATEDIFF(days, pic.signup_date, inv.created_at) AS days_to_invoice_creation\n",
    "    FROM invoices_in_a_period AS pic\n",
    "    LEFT JOIN coalesced_live_shards.invoice_stable as inv USING (systemid)\n",
    "    WHERE ((days_to_invoice_creation BETWEEN 0 AND 77) OR days_to_invoice_creation IS NULL)\n",
    ")\n",
    "\n",
    "SELECT *\n",
    "FROM invoice_created_at;'''\n",
    "\n",
    "# Import as dataframe from redshift\n",
    "df_invoices_77days_all_accounts = pig.run_query(sql_invoices_77days_all_accounts, return_data=True)\n",
    "\n",
    "# Words count in invoice's description, notes, terms, address\n",
    "df_invoices_77days_all_accounts['avg_wc_description_day_77'] = df_invoices_77days_all_accounts.apply(lambda x: words_count(x['description']), axis=1)\n",
    "df_invoices_77days_all_accounts['avg_wc_notes_day_77'] = df_invoices_77days_all_accounts.apply(lambda x: words_count(x['notes']), axis=1)\n",
    "df_invoices_77days_all_accounts['avg_wc_terms_day_77'] = df_invoices_77days_all_accounts.apply(lambda x: words_count(x['terms']), axis=1)\n",
    "df_invoices_77days_all_accounts['avg_wc_address_day_77'] = df_invoices_77days_all_accounts.apply(lambda x: words_count(x['address']), axis=1)\n",
    "\n",
    "                                                                                                                   \n",
    "# Filters the text columns from the dataframe\n",
    "df_invoices_77days_all_accounts_fil = df_invoices_77days_all_accounts.filter(['systemid', 'invoiceid', \n",
    "                                                                            'signup_date', \n",
    "                                                                            'create_date', \n",
    "                                                                            'created_at',\n",
    "                                                                            'days_to_invoice_creation', \n",
    "                                                                            'avg_wc_description_day_77', \n",
    "                                                                            'avg_wc_notes_day_77', \n",
    "                                                                            'avg_wc_terms_day_77',\n",
    "                                                                            'avg_wc_address_day_77'])  \n",
    "                                                                                                                   \n",
    "# Summing (grouping) all invoices for a 'systemid'\n",
    "df_word_count_77days_all_accounts_total = df_invoices_77days_all_accounts_fil.groupby('systemid').mean()  \n",
    "\n",
    "# Final word count table\n",
    "df_word_count_77days_all_accounts_final = df_word_count_77days_all_accounts_total.filter(['systemid',\n",
    "                                                                            'avg_wc_description_day_77', \n",
    "                                                                            'avg_wc_notes_day_77', \n",
    "                                                                            'avg_wc_terms_day_77',\n",
    "                                                                            'avg_wc_address_day_77'])\n",
    "\n",
    "# Export as csv file\n",
    "df_word_count_77days_all_accounts_final.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/df_word_count_77days_all_accounts_final.tsv\", \n",
    "                                      sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_wc_description_day_77</th>\n",
       "      <th>avg_wc_notes_day_77</th>\n",
       "      <th>avg_wc_terms_day_77</th>\n",
       "      <th>avg_wc_address_day_77</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systemid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3592461</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592463</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592465</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592467</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592469</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          avg_wc_description_day_77  avg_wc_notes_day_77  avg_wc_terms_day_77  \\\n",
       "systemid                                                                        \n",
       "3592461                         2.0                  6.0                  0.0   \n",
       "3592463                         0.0                  0.0                  0.0   \n",
       "3592465                         0.0                  0.0                  0.0   \n",
       "3592467                         0.0                  0.0                  0.0   \n",
       "3592469                         0.0                  0.0                  0.0   \n",
       "\n",
       "          avg_wc_address_day_77  \n",
       "systemid                         \n",
       "3592461                     0.0  \n",
       "3592463                     0.0  \n",
       "3592465                     0.0  \n",
       "3592467                     0.0  \n",
       "3592469                     0.0  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_count_77days_all_accounts_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.12 Invoice within 84 days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL for impoorting all invoices created within 84 days after signup_date\n",
    "sql_invoices_84days_all_accounts = '''WITH invoices_in_a_period AS (\n",
    "    SELECT systemid, signup_date\n",
    "    FROM report_systems rs\n",
    "    WHERE signup_date BETWEEN '2018-08-01' and '2019-07-30'\n",
    "), invoice_created_at AS (\n",
    "    SELECT\n",
    "           pic.systemid,\n",
    "           inv.invoiceid,\n",
    "           pic.signup_date,\n",
    "           inv.create_date,\n",
    "           inv.created_at,\n",
    "           inv.description,\n",
    "           inv.notes,\n",
    "           inv.terms,\n",
    "           inv.address,\n",
    "           DATEDIFF(days, pic.signup_date, inv.created_at) AS days_to_invoice_creation\n",
    "    FROM invoices_in_a_period AS pic\n",
    "    LEFT JOIN coalesced_live_shards.invoice_stable as inv USING (systemid)\n",
    "    WHERE ((days_to_invoice_creation BETWEEN 0 AND 84) OR days_to_invoice_creation IS NULL)\n",
    ")\n",
    "\n",
    "SELECT *\n",
    "FROM invoice_created_at;'''\n",
    "\n",
    "# Import as dataframe from redshift\n",
    "df_invoices_84days_all_accounts = pig.run_query(sql_invoices_84days_all_accounts, return_data=True)\n",
    "\n",
    "# Words count in invoice's description, notes, terms, address\n",
    "df_invoices_84days_all_accounts['avg_wc_description_day_84'] = df_invoices_84days_all_accounts.apply(lambda x: words_count(x['description']), axis=1)\n",
    "df_invoices_84days_all_accounts['avg_wc_notes_day_84'] = df_invoices_84days_all_accounts.apply(lambda x: words_count(x['notes']), axis=1)\n",
    "df_invoices_84days_all_accounts['avg_wc_terms_day_84'] = df_invoices_84days_all_accounts.apply(lambda x: words_count(x['terms']), axis=1)\n",
    "df_invoices_84days_all_accounts['avg_wc_address_day_84'] = df_invoices_84days_all_accounts.apply(lambda x: words_count(x['address']), axis=1)\n",
    "\n",
    "                                                                                                                   \n",
    "# Filters the text columns from the dataframe\n",
    "df_invoices_84days_all_accounts_fil = df_invoices_84days_all_accounts.filter(['systemid', 'invoiceid', \n",
    "                                                                            'signup_date', \n",
    "                                                                            'create_date', \n",
    "                                                                            'created_at',\n",
    "                                                                            'days_to_invoice_creation', \n",
    "                                                                            'avg_wc_description_day_84', \n",
    "                                                                            'avg_wc_notes_day_84', \n",
    "                                                                            'avg_wc_terms_day_84',\n",
    "                                                                            'avg_wc_address_day_84'])  \n",
    "                                                                                                                   \n",
    "# Summing (grouping) all invoices for a 'systemid'\n",
    "df_word_count_84days_all_accounts_total = df_invoices_84days_all_accounts_fil.groupby('systemid').mean()  \n",
    "\n",
    "# Final word count table\n",
    "df_word_count_84days_all_accounts_final = df_word_count_84days_all_accounts_total.filter(['systemid',\n",
    "                                                                            'avg_wc_description_day_84', \n",
    "                                                                            'avg_wc_notes_day_84', \n",
    "                                                                            'avg_wc_terms_day_84',\n",
    "                                                                            'avg_wc_address_day_84'])\n",
    "\n",
    "# Export as csv file\n",
    "df_word_count_84days_all_accounts_final.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/df_word_count_84days_all_accounts_final.tsv\", \n",
    "                                      sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_wc_description_day_84</th>\n",
       "      <th>avg_wc_notes_day_84</th>\n",
       "      <th>avg_wc_terms_day_84</th>\n",
       "      <th>avg_wc_address_day_84</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systemid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3592461</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592463</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592465</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592467</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592469</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          avg_wc_description_day_84  avg_wc_notes_day_84  avg_wc_terms_day_84  \\\n",
       "systemid                                                                        \n",
       "3592461                         2.0                  6.0                  0.0   \n",
       "3592463                         0.0                  0.0                  0.0   \n",
       "3592465                         0.0                  0.0                  0.0   \n",
       "3592467                         0.0                  0.0                  0.0   \n",
       "3592469                         0.0                  0.0                  0.0   \n",
       "\n",
       "          avg_wc_address_day_84  \n",
       "systemid                         \n",
       "3592461                     0.0  \n",
       "3592463                     0.0  \n",
       "3592465                     0.0  \n",
       "3592467                     0.0  \n",
       "3592469                     0.0  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_count_84days_all_accounts_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.13 Invoice within 91 days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL for impoorting all invoices created within 91 days after signup_date\n",
    "sql_invoices_91days_all_accounts = '''WITH invoices_in_a_period AS (\n",
    "    SELECT systemid, signup_date\n",
    "    FROM report_systems rs\n",
    "    WHERE signup_date BETWEEN '2018-08-01' and '2019-07-30'\n",
    "), invoice_created_at AS (\n",
    "    SELECT\n",
    "           pic.systemid,\n",
    "           inv.invoiceid,\n",
    "           pic.signup_date,\n",
    "           inv.create_date,\n",
    "           inv.created_at,\n",
    "           inv.description,\n",
    "           inv.notes,\n",
    "           inv.terms,\n",
    "           inv.address,\n",
    "           DATEDIFF(days, pic.signup_date, inv.created_at) AS days_to_invoice_creation\n",
    "    FROM invoices_in_a_period AS pic\n",
    "    LEFT JOIN coalesced_live_shards.invoice_stable as inv USING (systemid)\n",
    "    WHERE ((days_to_invoice_creation BETWEEN 0 AND 91) OR days_to_invoice_creation IS NULL)\n",
    ")\n",
    "\n",
    "SELECT *\n",
    "FROM invoice_created_at;'''\n",
    "\n",
    "# Import as dataframe from redshift\n",
    "df_invoices_91days_all_accounts = pig.run_query(sql_invoices_91days_all_accounts, return_data=True)\n",
    "\n",
    "# Words count in invoice's description, notes, terms, address\n",
    "df_invoices_91days_all_accounts['avg_wc_description_day_91'] = df_invoices_91days_all_accounts.apply(lambda x: words_count(x['description']), axis=1)\n",
    "df_invoices_91days_all_accounts['avg_wc_notes_day_91'] = df_invoices_91days_all_accounts.apply(lambda x: words_count(x['notes']), axis=1)\n",
    "df_invoices_91days_all_accounts['avg_wc_terms_day_91'] = df_invoices_91days_all_accounts.apply(lambda x: words_count(x['terms']), axis=1)\n",
    "df_invoices_91days_all_accounts['avg_wc_address_day_91'] = df_invoices_91days_all_accounts.apply(lambda x: words_count(x['address']), axis=1)\n",
    "\n",
    "                                                                                                                   \n",
    "# Filters the text columns from the dataframe\n",
    "df_invoices_91days_all_accounts_fil = df_invoices_91days_all_accounts.filter(['systemid', 'invoiceid', \n",
    "                                                                            'signup_date', \n",
    "                                                                            'create_date', \n",
    "                                                                            'created_at',\n",
    "                                                                            'days_to_invoice_creation', \n",
    "                                                                            'avg_wc_description_day_91', \n",
    "                                                                            'avg_wc_notes_day_91', \n",
    "                                                                            'avg_wc_terms_day_91',\n",
    "                                                                            'avg_wc_address_day_91'])  \n",
    "                                                                                                                   \n",
    "# Summing (grouping) all invoices for a 'systemid'\n",
    "df_word_count_91days_all_accounts_total = df_invoices_91days_all_accounts_fil.groupby('systemid').mean()  \n",
    "\n",
    "# Final word count table\n",
    "df_word_count_91days_all_accounts_final = df_word_count_91days_all_accounts_total.filter(['systemid',\n",
    "                                                                            'avg_wc_description_day_91', \n",
    "                                                                            'avg_wc_notes_day_91', \n",
    "                                                                            'avg_wc_terms_day_91',\n",
    "                                                                            'avg_wc_address_day_91'])\n",
    "\n",
    "# Export as csv file\n",
    "df_word_count_91days_all_accounts_final.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/df_word_count_91days_all_accounts_final.tsv\", \n",
    "                                      sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_wc_description_day_91</th>\n",
       "      <th>avg_wc_notes_day_91</th>\n",
       "      <th>avg_wc_terms_day_91</th>\n",
       "      <th>avg_wc_address_day_91</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systemid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3592461</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592463</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592465</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592467</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592469</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          avg_wc_description_day_91  avg_wc_notes_day_91  avg_wc_terms_day_91  \\\n",
       "systemid                                                                        \n",
       "3592461                         2.0                  6.0                  0.0   \n",
       "3592463                         0.0                  0.0                  0.0   \n",
       "3592465                         0.0                  0.0                  0.0   \n",
       "3592467                         0.0                  0.0                  0.0   \n",
       "3592469                         0.0                  0.0                  0.0   \n",
       "\n",
       "          avg_wc_address_day_91  \n",
       "systemid                         \n",
       "3592461                     0.0  \n",
       "3592463                     0.0  \n",
       "3592465                     0.0  \n",
       "3592467                     0.0  \n",
       "3592469                     0.0  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_count_91days_all_accounts_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.14 Joining All Periodic Average Words Counts Features Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joininig day 7 and day 14 th dataframes\n",
    "df_avg_invoice_word_count = pd.merge(df_word_count_7days_all_accounts_final, df_word_count_14days_all_accounts_final,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# left join day 21 \n",
    "df_avg_invoice_word_count = pd.merge(df_avg_invoice_word_count, df_word_count_21days_all_accounts_final,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# left join day 28\n",
    "df_avg_invoice_word_count = pd.merge(df_avg_invoice_word_count, df_word_count_28days_all_accounts_final,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# left join day 35\n",
    "df_avg_invoice_word_count = pd.merge(df_avg_invoice_word_count, df_word_count_35days_all_accounts_final,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# left join day 42\n",
    "df_avg_invoice_word_count = pd.merge(df_avg_invoice_word_count, df_word_count_42days_all_accounts_final,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# left join day 49\n",
    "df_avg_invoice_word_count = pd.merge(df_avg_invoice_word_count, df_word_count_49days_all_accounts_final,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# left join day 56\n",
    "df_avg_invoice_word_count = pd.merge(df_avg_invoice_word_count, df_word_count_56days_all_accounts_final,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# left join day 63\n",
    "df_avg_invoice_word_count = pd.merge(df_avg_invoice_word_count, df_word_count_63days_all_accounts_final,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# left join day 70\n",
    "df_avg_invoice_word_count = pd.merge(df_avg_invoice_word_count, df_word_count_70days_all_accounts_final,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# left join day 77\n",
    "df_avg_invoice_word_count = pd.merge(df_avg_invoice_word_count, df_word_count_77days_all_accounts_final,\n",
    "                                     on='systemid', how='left')\n",
    "# left join day 84\n",
    "df_avg_invoice_word_count = pd.merge(df_avg_invoice_word_count, df_word_count_84days_all_accounts_final,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# left join day 91\n",
    "df_avg_invoice_word_count = pd.merge(df_avg_invoice_word_count, df_word_count_91days_all_accounts_final,\n",
    "                                     on='systemid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export as csv file\n",
    "df_avg_invoice_word_count.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/df_avg_invoice_word_count.tsv\", \n",
    "                                      sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_wc_description_day_7</th>\n",
       "      <th>avg_wc_notes_day_7</th>\n",
       "      <th>avg_wc_terms_day_7</th>\n",
       "      <th>avg_wc_address_day_7</th>\n",
       "      <th>avg_wc_description_day_14</th>\n",
       "      <th>avg_wc_notes_day_14</th>\n",
       "      <th>avg_wc_terms_day_14</th>\n",
       "      <th>avg_wc_address_day_14</th>\n",
       "      <th>avg_wc_description_day_21</th>\n",
       "      <th>avg_wc_notes_day_21</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_wc_terms_day_77</th>\n",
       "      <th>avg_wc_address_day_77</th>\n",
       "      <th>avg_wc_description_day_84</th>\n",
       "      <th>avg_wc_notes_day_84</th>\n",
       "      <th>avg_wc_terms_day_84</th>\n",
       "      <th>avg_wc_address_day_84</th>\n",
       "      <th>avg_wc_description_day_91</th>\n",
       "      <th>avg_wc_notes_day_91</th>\n",
       "      <th>avg_wc_terms_day_91</th>\n",
       "      <th>avg_wc_address_day_91</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systemid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4502186</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4502188</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4502190</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.25</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.25</td>\n",
       "      <td>1.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.25</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.25</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4502192</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4502194</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          avg_wc_description_day_7  avg_wc_notes_day_7  avg_wc_terms_day_7  \\\n",
       "systemid                                                                     \n",
       "4502186                        0.0                 0.0                 0.0   \n",
       "4502188                        0.0                 0.0                 0.0   \n",
       "4502190                        0.0                 0.0                 0.0   \n",
       "4502192                        0.0                 0.0                 0.0   \n",
       "4502194                        0.0                 0.0                 0.0   \n",
       "\n",
       "          avg_wc_address_day_7  avg_wc_description_day_14  \\\n",
       "systemid                                                    \n",
       "4502186                    0.0                       0.00   \n",
       "4502188                    0.0                       0.00   \n",
       "4502190                    0.0                       5.25   \n",
       "4502192                    0.0                       0.00   \n",
       "4502194                    0.0                       0.00   \n",
       "\n",
       "          avg_wc_notes_day_14  avg_wc_terms_day_14  avg_wc_address_day_14  \\\n",
       "systemid                                                                    \n",
       "4502186                  0.00                  0.0                    0.0   \n",
       "4502188                  0.00                  0.0                    0.0   \n",
       "4502190                  1.25                  0.0                    0.0   \n",
       "4502192                  0.00                  0.0                    0.0   \n",
       "4502194                  0.00                  0.0                    0.0   \n",
       "\n",
       "          avg_wc_description_day_21  avg_wc_notes_day_21  ...  \\\n",
       "systemid                                                  ...   \n",
       "4502186                        0.00                 0.00  ...   \n",
       "4502188                        0.00                 0.00  ...   \n",
       "4502190                        5.25                 1.25  ...   \n",
       "4502192                        0.00                 0.00  ...   \n",
       "4502194                        0.00                 0.00  ...   \n",
       "\n",
       "          avg_wc_terms_day_77  avg_wc_address_day_77  \\\n",
       "systemid                                               \n",
       "4502186                   0.0                    0.0   \n",
       "4502188                   0.0                    0.0   \n",
       "4502190                   0.0                    0.0   \n",
       "4502192                   0.0                    0.0   \n",
       "4502194                   0.0                    0.0   \n",
       "\n",
       "          avg_wc_description_day_84  avg_wc_notes_day_84  avg_wc_terms_day_84  \\\n",
       "systemid                                                                        \n",
       "4502186                        0.00                 0.00                  0.0   \n",
       "4502188                        0.00                 0.00                  0.0   \n",
       "4502190                        5.25                 1.25                  0.0   \n",
       "4502192                        0.00                 0.00                  0.0   \n",
       "4502194                        0.00                 0.00                  0.0   \n",
       "\n",
       "          avg_wc_address_day_84  avg_wc_description_day_91  \\\n",
       "systemid                                                     \n",
       "4502186                     0.0                       0.00   \n",
       "4502188                     0.0                       0.00   \n",
       "4502190                     0.0                       5.25   \n",
       "4502192                     0.0                       0.00   \n",
       "4502194                     0.0                       0.00   \n",
       "\n",
       "          avg_wc_notes_day_91  avg_wc_terms_day_91  avg_wc_address_day_91  \n",
       "systemid                                                                   \n",
       "4502186                  0.00                  0.0                    0.0  \n",
       "4502188                  0.00                  0.0                    0.0  \n",
       "4502190                  1.25                  0.0                    0.0  \n",
       "4502192                  0.00                  0.0                    0.0  \n",
       "4502194                  0.00                  0.0                    0.0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking\n",
    "df_avg_invoice_word_count.tail()\n",
    "# df_avg_invoice_word_count.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Report Systems, Invoice & Client Counts Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "################# Import RSystems, Periodic Invoices & Client Counts Data ###############\n",
    "\n",
    "# SQL query \n",
    "sql_rs_invoices_clients_activities_all_accounts = '''WITH periodic_report_system_activities AS (\n",
    "    SELECT\n",
    "        systemid,\n",
    "        signup_date,\n",
    "        admin_email,\n",
    "        is_sales_managed,\n",
    "        is_freshbooks_account_active,\n",
    "        is_paying,\n",
    "        signup_ip_address\n",
    "    FROM report_systems rs\n",
    "    WHERE signup_date BETWEEN '2018-08-01' and '2019-07-30'\n",
    "), invoice_create_date AS (\n",
    "    SELECT\n",
    "           pic.systemid,\n",
    "           inv.invoiceid,\n",
    "           inv.create_date,\n",
    "           inv.created_at,\n",
    "           DATEDIFF(days, pic.signup_date, inv.created_at) AS days_to_invoice_creation\n",
    "    FROM periodic_report_system_activities AS pic\n",
    "    LEFT JOIN coalesced_live_shards.invoice_stable as inv USING (systemid)\n",
    "), invoice_grouping AS (\n",
    "    SELECT\n",
    "           systemid,\n",
    "           COUNT(invoiceid) as invoice_count,\n",
    "           SUM(CASE WHEN days_to_invoice_creation BETWEEN 0 AND 7 THEN 1 ELSE 0 END) AS invoice_count_day_7,\n",
    "           SUM(CASE WHEN days_to_invoice_creation BETWEEN 0 AND 14 THEN 1 ELSE 0 END) AS invoice_count_day_14,\n",
    "           SUM(CASE WHEN days_to_invoice_creation BETWEEN 0 AND 21 THEN 1 ELSE 0 END) AS invoice_count_day_21,\n",
    "           SUM(CASE WHEN days_to_invoice_creation BETWEEN 0 AND 28 THEN 1 ELSE 0 END) AS invoice_count_day_28,\n",
    "           SUM(CASE WHEN days_to_invoice_creation BETWEEN 0 AND 35 THEN 1 ELSE 0 END) AS invoice_count_day_35,\n",
    "           SUM(CASE WHEN days_to_invoice_creation BETWEEN 0 AND 42 THEN 1 ELSE 0 END) AS invoice_count_day_42,\n",
    "           SUM(CASE WHEN days_to_invoice_creation BETWEEN 0 AND 49 THEN 1 ELSE 0 END) AS invoice_count_day_49,\n",
    "           SUM(CASE WHEN days_to_invoice_creation BETWEEN 0 AND 56 THEN 1 ELSE 0 END) AS invoice_count_day_56,\n",
    "           SUM(CASE WHEN days_to_invoice_creation BETWEEN 0 AND 63 THEN 1 ELSE 0 END) AS invoice_count_day_63,\n",
    "           SUM(CASE WHEN days_to_invoice_creation BETWEEN 0 AND 70 THEN 1 ELSE 0 END) AS invoice_count_day_70,\n",
    "           SUM(CASE WHEN days_to_invoice_creation BETWEEN 0 AND 77 THEN 1 ELSE 0 END) AS invoice_count_day_77,\n",
    "           SUM(CASE WHEN days_to_invoice_creation BETWEEN 0 AND 84 THEN 1 ELSE 0 END) AS invoice_count_day_84,\n",
    "           SUM(CASE WHEN days_to_invoice_creation BETWEEN 0 AND 91 THEN 1 ELSE 0 END) AS invoice_count_day_91\n",
    "    FROM invoice_create_date\n",
    "    GROUP BY systemid\n",
    "), client_crate_date AS (\n",
    "     SELECT\n",
    "            pic.systemid,\n",
    "            usr.userid,\n",
    "            usr.signup_date,\n",
    "            DATEDIFF(days, pic.signup_date, usr.signup_date) AS days_to_client_creation\n",
    "    FROM periodic_report_system_activities  AS pic\n",
    "    LEFT JOIN coalesced_live_shards.\"user\" as usr USING (systemid)\n",
    "), client_grouping AS (\n",
    "    SELECT\n",
    "           systemid,\n",
    "           count(userid) AS client_count,\n",
    "           SUM(CASE WHEN days_to_client_creation BETWEEN 0 AND 7 THEN 1 ELSE 0 END) AS client_count_day_7,\n",
    "           SUM(CASE WHEN days_to_client_creation BETWEEN 0 AND 14 THEN 1 ELSE 0 END) AS client_count_day_14,\n",
    "           SUM(CASE WHEN days_to_client_creation BETWEEN 0 AND 21 THEN 1 ELSE 0 END) AS client_count_day_21,\n",
    "           SUM(CASE WHEN days_to_client_creation BETWEEN 0 AND 28 THEN 1 ELSE 0 END) AS client_count_day_28,\n",
    "           SUM(CASE WHEN days_to_client_creation BETWEEN 0 AND 35 THEN 1 ELSE 0 END) AS client_count_day_35,\n",
    "           SUM(CASE WHEN days_to_client_creation BETWEEN 0 AND 42 THEN 1 ELSE 0 END) AS client_count_day_42,\n",
    "           SUM(CASE WHEN days_to_client_creation BETWEEN 0 AND 49 THEN 1 ELSE 0 END) AS client_count_day_49,\n",
    "           SUM(CASE WHEN days_to_client_creation BETWEEN 0 AND 56 THEN 1 ELSE 0 END) AS client_count_day_56,\n",
    "           SUM(CASE WHEN days_to_client_creation BETWEEN 0 AND 63 THEN 1 ELSE 0 END) AS client_count_day_63,\n",
    "           SUM(CASE WHEN days_to_client_creation BETWEEN 0 AND 70 THEN 1 ELSE 0 END) AS client_count_day_70,\n",
    "           SUM(CASE WHEN days_to_client_creation BETWEEN 0 AND 77 THEN 1 ELSE 0 END) AS client_count_day_77,\n",
    "           SUM(CASE WHEN days_to_client_creation BETWEEN 0 AND 84 THEN 1 ELSE 0 END) AS client_count_day_84,\n",
    "           SUM(CASE WHEN days_to_client_creation BETWEEN 0 AND 91 THEN 1 ELSE 0 END) AS client_count_day_91\n",
    "    FROM  client_crate_date\n",
    "    GROUP BY systemid\n",
    ")\n",
    "\n",
    "SELECT\n",
    "       systemid,\n",
    "       signup_date,\n",
    "       admin_email,\n",
    "       is_sales_managed,\n",
    "       is_freshbooks_account_active,\n",
    "       is_paying,\n",
    "       signup_ip_address,\n",
    "       inv_gr.invoice_count,\n",
    "       inv_gr.invoice_count_day_7,\n",
    "       inv_gr.invoice_count_day_14,\n",
    "       inv_gr.invoice_count_day_21,\n",
    "       inv_gr.invoice_count_day_28,\n",
    "       inv_gr.invoice_count_day_35,\n",
    "       inv_gr.invoice_count_day_42,\n",
    "       inv_gr.invoice_count_day_49,\n",
    "       inv_gr.invoice_count_day_56,\n",
    "       inv_gr.invoice_count_day_63,\n",
    "       inv_gr.invoice_count_day_70,\n",
    "       inv_gr.invoice_count_day_77,\n",
    "       inv_gr.invoice_count_day_84,\n",
    "       inv_gr.invoice_count_day_91,\n",
    "       cl_gr.client_count,\n",
    "       cl_gr.client_count_day_7,\n",
    "       cl_gr.client_count_day_14,\n",
    "       cl_gr.client_count_day_21,\n",
    "       cl_gr.client_count_day_28,\n",
    "       cl_gr.client_count_day_35,\n",
    "       cl_gr.client_count_day_42,\n",
    "       cl_gr.client_count_day_49,\n",
    "       cl_gr.client_count_day_56,\n",
    "       cl_gr.client_count_day_63,\n",
    "       cl_gr.client_count_day_70,\n",
    "       cl_gr.client_count_day_77,\n",
    "       cl_gr.client_count_day_84,\n",
    "       cl_gr.client_count_day_91\n",
    "FROM periodic_report_system_activities\n",
    "LEFT JOIN invoice_grouping as inv_gr USING (systemid)\n",
    "LEFT JOIN client_grouping AS cl_gr USING (systemid);\n",
    "'''\n",
    "\n",
    "# Import as dataframe from redshift\n",
    "df_rs_invoices_clients_activities_all_accounts = pig.run_query(sql_rs_invoices_clients_activities_all_accounts, return_data=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export as csv file\n",
    "df_rs_invoices_clients_activities_all_accounts.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/df_rs_invoices_clients_activities_all_accounts.tsv\", \n",
    "                                      sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>systemid</th>\n",
       "      <th>signup_date</th>\n",
       "      <th>admin_email</th>\n",
       "      <th>is_sales_managed</th>\n",
       "      <th>is_freshbooks_account_active</th>\n",
       "      <th>is_paying</th>\n",
       "      <th>signup_ip_address</th>\n",
       "      <th>invoice_count</th>\n",
       "      <th>invoice_count_day_7</th>\n",
       "      <th>invoice_count_day_14</th>\n",
       "      <th>...</th>\n",
       "      <th>client_count_day_28</th>\n",
       "      <th>client_count_day_35</th>\n",
       "      <th>client_count_day_42</th>\n",
       "      <th>client_count_day_49</th>\n",
       "      <th>client_count_day_56</th>\n",
       "      <th>client_count_day_63</th>\n",
       "      <th>client_count_day_70</th>\n",
       "      <th>client_count_day_77</th>\n",
       "      <th>client_count_day_84</th>\n",
       "      <th>client_count_day_91</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>452623</th>\n",
       "      <td>4473144</td>\n",
       "      <td>2019-07-19</td>\n",
       "      <td>rudy77769@yahoo.com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.227.252.148</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452624</th>\n",
       "      <td>4485724</td>\n",
       "      <td>2019-07-24</td>\n",
       "      <td>juliecnry@gmail.com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73.93.206.236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452625</th>\n",
       "      <td>4494366</td>\n",
       "      <td>2019-07-28</td>\n",
       "      <td>arenatwin@gmail.com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>203.106.141.143</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452626</th>\n",
       "      <td>4495016</td>\n",
       "      <td>2019-07-28</td>\n",
       "      <td>pgdesigns1@gmail.com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.236.230.214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452627</th>\n",
       "      <td>4496464</td>\n",
       "      <td>2019-07-29</td>\n",
       "      <td>elvissibanda@yahoo.co.uk</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>185.125.224.24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        systemid signup_date               admin_email  is_sales_managed  \\\n",
       "452623   4473144  2019-07-19       rudy77769@yahoo.com                 0   \n",
       "452624   4485724  2019-07-24       juliecnry@gmail.com                 0   \n",
       "452625   4494366  2019-07-28       arenatwin@gmail.com                 0   \n",
       "452626   4495016  2019-07-28      pgdesigns1@gmail.com                 0   \n",
       "452627   4496464  2019-07-29  elvissibanda@yahoo.co.uk                 0   \n",
       "\n",
       "        is_freshbooks_account_active  is_paying signup_ip_address  \\\n",
       "452623                             1          0    35.227.252.148   \n",
       "452624                             1          0     73.93.206.236   \n",
       "452625                             1          0   203.106.141.143   \n",
       "452626                             1          0    71.236.230.214   \n",
       "452627                             1          0    185.125.224.24   \n",
       "\n",
       "        invoice_count  invoice_count_day_7  invoice_count_day_14  ...  \\\n",
       "452623              1                    1                     1  ...   \n",
       "452624              0                    0                     0  ...   \n",
       "452625             10                   10                    10  ...   \n",
       "452626              0                    0                     0  ...   \n",
       "452627              0                    0                     0  ...   \n",
       "\n",
       "        client_count_day_28  client_count_day_35  client_count_day_42  \\\n",
       "452623                    2                    2                    2   \n",
       "452624                    1                    1                    1   \n",
       "452625                    2                    2                    2   \n",
       "452626                   45                   45                   45   \n",
       "452627                    1                    1                    1   \n",
       "\n",
       "        client_count_day_49  client_count_day_56  client_count_day_63  \\\n",
       "452623                    2                    2                    2   \n",
       "452624                    1                    1                    1   \n",
       "452625                    2                    2                    2   \n",
       "452626                   45                   45                   45   \n",
       "452627                    1                    1                    1   \n",
       "\n",
       "        client_count_day_70  client_count_day_77  client_count_day_84  \\\n",
       "452623                    2                    2                    2   \n",
       "452624                    1                    1                    1   \n",
       "452625                    2                    2                    2   \n",
       "452626                   45                   45                   45   \n",
       "452627                    1                    1                    1   \n",
       "\n",
       "        client_count_day_91  \n",
       "452623                    2  \n",
       "452624                    1  \n",
       "452625                    2  \n",
       "452626                   45  \n",
       "452627                    1  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking \n",
    "df_rs_invoices_clients_activities_all_accounts.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(452628, 35)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rs_invoices_clients_activities_all_accounts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Join Avg Word counts and Invoice & Client Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Join Avg Word Counts and Invoice & Client Counts ########################\n",
    "\n",
    "# left join invoices' average periodic word counts (description, notes, terms, address) with the invices & client counts\n",
    "df_periodic_invoice_all_counts = pd.merge(df_avg_invoice_word_count, df_rs_invoices_clients_activities_all_accounts,\n",
    "                                     on='systemid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>systemid</th>\n",
       "      <th>avg_wc_description_day_7</th>\n",
       "      <th>avg_wc_notes_day_7</th>\n",
       "      <th>avg_wc_terms_day_7</th>\n",
       "      <th>avg_wc_address_day_7</th>\n",
       "      <th>avg_wc_description_day_14</th>\n",
       "      <th>avg_wc_notes_day_14</th>\n",
       "      <th>avg_wc_terms_day_14</th>\n",
       "      <th>avg_wc_address_day_14</th>\n",
       "      <th>avg_wc_description_day_21</th>\n",
       "      <th>...</th>\n",
       "      <th>client_count_day_28</th>\n",
       "      <th>client_count_day_35</th>\n",
       "      <th>client_count_day_42</th>\n",
       "      <th>client_count_day_49</th>\n",
       "      <th>client_count_day_56</th>\n",
       "      <th>client_count_day_63</th>\n",
       "      <th>client_count_day_70</th>\n",
       "      <th>client_count_day_77</th>\n",
       "      <th>client_count_day_84</th>\n",
       "      <th>client_count_day_91</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>438748</th>\n",
       "      <td>4502186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438749</th>\n",
       "      <td>4502188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438750</th>\n",
       "      <td>4502190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.25</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.25</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438751</th>\n",
       "      <td>4502192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438752</th>\n",
       "      <td>4502194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        systemid  avg_wc_description_day_7  avg_wc_notes_day_7  \\\n",
       "438748   4502186                       0.0                 0.0   \n",
       "438749   4502188                       0.0                 0.0   \n",
       "438750   4502190                       0.0                 0.0   \n",
       "438751   4502192                       0.0                 0.0   \n",
       "438752   4502194                       0.0                 0.0   \n",
       "\n",
       "        avg_wc_terms_day_7  avg_wc_address_day_7  avg_wc_description_day_14  \\\n",
       "438748                 0.0                   0.0                       0.00   \n",
       "438749                 0.0                   0.0                       0.00   \n",
       "438750                 0.0                   0.0                       5.25   \n",
       "438751                 0.0                   0.0                       0.00   \n",
       "438752                 0.0                   0.0                       0.00   \n",
       "\n",
       "        avg_wc_notes_day_14  avg_wc_terms_day_14  avg_wc_address_day_14  \\\n",
       "438748                 0.00                  0.0                    0.0   \n",
       "438749                 0.00                  0.0                    0.0   \n",
       "438750                 1.25                  0.0                    0.0   \n",
       "438751                 0.00                  0.0                    0.0   \n",
       "438752                 0.00                  0.0                    0.0   \n",
       "\n",
       "        avg_wc_description_day_21  ...  client_count_day_28  \\\n",
       "438748                       0.00  ...                    1   \n",
       "438749                       0.00  ...                    1   \n",
       "438750                       5.25  ...                    2   \n",
       "438751                       0.00  ...                    1   \n",
       "438752                       0.00  ...                    1   \n",
       "\n",
       "        client_count_day_35  client_count_day_42  client_count_day_49  \\\n",
       "438748                    1                    1                    1   \n",
       "438749                    1                    1                    1   \n",
       "438750                    2                    2                    2   \n",
       "438751                    1                    1                    1   \n",
       "438752                    1                    1                    1   \n",
       "\n",
       "        client_count_day_56  client_count_day_63  client_count_day_70  \\\n",
       "438748                    1                    1                    1   \n",
       "438749                    1                    1                    1   \n",
       "438750                    2                    2                    2   \n",
       "438751                    1                    1                    1   \n",
       "438752                    1                    1                    1   \n",
       "\n",
       "        client_count_day_77  client_count_day_84  client_count_day_91  \n",
       "438748                    1                    1                    1  \n",
       "438749                    1                    1                    1  \n",
       "438750                    2                    2                    2  \n",
       "438751                    1                    1                    1  \n",
       "438752                    1                    1                    1  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chiecking\n",
    "df_periodic_invoice_all_counts.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(438753, 87)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_periodic_invoice_all_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export as csv file\n",
    "df_periodic_invoice_all_counts.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/periodic_invoice_all_counts_all_accounts.csv\", \n",
    "                                      sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV file\n",
    "# df_periodic_invoice_all_counts = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/periodic_invoice_all_counts_all_accounts.csv\", \n",
    "#                                       sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(438753, 87)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking\n",
    "df_periodic_invoice_all_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['systemid',\n",
       " 'avg_wc_description_day_7',\n",
       " 'avg_wc_notes_day_7',\n",
       " 'avg_wc_terms_day_7',\n",
       " 'avg_wc_address_day_7',\n",
       " 'avg_wc_description_day_14',\n",
       " 'avg_wc_notes_day_14',\n",
       " 'avg_wc_terms_day_14',\n",
       " 'avg_wc_address_day_14',\n",
       " 'avg_wc_description_day_21',\n",
       " 'avg_wc_notes_day_21',\n",
       " 'avg_wc_terms_day_21',\n",
       " 'avg_wc_address_day_21',\n",
       " 'avg_wc_description_day_28',\n",
       " 'avg_wc_notes_day_28',\n",
       " 'avg_wc_terms_day_28',\n",
       " 'avg_wc_address_day_28',\n",
       " 'avg_wc_description_day_35',\n",
       " 'avg_wc_notes_day_35',\n",
       " 'avg_wc_terms_day_35',\n",
       " 'avg_wc_address_day_35',\n",
       " 'avg_wc_description_day_42',\n",
       " 'avg_wc_notes_day_42',\n",
       " 'avg_wc_terms_day_42',\n",
       " 'avg_wc_address_day_42',\n",
       " 'avg_wc_description_day_49',\n",
       " 'avg_wc_notes_day_49',\n",
       " 'avg_wc_terms_day_49',\n",
       " 'avg_wc_address_day_49',\n",
       " 'avg_wc_description_day_56',\n",
       " 'avg_wc_notes_day_56',\n",
       " 'avg_wc_terms_day_56',\n",
       " 'avg_wc_address_day_56',\n",
       " 'avg_wc_description_day_63',\n",
       " 'avg_wc_notes_day_63',\n",
       " 'avg_wc_terms_day_63',\n",
       " 'avg_wc_address_day_63',\n",
       " 'avg_wc_description_day_70',\n",
       " 'avg_wc_notes_day_70',\n",
       " 'avg_wc_terms_day_70',\n",
       " 'avg_wc_address_day_70',\n",
       " 'avg_wc_description_day_77',\n",
       " 'avg_wc_notes_day_77',\n",
       " 'avg_wc_terms_day_77',\n",
       " 'avg_wc_address_day_77',\n",
       " 'avg_wc_description_day_84',\n",
       " 'avg_wc_notes_day_84',\n",
       " 'avg_wc_terms_day_84',\n",
       " 'avg_wc_address_day_84',\n",
       " 'avg_wc_description_day_91',\n",
       " 'avg_wc_notes_day_91',\n",
       " 'avg_wc_terms_day_91',\n",
       " 'avg_wc_address_day_91',\n",
       " 'signup_date',\n",
       " 'admin_email',\n",
       " 'is_sales_managed',\n",
       " 'is_freshbooks_account_active',\n",
       " 'is_paying',\n",
       " 'signup_ip_address',\n",
       " 'invoice_count',\n",
       " 'invoice_count_day_7',\n",
       " 'invoice_count_day_14',\n",
       " 'invoice_count_day_21',\n",
       " 'invoice_count_day_28',\n",
       " 'invoice_count_day_35',\n",
       " 'invoice_count_day_42',\n",
       " 'invoice_count_day_49',\n",
       " 'invoice_count_day_56',\n",
       " 'invoice_count_day_63',\n",
       " 'invoice_count_day_70',\n",
       " 'invoice_count_day_77',\n",
       " 'invoice_count_day_84',\n",
       " 'invoice_count_day_91',\n",
       " 'client_count',\n",
       " 'client_count_day_7',\n",
       " 'client_count_day_14',\n",
       " 'client_count_day_21',\n",
       " 'client_count_day_28',\n",
       " 'client_count_day_35',\n",
       " 'client_count_day_42',\n",
       " 'client_count_day_49',\n",
       " 'client_count_day_56',\n",
       " 'client_count_day_63',\n",
       " 'client_count_day_70',\n",
       " 'client_count_day_77',\n",
       " 'client_count_day_84',\n",
       " 'client_count_day_91']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_periodic_invoice_all_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Import and Exract Features from Events Data\n",
    "## 4.1 Event data collection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### Event Features Extraction ################################\n",
    "\n",
    "#SQL for events \n",
    "sql_events = '''WITH selected_accounts_events AS (\n",
    "    SELECT systemid,\n",
    "           signup_date,\n",
    "           signup_datetime\n",
    "    FROM report_systems\n",
    "    WHERE signup_date BETWEEN '2018-08-01' and '2019-07-30'\n",
    "), events_activities AS (\n",
    "    SELECT sae.systemid,\n",
    "           signup_date,\n",
    "           dd.date,\n",
    "           datediff(days, signup_date, dd.date) as days_to_event,\n",
    "           lower(e.event) as event,\n",
    "           ec.count\n",
    "    FROM selected_accounts_events AS sae\n",
    "    LEFT JOIN event_counts AS ec USING (systemid)\n",
    "    LEFT JOIN d_date AS dd USING (date_key)\n",
    "    LEFT JOIN d_event e on ec.event_key = e.event_key\n",
    "), event_groupings AS (\n",
    "    SELECT distinct  ea.systemid,\n",
    "                    ea.signup_date,\n",
    "                    ea.date,\n",
    "                    ea.event,\n",
    "                    ea.count,\n",
    "                    (CASE WHEN days_to_event BETWEEN 0 AND 7 THEN ea.count END) AS day_7_event,\n",
    "                    (CASE WHEN days_to_event BETWEEN 0 AND 14 THEN ea.count END) AS day_14_event,\n",
    "                    (CASE WHEN days_to_event BETWEEN 0 AND 21 THEN ea.count END) AS day_21_event,\n",
    "                    (CASE WHEN days_to_event BETWEEN 0 AND 28 THEN ea.count END) AS day_28_event,\n",
    "                    (CASE WHEN days_to_event BETWEEN 0 AND 35 THEN ea.count END) AS day_35_event,\n",
    "                    (CASE WHEN days_to_event BETWEEN 0 AND 42 THEN ea.count END) AS day_42_event,\n",
    "                    (CASE WHEN days_to_event BETWEEN 0 AND 49 THEN ea.count END) AS day_49_event,\n",
    "                    (CASE WHEN days_to_event BETWEEN 0 AND 56 THEN ea.count END) AS day_56_event,\n",
    "                    (CASE WHEN days_to_event BETWEEN 0 AND 63 THEN ea.count END) AS day_63_event,\n",
    "                    (CASE WHEN days_to_event BETWEEN 0 AND 70 THEN ea.count END) AS day_70_event,\n",
    "                    (CASE WHEN days_to_event BETWEEN 0 AND 77 THEN ea.count END) AS day_77_event,\n",
    "                    (CASE WHEN days_to_event BETWEEN 0 AND 84 THEN ea.count END) AS day_84_event,\n",
    "                    (CASE WHEN days_to_event BETWEEN 0 AND 91 THEN ea.count END) AS day_91_event\n",
    "    FROM events_activities AS ea\n",
    ")\n",
    "SELECT systemid,\n",
    "       signup_date,\n",
    "       date,\n",
    "       event,\n",
    "       count,\n",
    "       sum(day_7_event) AS event_count_day_7,\n",
    "       sum(day_14_event) AS event_count_day_14,\n",
    "       sum(day_21_event) AS event_count_day_21,\n",
    "       sum(day_28_event) AS event_count_day_28,\n",
    "       sum(day_35_event) AS event_count_day_35,\n",
    "       sum(day_42_event) AS event_count_day_42,\n",
    "       sum(day_49_event) AS event_count_day_49,\n",
    "       sum(day_56_event) AS event_count_day_56,\n",
    "       sum(day_63_event) AS event_count_day_63,\n",
    "       sum(day_70_event) AS event_count_day_70,\n",
    "       sum(day_77_event) AS event_count_day_77,\n",
    "       sum(day_84_event) AS event_count_day_84,\n",
    "       sum(day_91_event) AS event_count_day_91\n",
    "From event_groupings\n",
    "GROUP BY systemid, signup_date, date, event, count\n",
    "ORDER BY systemid, count DESC;'''\n",
    "\n",
    "# Import as dataframe from redshift\n",
    "# df_events_all_accounts = pd.read_sql_query(sql_events, connect_to_db)\n",
    "df_events_all_accounts = pig.run_query(sql_events, return_data=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>systemid</th>\n",
       "      <th>signup_date</th>\n",
       "      <th>date</th>\n",
       "      <th>event</th>\n",
       "      <th>count</th>\n",
       "      <th>event_count_day_7</th>\n",
       "      <th>event_count_day_14</th>\n",
       "      <th>event_count_day_21</th>\n",
       "      <th>event_count_day_28</th>\n",
       "      <th>event_count_day_35</th>\n",
       "      <th>event_count_day_42</th>\n",
       "      <th>event_count_day_49</th>\n",
       "      <th>event_count_day_56</th>\n",
       "      <th>event_count_day_63</th>\n",
       "      <th>event_count_day_70</th>\n",
       "      <th>event_count_day_77</th>\n",
       "      <th>event_count_day_84</th>\n",
       "      <th>event_count_day_91</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3592461</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>update identity</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3592461</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>subscription details changed</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3592461</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>update system</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3592461</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>update business</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3592461</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>survey question answered</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   systemid signup_date        date                         event  count  \\\n",
       "0   3592461  2018-08-01  2018-08-01               update identity   25.0   \n",
       "1   3592461  2018-08-01  2018-08-01  subscription details changed   13.0   \n",
       "2   3592461  2018-08-01  2018-08-01                 update system    6.0   \n",
       "3   3592461  2018-08-01  2018-08-01               update business    6.0   \n",
       "4   3592461  2018-08-01  2018-08-01      survey question answered    4.0   \n",
       "\n",
       "   event_count_day_7  event_count_day_14  event_count_day_21  \\\n",
       "0               25.0                25.0                25.0   \n",
       "1               13.0                13.0                13.0   \n",
       "2                6.0                 6.0                 6.0   \n",
       "3                6.0                 6.0                 6.0   \n",
       "4                4.0                 4.0                 4.0   \n",
       "\n",
       "   event_count_day_28  event_count_day_35  event_count_day_42  \\\n",
       "0                25.0                25.0                25.0   \n",
       "1                13.0                13.0                13.0   \n",
       "2                 6.0                 6.0                 6.0   \n",
       "3                 6.0                 6.0                 6.0   \n",
       "4                 4.0                 4.0                 4.0   \n",
       "\n",
       "   event_count_day_49  event_count_day_56  event_count_day_63  \\\n",
       "0                25.0                25.0                25.0   \n",
       "1                13.0                13.0                13.0   \n",
       "2                 6.0                 6.0                 6.0   \n",
       "3                 6.0                 6.0                 6.0   \n",
       "4                 4.0                 4.0                 4.0   \n",
       "\n",
       "   event_count_day_70  event_count_day_77  event_count_day_84  \\\n",
       "0                25.0                25.0                25.0   \n",
       "1                13.0                13.0                13.0   \n",
       "2                 6.0                 6.0                 6.0   \n",
       "3                 6.0                 6.0                 6.0   \n",
       "4                 4.0                 4.0                 4.0   \n",
       "\n",
       "   event_count_day_91  \n",
       "0                25.0  \n",
       "1                13.0  \n",
       "2                 6.0  \n",
       "3                 6.0  \n",
       "4                 4.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking\n",
    "df_events_all_accounts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29470655, 18)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_events_all_accounts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Removing whitespce from the event strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing row if there is 'None' the event cell\n",
    "df_events_all_accounts = df_events_all_accounts[~df_events_all_accounts.astype(str).eq('None').any(1)]\n",
    "\n",
    "# Replace the 'NaN' cell by zero\n",
    "df_events_all_accounts.fillna(0, inplace=True)\n",
    "\n",
    "# Using lambda function to remove the white space in the event string name\n",
    "df_events_all_accounts['event_name'] = df_events_all_accounts.apply(lambda x: x['event'].replace(' ', ''), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29470592, 19)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking\n",
    "df_events_all_accounts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>systemid</th>\n",
       "      <th>signup_date</th>\n",
       "      <th>date</th>\n",
       "      <th>event</th>\n",
       "      <th>count</th>\n",
       "      <th>event_count_day_7</th>\n",
       "      <th>event_count_day_14</th>\n",
       "      <th>event_count_day_21</th>\n",
       "      <th>event_count_day_28</th>\n",
       "      <th>event_count_day_35</th>\n",
       "      <th>event_count_day_42</th>\n",
       "      <th>event_count_day_49</th>\n",
       "      <th>event_count_day_56</th>\n",
       "      <th>event_count_day_63</th>\n",
       "      <th>event_count_day_70</th>\n",
       "      <th>event_count_day_77</th>\n",
       "      <th>event_count_day_84</th>\n",
       "      <th>event_count_day_91</th>\n",
       "      <th>event_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3592461</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>update identity</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>updateidentity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3592461</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>subscription details changed</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>subscriptiondetailschanged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3592461</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>update system</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>updatesystem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3592461</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>update business</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>updatebusiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3592461</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>survey question answered</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>surveyquestionanswered</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   systemid signup_date        date                         event  count  \\\n",
       "0   3592461  2018-08-01  2018-08-01               update identity   25.0   \n",
       "1   3592461  2018-08-01  2018-08-01  subscription details changed   13.0   \n",
       "2   3592461  2018-08-01  2018-08-01                 update system    6.0   \n",
       "3   3592461  2018-08-01  2018-08-01               update business    6.0   \n",
       "4   3592461  2018-08-01  2018-08-01      survey question answered    4.0   \n",
       "\n",
       "   event_count_day_7  event_count_day_14  event_count_day_21  \\\n",
       "0               25.0                25.0                25.0   \n",
       "1               13.0                13.0                13.0   \n",
       "2                6.0                 6.0                 6.0   \n",
       "3                6.0                 6.0                 6.0   \n",
       "4                4.0                 4.0                 4.0   \n",
       "\n",
       "   event_count_day_28  event_count_day_35  event_count_day_42  \\\n",
       "0                25.0                25.0                25.0   \n",
       "1                13.0                13.0                13.0   \n",
       "2                 6.0                 6.0                 6.0   \n",
       "3                 6.0                 6.0                 6.0   \n",
       "4                 4.0                 4.0                 4.0   \n",
       "\n",
       "   event_count_day_49  event_count_day_56  event_count_day_63  \\\n",
       "0                25.0                25.0                25.0   \n",
       "1                13.0                13.0                13.0   \n",
       "2                 6.0                 6.0                 6.0   \n",
       "3                 6.0                 6.0                 6.0   \n",
       "4                 4.0                 4.0                 4.0   \n",
       "\n",
       "   event_count_day_70  event_count_day_77  event_count_day_84  \\\n",
       "0                25.0                25.0                25.0   \n",
       "1                13.0                13.0                13.0   \n",
       "2                 6.0                 6.0                 6.0   \n",
       "3                 6.0                 6.0                 6.0   \n",
       "4                 4.0                 4.0                 4.0   \n",
       "\n",
       "   event_count_day_91                  event_name  \n",
       "0                25.0              updateidentity  \n",
       "1                13.0  subscriptiondetailschanged  \n",
       "2                 6.0                updatesystem  \n",
       "3                 6.0              updatebusiness  \n",
       "4                 4.0      surveyquestionanswered  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_events_all_accounts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Final Features Extraction: Day 7\n",
    "\n",
    "## 5.1 Filter Only Events for Day 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## Final Features Extraction: Day 7 ##############################\n",
    "\n",
    "# Filtered the events columns for day 7 period\n",
    "df_events_all_accounts_day_7 = df_events_all_accounts[['systemid', 'event_count_day_7', 'event_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>systemid</th>\n",
       "      <th>event_count_day_7</th>\n",
       "      <th>event_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29470650</th>\n",
       "      <td>4502194</td>\n",
       "      <td>1.0</td>\n",
       "      <td>updateuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29470651</th>\n",
       "      <td>4502194</td>\n",
       "      <td>1.0</td>\n",
       "      <td>welcomeaccount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29470652</th>\n",
       "      <td>4502194</td>\n",
       "      <td>1.0</td>\n",
       "      <td>updateidentity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29470653</th>\n",
       "      <td>4502194</td>\n",
       "      <td>1.0</td>\n",
       "      <td>accesstokencreated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29470654</th>\n",
       "      <td>4502194</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ariasupplementalplanreplaced</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          systemid  event_count_day_7                    event_name\n",
       "29470650   4502194                1.0                    updateuser\n",
       "29470651   4502194                1.0                welcomeaccount\n",
       "29470652   4502194                1.0                updateidentity\n",
       "29470653   4502194                1.0            accesstokencreated\n",
       "29470654   4502194                1.0  ariasupplementalplanreplaced"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_events_all_accounts_day_7.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29470592, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_events_all_accounts_day_7.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Pivote the Day 7 Events (Each Unique Event Become a Column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pivote the Day 7 Events (Each Unique Event Become a Column)###\n",
    "# Pivot table based on the unique column value in 'event_name'\n",
    "df_events_all_accounts_day_7 = df_events_all_accounts_day_7.pivot_table(values='event_count_day_7', columns='event_name', index='systemid', aggfunc=np.sum,  fill_value=0)\n",
    "\n",
    "# Drop the old column name\n",
    "df_events_all_accounts_day_7.columns.name = None\n",
    "\n",
    "# Reset the index\n",
    "df_events_all_accounts_day_7 = df_events_all_accounts_day_7.reset_index()\n",
    "\n",
    "# Replace 'NaN' with zero\n",
    "df_events_all_accounts_day_7.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>systemid</th>\n",
       "      <th>acceptestimate</th>\n",
       "      <th>accesstokencreated</th>\n",
       "      <th>activateclient</th>\n",
       "      <th>activatecontractor</th>\n",
       "      <th>activateestimate</th>\n",
       "      <th>activateexpense</th>\n",
       "      <th>activateinvoice</th>\n",
       "      <th>activateitem</th>\n",
       "      <th>activateotherincome</th>\n",
       "      <th>...</th>\n",
       "      <th>uploadexpensereceipt</th>\n",
       "      <th>uploadhi-reslogo</th>\n",
       "      <th>verifycallback</th>\n",
       "      <th>verifymigration</th>\n",
       "      <th>viewedcreupgradepage</th>\n",
       "      <th>viewestimate</th>\n",
       "      <th>viewinvoice</th>\n",
       "      <th>welcomeaccount</th>\n",
       "      <th>zendesksupporte-mail</th>\n",
       "      <th>zero-amountinvoicefromrecurringprofile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>452560</th>\n",
       "      <td>4502186</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452561</th>\n",
       "      <td>4502188</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452562</th>\n",
       "      <td>4502190</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452563</th>\n",
       "      <td>4502192</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452564</th>\n",
       "      <td>4502194</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        systemid  acceptestimate  accesstokencreated  activateclient  \\\n",
       "452560   4502186               0                   1               0   \n",
       "452561   4502188               0                   0               0   \n",
       "452562   4502190               0                   2               0   \n",
       "452563   4502192               0                   1               0   \n",
       "452564   4502194               0                   1               0   \n",
       "\n",
       "        activatecontractor  activateestimate  activateexpense  \\\n",
       "452560                   0                 0                0   \n",
       "452561                   0                 0                0   \n",
       "452562                   0                 0                0   \n",
       "452563                   0                 0                0   \n",
       "452564                   0                 0                0   \n",
       "\n",
       "        activateinvoice  activateitem  activateotherincome  ...  \\\n",
       "452560                0             0                    0  ...   \n",
       "452561                0             0                    0  ...   \n",
       "452562                0             0                    0  ...   \n",
       "452563                0             0                    0  ...   \n",
       "452564                0             0                    0  ...   \n",
       "\n",
       "        uploadexpensereceipt  uploadhi-reslogo  verifycallback  \\\n",
       "452560                     0                 0               0   \n",
       "452561                     0                 0               0   \n",
       "452562                     0                 0               0   \n",
       "452563                     0                 0               0   \n",
       "452564                     0                 0               0   \n",
       "\n",
       "        verifymigration  viewedcreupgradepage  viewestimate  viewinvoice  \\\n",
       "452560                0                     0             0            0   \n",
       "452561                0                     0             0            0   \n",
       "452562                0                     0             0            1   \n",
       "452563                0                     0             0            0   \n",
       "452564                0                     0             0            0   \n",
       "\n",
       "        welcomeaccount  zendesksupporte-mail  \\\n",
       "452560               1                     0   \n",
       "452561               0                     0   \n",
       "452562               1                     0   \n",
       "452563               1                     0   \n",
       "452564               1                     0   \n",
       "\n",
       "        zero-amountinvoicefromrecurringprofile  \n",
       "452560                                       0  \n",
       "452561                                       0  \n",
       "452562                                       0  \n",
       "452563                                       0  \n",
       "452564                                       0  \n",
       "\n",
       "[5 rows x 500 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking\n",
    "df_events_all_accounts_day_7.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(452565, 500)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_events_all_accounts_day_7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking duplicate systemid presense \n",
    "# duplicateSystemID = pd.concat(g for _, g in df_events_all_accounts_day_7.groupby('systemid') if len(g) > 1)\n",
    "# duplicateSystemID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV export \n",
    "df_events_all_accounts_day_7.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_7.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_events_all_accounts_day_7 = pd.read_csv(\"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_7.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Events Important Features Selection\n",
    "\n",
    "### 5.3.1 Adding missing features columns in the event features dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing importing features list\n",
    "important_features = pd.read_csv( \n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/important_features.csv\", sep=\"\\n,\")\n",
    "\n",
    "# Get the important feature as a list\n",
    "imp_features_list = list(important_features['important_feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking\n",
    "# important_features.head()\n",
    "# imp_features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding missing important feature column \n",
    "for i in range(len(imp_features_list)):\n",
    "    if imp_features_list[i] in df_events_all_accounts_day_7.columns:\n",
    "        print(\"True\")\n",
    "    else:\n",
    "        print(\"False\")\n",
    "        df_events_all_accounts_day_7[imp_features_list[i]] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking\n",
    "# df_events_all_accounts_day_7.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 Fitering only important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering only important features \n",
    "df_events_imp_features_all_accounts_day_7 = \\\n",
    "            df_events_all_accounts_day_7.loc[:, df_events_all_accounts_day_7.columns.str.contains('|'.join(imp_features_list))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>systemid</th>\n",
       "      <th>acceptestimate</th>\n",
       "      <th>accesstokencreated</th>\n",
       "      <th>activateclient</th>\n",
       "      <th>activateestimate</th>\n",
       "      <th>activateexpense</th>\n",
       "      <th>activateinvoice</th>\n",
       "      <th>activateotherincome</th>\n",
       "      <th>activatepayment</th>\n",
       "      <th>activateproject</th>\n",
       "      <th>...</th>\n",
       "      <th>updateitem</th>\n",
       "      <th>updatejournalentrysub-account</th>\n",
       "      <th>updateretainerprofile</th>\n",
       "      <th>updateservice</th>\n",
       "      <th>updatestaff</th>\n",
       "      <th>updatetax</th>\n",
       "      <th>upgradeform-paymenterror</th>\n",
       "      <th>upgradeform-submitted</th>\n",
       "      <th>verifycallback</th>\n",
       "      <th>zendesksupporte-mail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3592461</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3592463</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3592465</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3592467</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3592469</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 239 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   systemid  acceptestimate  accesstokencreated  activateclient  \\\n",
       "0   3592461               0                   0               0   \n",
       "1   3592463               0                   0               0   \n",
       "2   3592465               0                   0               0   \n",
       "3   3592467               0                   0               0   \n",
       "4   3592469               0                   0               0   \n",
       "\n",
       "   activateestimate  activateexpense  activateinvoice  activateotherincome  \\\n",
       "0                 0                0                0                    0   \n",
       "1                 0                0                0                    0   \n",
       "2                 0                0                0                    0   \n",
       "3                 0                0                0                    0   \n",
       "4                 0                0                0                    0   \n",
       "\n",
       "   activatepayment  activateproject  ...  updateitem  \\\n",
       "0                0                0  ...           0   \n",
       "1                0                0  ...           0   \n",
       "2                0                0  ...           0   \n",
       "3                0                0  ...           0   \n",
       "4                0                0  ...           0   \n",
       "\n",
       "   updatejournalentrysub-account  updateretainerprofile  updateservice  \\\n",
       "0                              0                      0              0   \n",
       "1                              0                      0              0   \n",
       "2                              0                      0              0   \n",
       "3                              0                      0              0   \n",
       "4                              0                      0              0   \n",
       "\n",
       "   updatestaff  updatetax  upgradeform-paymenterror  upgradeform-submitted  \\\n",
       "0            0          0                         0                      0   \n",
       "1            0          0                         0                      0   \n",
       "2            0          0                         0                      0   \n",
       "3            0          0                         0                      0   \n",
       "4            0          0                         0                      0   \n",
       "\n",
       "   verifycallback  zendesksupporte-mail  \n",
       "0               0                     0  \n",
       "1               0                     0  \n",
       "2               0                     0  \n",
       "3               0                     0  \n",
       "4               0                     0  \n",
       "\n",
       "[5 rows x 239 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking\n",
    "df_events_imp_features_all_accounts_day_7.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Filtering avgerage word counts features from invoice data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filtering average word counts features from the invoice data\n",
    "# Invoice features at day 7\n",
    "df_invoice_features_all_accounts_day_7 = df_periodic_invoice_all_counts[[\n",
    "        'systemid',\n",
    "        'admin_email',\n",
    "        'is_sales_managed', \n",
    "        'is_freshbooks_account_active',\n",
    "        'is_paying',\n",
    "        'avg_wc_description_day_7',\n",
    "        'avg_wc_notes_day_7',\n",
    "        'avg_wc_terms_day_7',\n",
    "        'avg_wc_address_day_7',\n",
    "        'invoice_count_day_7',\n",
    "        'client_count_day_7'\n",
    "        ]]\n",
    "\n",
    "# CSV export\n",
    "df_invoice_features_all_accounts_day_7.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_7.csv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_invoice_features_all_accounts_day_7 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_7.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking\n",
    "# df_invoice_features_all_accounts_day_7.shape\n",
    "# list(df_periodic_invoice_all_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Merging events' and Invoice features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging events' and invoice features\n",
    "df_final_features_day_7 = pd.merge(df_events_imp_features_all_accounts_day_7, \n",
    "                                   df_invoice_features_all_accounts_day_7,\n",
    "                                     on='systemid', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>systemid</th>\n",
       "      <th>acceptestimate</th>\n",
       "      <th>accesstokencreated</th>\n",
       "      <th>activateclient</th>\n",
       "      <th>activateestimate</th>\n",
       "      <th>activateexpense</th>\n",
       "      <th>activateinvoice</th>\n",
       "      <th>activateotherincome</th>\n",
       "      <th>activatepayment</th>\n",
       "      <th>activateproject</th>\n",
       "      <th>...</th>\n",
       "      <th>admin_email</th>\n",
       "      <th>is_sales_managed</th>\n",
       "      <th>is_freshbooks_account_active</th>\n",
       "      <th>is_paying</th>\n",
       "      <th>avg_wc_description_day_7</th>\n",
       "      <th>avg_wc_notes_day_7</th>\n",
       "      <th>avg_wc_terms_day_7</th>\n",
       "      <th>avg_wc_address_day_7</th>\n",
       "      <th>invoice_count_day_7</th>\n",
       "      <th>client_count_day_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3592461</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>arlarellano2812@gmail.com</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3592463</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>vicky.navdurga1989@gmail.com</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3592465</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>alaizagraham@icloud.com</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3592467</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>sabeeh_gd@yahoo.com</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3592469</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>nayreh55@gmail.com</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 249 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   systemid  acceptestimate  accesstokencreated  activateclient  \\\n",
       "0   3592461               0                   0               0   \n",
       "1   3592463               0                   0               0   \n",
       "2   3592465               0                   0               0   \n",
       "3   3592467               0                   0               0   \n",
       "4   3592469               0                   0               0   \n",
       "\n",
       "   activateestimate  activateexpense  activateinvoice  activateotherincome  \\\n",
       "0                 0                0                0                    0   \n",
       "1                 0                0                0                    0   \n",
       "2                 0                0                0                    0   \n",
       "3                 0                0                0                    0   \n",
       "4                 0                0                0                    0   \n",
       "\n",
       "   activatepayment  activateproject  ...                   admin_email  \\\n",
       "0                0                0  ...     arlarellano2812@gmail.com   \n",
       "1                0                0  ...  vicky.navdurga1989@gmail.com   \n",
       "2                0                0  ...       alaizagraham@icloud.com   \n",
       "3                0                0  ...           sabeeh_gd@yahoo.com   \n",
       "4                0                0  ...            nayreh55@gmail.com   \n",
       "\n",
       "   is_sales_managed  is_freshbooks_account_active  is_paying  \\\n",
       "0               0.0                           0.0        0.0   \n",
       "1               0.0                           1.0        0.0   \n",
       "2               0.0                           1.0        0.0   \n",
       "3               0.0                           1.0        0.0   \n",
       "4               0.0                           1.0        0.0   \n",
       "\n",
       "   avg_wc_description_day_7  avg_wc_notes_day_7  avg_wc_terms_day_7  \\\n",
       "0                       2.0                 6.0                 0.0   \n",
       "1                       0.0                 0.0                 0.0   \n",
       "2                       0.0                 0.0                 0.0   \n",
       "3                       0.0                 0.0                 0.0   \n",
       "4                       0.0                 0.0                 0.0   \n",
       "\n",
       "   avg_wc_address_day_7  invoice_count_day_7  client_count_day_7  \n",
       "0                   0.0                  1.0                 2.0  \n",
       "1                   0.0                  0.0                 1.0  \n",
       "2                   0.0                  0.0                 1.0  \n",
       "3                   0.0                  0.0                 1.0  \n",
       "4                   0.0                  0.0                 1.0  \n",
       "\n",
       "[5 rows x 249 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Head of the dataframe\n",
    "df_final_features_day_7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(452565, 249)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the dimension \n",
    "df_final_features_day_7.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Filtering FreshBooks test accounts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Filtering FreshBooks Test Accounts #############################################################\n",
    "\n",
    "# Import Freshbooks test accounts email from CSV file (non-freshbooks email)\n",
    "fb_test_emails = pd.read_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_fb_test_email/non-fb-testing-emails.csv\", \n",
    "                                      sep=\"\\n\")\n",
    "fb_test_email_list = list(fb_test_emails['email'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fb_test_email_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Filtering FB test account by using admin email\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def email_match(em, email_list):\n",
    "    \n",
    "    L = len(email_list)\n",
    "#     print('L', L)\n",
    "#     print('em-before-loop: ', em)\n",
    "    match_score = 0\n",
    "#     x = float(em)\n",
    "    \n",
    "    for i in range(0, L):\n",
    "#         if math.isnan(x):\n",
    "#             match_score = 0\n",
    "#             break;\n",
    "        if pd.isnull(em):\n",
    "            match_score = 0\n",
    "            break;\n",
    "        else: \n",
    "            match_score =  max(match_score, SequenceMatcher(None,em, email_list[i]).ratio())\n",
    "            print(i, em, email_list[i], match_score)\n",
    "\n",
    "    return match_score\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering final data from the FreshBooks Test emails\n",
    "# df_final_features_day_7 = df_final_features_day_7[\n",
    "#     df_final_features_day_7.apply(lambda x: email_match(x['admin_email'], fb_test_email_list) > 0.9, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV export \n",
    "df_final_features_day_7.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_7.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_final_features_day_7 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_7.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking\n",
    "df_final_features_day_7.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Final Features Data: Day 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Final Features Data: Day 14 Model ###########\n",
    "\n",
    "# Filtered the events columns for day 14 period\n",
    "df_events_all_accounts_day_14 = df_events_all_accounts[['systemid', 'event_count_day_14', 'event_name']]\n",
    "\n",
    "### Pivote the Day 14 Events (Each Unique Event Become a Column)###\n",
    "# Pivot table based on the unique column value in 'event_name'\n",
    "df_events_all_accounts_day_14 = df_events_all_accounts_day_14.pivot_table(values='event_count_day_14', columns='event_name', index='systemid', aggfunc=np.sum,  fill_value=0)\n",
    "\n",
    "# Drop the old column name\n",
    "df_events_all_accounts_day_14.columns.name = None\n",
    "\n",
    "# Reset the index\n",
    "df_events_all_accounts_day_14 = df_events_all_accounts_day_14.reset_index()\n",
    "\n",
    "# Replace 'NaN' with zero\n",
    "df_events_all_accounts_day_14.fillna(0, inplace=True)\n",
    "\n",
    "# CSV export \n",
    "df_events_all_accounts_day_14.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_14.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_events_all_accounts_day_14 = pd.read_csv(\"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_14.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Importing importing features list\n",
    "important_features = pd.read_csv( \n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/important_features.csv\", sep=\"\\n,\")\n",
    "\n",
    "# Get the important feature as a list\n",
    "imp_features_list = list(important_features['important_feature'])\n",
    "\n",
    "# Adding missing important feature column \n",
    "for i in range(len(imp_features_list)):\n",
    "    if imp_features_list[i] in df_events_all_accounts_day_14.columns:\n",
    "        print(\"True\")\n",
    "    else:\n",
    "        print(\"False\")\n",
    "        df_events_all_accounts_day_14[imp_features_list[i]] = 0\n",
    "\n",
    "# Filtering only important features \n",
    "df_events_imp_features_all_accounts_day_14 = \\\n",
    "            df_events_all_accounts_day_14.loc[:, df_events_all_accounts_day_14.columns.str.contains('|'.join(imp_features_list))]\n",
    "\n",
    "\n",
    "### Filtering average word counts features from the invoice data\n",
    "# Invoice features at day 14\n",
    "df_invoice_features_all_accounts_day_14 = df_periodic_invoice_all_counts[[\n",
    "        'systemid',\n",
    "        'admin_email',\n",
    "        'is_sales_managed', \n",
    "        'is_freshbooks_account_active',\n",
    "        'is_paying',\n",
    "        'avg_wc_description_day_14',\n",
    "        'avg_wc_notes_day_14',\n",
    "        'avg_wc_terms_day_14',\n",
    "        'avg_wc_address_day_14',\n",
    "        'invoice_count_day_14',\n",
    "        'client_count_day_14'\n",
    "        ]]\n",
    "\n",
    "# CSV export\n",
    "df_invoice_features_all_accounts_day_14.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_14.csv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_invoice_features_all_accounts_day_14 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_14.csv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Merging events' and invoice features\n",
    "df_final_features_day_14 = pd.merge(df_events_imp_features_all_accounts_day_14, \n",
    "                                   df_invoice_features_all_accounts_day_14,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "\n",
    "# Filtering final data from the FreshBooks Test emails\n",
    "# df_final_features_day_14 = df_final_features_day_14[\n",
    "#     df_final_features_day_14.apply(lambda x: email_match(x['admin_email'], fb_test_email_list) > 0.9, axis=1)]\n",
    "\n",
    "# CSV export \n",
    "df_final_features_day_14.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_14.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_final_features_day_14 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_14.tsv\", sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Final Featues Data: Day 21\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Final Features Data: Day 21 Model ###########\n",
    "\n",
    "# Filtered the events columns for day 21 period\n",
    "df_events_all_accounts_day_21 = df_events_all_accounts[['systemid', 'event_count_day_21', 'event_name']]\n",
    "\n",
    "### Pivote the Day 21 Events (Each Unique Event Become a Column)###\n",
    "# Pivot table based on the unique column value in 'event_name'\n",
    "df_events_all_accounts_day_21 = df_events_all_accounts_day_21.pivot_table(values='event_count_day_21', columns='event_name', index='systemid', aggfunc=np.sum,  fill_value=0)\n",
    "\n",
    "# Drop the old column name\n",
    "df_events_all_accounts_day_21.columns.name = None\n",
    "\n",
    "# Reset the index\n",
    "df_events_all_accounts_day_21 = df_events_all_accounts_day_21.reset_index()\n",
    "\n",
    "# Replace 'NaN' with zero\n",
    "df_events_all_accounts_day_21.fillna(0, inplace=True)\n",
    "\n",
    "# CSV export \n",
    "df_events_all_accounts_day_21.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_21.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_events_all_accounts_day_21 = pd.read_csv(\"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_21.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Importing importing features list\n",
    "important_features = pd.read_csv( \n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/important_features.csv\", sep=\"\\n,\")\n",
    "\n",
    "# Get the important feature as a list\n",
    "imp_features_list = list(important_features['important_feature'])\n",
    "\n",
    "# Adding missing important feature column \n",
    "for i in range(len(imp_features_list)):\n",
    "    if imp_features_list[i] in df_events_all_accounts_day_21.columns:\n",
    "        print(\"True\")\n",
    "    else:\n",
    "        print(\"False\")\n",
    "        df_events_all_accounts_day_21[imp_features_list[i]] = 0\n",
    "\n",
    "# Filtering only important features \n",
    "df_events_imp_features_all_accounts_day_21 = \\\n",
    "            df_events_all_accounts_day_21.loc[:, df_events_all_accounts_day_21.columns.str.contains('|'.join(imp_features_list))]\n",
    "\n",
    "\n",
    "### Filtering average word counts features from the invoice data\n",
    "# Invoice features at day 21\n",
    "df_invoice_features_all_accounts_day_21 = df_periodic_invoice_all_counts[[\n",
    "        'systemid',\n",
    "        'admin_email',\n",
    "        'is_sales_managed', \n",
    "        'is_freshbooks_account_active',\n",
    "        'is_paying',\n",
    "        'avg_wc_description_day_21',\n",
    "        'avg_wc_notes_day_21',\n",
    "        'avg_wc_terms_day_21',\n",
    "        'avg_wc_address_day_21',\n",
    "        'invoice_count_day_21',\n",
    "        'client_count_day_21'\n",
    "        ]]\n",
    "\n",
    "# CSV export\n",
    "df_invoice_features_all_accounts_day_21.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_21.csv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_invoice_features_all_accounts_day_21 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_21.csv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Merging events' and invoice features\n",
    "df_final_features_day_21 = pd.merge(df_events_imp_features_all_accounts_day_21, \n",
    "                                   df_invoice_features_all_accounts_day_21,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "\n",
    "# Filtering final data from the FreshBooks Test emails\n",
    "# df_final_features_day_21 = df_final_features_day_21[\n",
    "#     df_final_features_day_21.apply(lambda x: email_match(x['admin_email'], fb_test_email_list) > 0.9, axis=1)]\n",
    "\n",
    "# CSV export \n",
    "df_final_features_day_21.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_21.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_final_features_day_21 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_21.tsv\", sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Final Features Extraction: Day 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Final Features Data: Day 28 Model ###########\n",
    "\n",
    "# Filtered the events columns for day 28 period\n",
    "df_events_all_accounts_day_28 = df_events_all_accounts[['systemid', 'event_count_day_28', 'event_name']]\n",
    "\n",
    "### Pivote the Day 28 Events (Each Unique Event Become a Column)###\n",
    "# Pivot table based on the unique column value in 'event_name'\n",
    "df_events_all_accounts_day_28 = df_events_all_accounts_day_28.pivot_table(values='event_count_day_28', columns='event_name', index='systemid', aggfunc=np.sum,  fill_value=0)\n",
    "\n",
    "# Drop the old column name\n",
    "df_events_all_accounts_day_28.columns.name = None\n",
    "\n",
    "# Reset the index\n",
    "df_events_all_accounts_day_28 = df_events_all_accounts_day_28.reset_index()\n",
    "\n",
    "# Replace 'NaN' with zero\n",
    "df_events_all_accounts_day_28.fillna(0, inplace=True)\n",
    "\n",
    "# CSV export \n",
    "df_events_all_accounts_day_28.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_28.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_events_all_accounts_day_28 = pd.read_csv(\"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_28.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Importing importing features list\n",
    "important_features = pd.read_csv( \n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/important_features.csv\", sep=\"\\n,\")\n",
    "\n",
    "# Get the important feature as a list\n",
    "imp_features_list = list(important_features['important_feature'])\n",
    "\n",
    "# Adding missing important feature column \n",
    "for i in range(len(imp_features_list)):\n",
    "    if imp_features_list[i] in df_events_all_accounts_day_28.columns:\n",
    "        print(\"True\")\n",
    "    else:\n",
    "        print(\"False\")\n",
    "        df_events_all_accounts_day_28[imp_features_list[i]] = 0\n",
    "\n",
    "# Filtering only important features \n",
    "df_events_imp_features_all_accounts_day_28 = \\\n",
    "            df_events_all_accounts_day_28.loc[:, df_events_all_accounts_day_28.columns.str.contains('|'.join(imp_features_list))]\n",
    "\n",
    "\n",
    "### Filtering average word counts features from the invoice data\n",
    "# Invoice features at day 28\n",
    "df_invoice_features_all_accounts_day_28 = df_periodic_invoice_all_counts[[\n",
    "        'systemid',\n",
    "        'admin_email', \n",
    "        'is_sales_managed', \n",
    "        'is_freshbooks_account_active',\n",
    "        'is_paying',\n",
    "        'avg_wc_description_day_28',\n",
    "        'avg_wc_notes_day_28',\n",
    "        'avg_wc_terms_day_28',\n",
    "        'avg_wc_address_day_28',\n",
    "        'invoice_count_day_28',\n",
    "        'client_count_day_28'\n",
    "        ]]\n",
    "\n",
    "# CSV export\n",
    "df_invoice_features_all_accounts_day_28.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_28.csv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_invoice_features_all_accounts_day_28 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_28.csv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Merging events' and invoice features\n",
    "df_final_features_day_28 = pd.merge(df_events_imp_features_all_accounts_day_28, \n",
    "                                   df_invoice_features_all_accounts_day_28,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# Filtering final data from the FreshBooks Test emails\n",
    "# df_final_features_day_28 = df_final_features_day_28[\n",
    "#     df_final_features_day_28.apply(lambda x: email_match(x['admin_email'], fb_test_email_list) > 0.9, axis=1)]\n",
    "\n",
    "# CSV export \n",
    "df_final_features_day_28.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_28.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_final_features_day_28 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_28.tsv\", sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Final Features Extraction: Day 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Final Features Data: Day 35 Model ###########\n",
    "\n",
    "# Filtered the events columns for day 35 period\n",
    "df_events_all_accounts_day_35 = df_events_all_accounts[['systemid', 'event_count_day_35', 'event_name']]\n",
    "\n",
    "### Pivote the Day 35 Events (Each Unique Event Become a Column)###\n",
    "# Pivot table based on the unique column value in 'event_name'\n",
    "df_events_all_accounts_day_35 = df_events_all_accounts_day_35.pivot_table(values='event_count_day_35', columns='event_name', index='systemid', aggfunc=np.sum,  fill_value=0)\n",
    "\n",
    "# Drop the old column name\n",
    "df_events_all_accounts_day_35.columns.name = None\n",
    "\n",
    "# Reset the index\n",
    "df_events_all_accounts_day_35 = df_events_all_accounts_day_35.reset_index()\n",
    "\n",
    "# Replace 'NaN' with zero\n",
    "df_events_all_accounts_day_35.fillna(0, inplace=True)\n",
    "\n",
    "# CSV export \n",
    "df_events_all_accounts_day_35.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_35.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_events_all_accounts_day_35 = pd.read_csv(\"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_35.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Importing importing features list\n",
    "important_features = pd.read_csv( \n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/important_features.csv\", sep=\"\\n,\")\n",
    "\n",
    "# Get the important feature as a list\n",
    "imp_features_list = list(important_features['important_feature'])\n",
    "\n",
    "# Adding missing important feature column \n",
    "for i in range(len(imp_features_list)):\n",
    "    if imp_features_list[i] in df_events_all_accounts_day_35.columns:\n",
    "        print(\"True\")\n",
    "    else:\n",
    "        print(\"False\")\n",
    "        df_events_all_accounts_day_35[imp_features_list[i]] = 0\n",
    "\n",
    "# Filtering only important features \n",
    "df_events_imp_features_all_accounts_day_35 = \\\n",
    "            df_events_all_accounts_day_35.loc[:, df_events_all_accounts_day_35.columns.str.contains('|'.join(imp_features_list))]\n",
    "\n",
    "\n",
    "### Filtering average word counts features from the invoice data\n",
    "# Invoice features at day 35\n",
    "df_invoice_features_all_accounts_day_35 = df_periodic_invoice_all_counts[[\n",
    "        'systemid',\n",
    "        'admin_email',\n",
    "        'is_sales_managed', \n",
    "        'is_freshbooks_account_active',\n",
    "        'is_paying',\n",
    "        'avg_wc_description_day_35',\n",
    "        'avg_wc_notes_day_35',\n",
    "        'avg_wc_terms_day_35',\n",
    "        'avg_wc_address_day_35',\n",
    "        'invoice_count_day_35',\n",
    "        'client_count_day_35'\n",
    "        ]]\n",
    "\n",
    "# CSV export\n",
    "df_invoice_features_all_accounts_day_35.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_35.csv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_invoice_features_all_accounts_day_35 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_35.csv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Merging events' and invoice features\n",
    "df_final_features_day_35 = pd.merge(df_events_imp_features_all_accounts_day_35, \n",
    "                                   df_invoice_features_all_accounts_day_35,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# Filtering final data from the FreshBooks Test emails\n",
    "# df_final_features_day_35 = df_final_features_day_35[\n",
    "#     df_final_features_day_35.apply(lambda x: email_match(x['admin_email'], fb_test_email_list) > 0.9, axis=1)]\n",
    "\n",
    "# CSV export \n",
    "df_final_features_day_35.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_35.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_final_features_day_35 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_35.tsv\", sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Final Features Extraction: Day 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Final Features Data: Day 42 Model ###########\n",
    "\n",
    "# Filtered the events columns for day 42 period\n",
    "df_events_all_accounts_day_42 = df_events_all_accounts[['systemid', 'event_count_day_42', 'event_name']]\n",
    "\n",
    "### Pivote the Day 42 Events (Each Unique Event Become a Column)###\n",
    "# Pivot table based on the unique column value in 'event_name'\n",
    "df_events_all_accounts_day_42 = df_events_all_accounts_day_42.pivot_table(values='event_count_day_42', columns='event_name', index='systemid', aggfunc=np.sum,  fill_value=0)\n",
    "\n",
    "# Drop the old column name\n",
    "df_events_all_accounts_day_42.columns.name = None\n",
    "\n",
    "# Reset the index\n",
    "df_events_all_accounts_day_42 = df_events_all_accounts_day_42.reset_index()\n",
    "\n",
    "# Replace 'NaN' with zero\n",
    "df_events_all_accounts_day_42.fillna(0, inplace=True)\n",
    "\n",
    "# CSV export \n",
    "df_events_all_accounts_day_42.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_42.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_events_all_accounts_day_42 = pd.read_csv(\"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_42.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Importing importing features list\n",
    "important_features = pd.read_csv( \n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/important_features.csv\", sep=\"\\n,\")\n",
    "\n",
    "# Get the important feature as a list\n",
    "imp_features_list = list(important_features['important_feature'])\n",
    "\n",
    "# Adding missing important feature column \n",
    "for i in range(len(imp_features_list)):\n",
    "    if imp_features_list[i] in df_events_all_accounts_day_42.columns:\n",
    "        print(\"True\")\n",
    "    else:\n",
    "        print(\"False\")\n",
    "        df_events_all_accounts_day_42[imp_features_list[i]] = 0\n",
    "\n",
    "# Filtering only important features \n",
    "df_events_imp_features_all_accounts_day_42 = \\\n",
    "            df_events_all_accounts_day_42.loc[:, df_events_all_accounts_day_42.columns.str.contains('|'.join(imp_features_list))]\n",
    "\n",
    "\n",
    "### Filtering average word counts features from the invoice data\n",
    "# Invoice features at day 42\n",
    "df_invoice_features_all_accounts_day_42 = df_periodic_invoice_all_counts[[\n",
    "        'systemid',\n",
    "        'admin_email',\n",
    "        'is_sales_managed', \n",
    "        'is_freshbooks_account_active',\n",
    "        'is_paying',\n",
    "        'avg_wc_description_day_42',\n",
    "        'avg_wc_notes_day_42',\n",
    "        'avg_wc_terms_day_42',\n",
    "        'avg_wc_address_day_42',\n",
    "        'invoice_count_day_42',\n",
    "        'client_count_day_42'\n",
    "        ]]\n",
    "\n",
    "# CSV export\n",
    "df_invoice_features_all_accounts_day_42.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_42.csv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_invoice_features_all_accounts_day_42 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_42.csv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Merging events' and invoice features\n",
    "df_final_features_day_42 = pd.merge(df_events_imp_features_all_accounts_day_42, \n",
    "                                   df_invoice_features_all_accounts_day_42,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# Filtering final data from the FreshBooks Test emails\n",
    "# df_final_features_day_42 = df_final_features_day_42[\n",
    "#     df_final_features_day_42.apply(lambda x: email_match(x['admin_email'], fb_test_email_list) > 0.9, axis=1)]\n",
    "\n",
    "# CSV export \n",
    "df_final_features_day_42.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_42.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_final_features_day_42 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_42.tsv\", sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Final Features Data: Day 49 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Final Features Data: Day 49 Model ###########\n",
    "\n",
    "# Filtered the events columns for day 49 period\n",
    "df_events_all_accounts_day_49 = df_events_all_accounts[['systemid', 'event_count_day_49', 'event_name']]\n",
    "\n",
    "### Pivote the Day 49 Events (Each Unique Event Become a Column)###\n",
    "# Pivot table based on the unique column value in 'event_name'\n",
    "df_events_all_accounts_day_49 = df_events_all_accounts_day_49.pivot_table(values='event_count_day_49', columns='event_name', index='systemid', aggfunc=np.sum,  fill_value=0)\n",
    "\n",
    "# Drop the old column name\n",
    "df_events_all_accounts_day_49.columns.name = None\n",
    "\n",
    "# Reset the index\n",
    "df_events_all_accounts_day_49 = df_events_all_accounts_day_49.reset_index()\n",
    "\n",
    "# Replace 'NaN' with zero\n",
    "df_events_all_accounts_day_49.fillna(0, inplace=True)\n",
    "\n",
    "# CSV export \n",
    "df_events_all_accounts_day_49.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_49.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_events_all_accounts_day_49 = pd.read_csv(\"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_49.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Importing importing features list\n",
    "important_features = pd.read_csv( \n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/important_features.csv\", sep=\"\\n,\")\n",
    "\n",
    "# Get the important feature as a list\n",
    "imp_features_list = list(important_features['important_feature'])\n",
    "\n",
    "# Adding missing important feature column \n",
    "for i in range(len(imp_features_list)):\n",
    "    if imp_features_list[i] in df_events_all_accounts_day_49.columns:\n",
    "        print(\"True\")\n",
    "    else:\n",
    "        print(\"False\")\n",
    "        df_events_all_accounts_day_49[imp_features_list[i]] = 0\n",
    "\n",
    "# Filtering only important features \n",
    "df_events_imp_features_all_accounts_day_49 = \\\n",
    "            df_events_all_accounts_day_49.loc[:, df_events_all_accounts_day_49.columns.str.contains('|'.join(imp_features_list))]\n",
    "\n",
    "\n",
    "### Filtering average word counts features from the invoice data\n",
    "# Invoice features at day 49\n",
    "df_invoice_features_all_accounts_day_49 = df_periodic_invoice_all_counts[[\n",
    "        'systemid',\n",
    "        'admin_email',\n",
    "        'is_sales_managed', \n",
    "        'is_freshbooks_account_active',\n",
    "        'is_paying',\n",
    "        'avg_wc_description_day_49',\n",
    "        'avg_wc_notes_day_49',\n",
    "        'avg_wc_terms_day_49',\n",
    "        'avg_wc_address_day_49',\n",
    "        'invoice_count_day_49',\n",
    "        'client_count_day_49'\n",
    "        ]]\n",
    "\n",
    "# CSV export\n",
    "df_invoice_features_all_accounts_day_49.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_49.csv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_invoice_features_all_accounts_day_49 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_49.csv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Merging events' and invoice features\n",
    "df_final_features_day_49 = pd.merge(df_events_imp_features_all_accounts_day_49, \n",
    "                                   df_invoice_features_all_accounts_day_49,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# Filtering final data from the FreshBooks Test emails\n",
    "# df_final_features_day_49 = df_final_features_day_49[\n",
    "#     df_final_features_day_49.apply(lambda x: email_match(x['admin_email'], fb_test_email_list) > 0.9, axis=1)]\n",
    "\n",
    "# CSV export \n",
    "df_final_features_day_49.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_49.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_final_features_day_49 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_49.tsv\", sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Final Feature Data: Day 56 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Final Features Data: Day 56 Model ###########\n",
    "\n",
    "# Filtered the events columns for day 56 period\n",
    "df_events_all_accounts_day_56 = df_events_all_accounts[['systemid', 'event_count_day_56', 'event_name']]\n",
    "\n",
    "### Pivote the Day 56 Events (Each Unique Event Become a Column)###\n",
    "# Pivot table based on the unique column value in 'event_name'\n",
    "df_events_all_accounts_day_56 = df_events_all_accounts_day_56.pivot_table(values='event_count_day_56', columns='event_name', index='systemid', aggfunc=np.sum,  fill_value=0)\n",
    "\n",
    "# Drop the old column name\n",
    "df_events_all_accounts_day_56.columns.name = None\n",
    "\n",
    "# Reset the index\n",
    "df_events_all_accounts_day_56 = df_events_all_accounts_day_56.reset_index()\n",
    "\n",
    "# Replace 'NaN' with zero\n",
    "df_events_all_accounts_day_56.fillna(0, inplace=True)\n",
    "\n",
    "# CSV export \n",
    "df_events_all_accounts_day_56.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_56.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_events_all_accounts_day_56 = pd.read_csv(\"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_56.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Importing importing features list\n",
    "important_features = pd.read_csv( \n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/important_features.csv\", sep=\"\\n,\")\n",
    "\n",
    "# Get the important feature as a list\n",
    "imp_features_list = list(important_features['important_feature'])\n",
    "\n",
    "# Adding missing important feature column \n",
    "for i in range(len(imp_features_list)):\n",
    "    if imp_features_list[i] in df_events_all_accounts_day_56.columns:\n",
    "        print(\"True\")\n",
    "    else:\n",
    "        print(\"False\")\n",
    "        df_events_all_accounts_day_56[imp_features_list[i]] = 0\n",
    "\n",
    "# Filtering only important features \n",
    "df_events_imp_features_all_accounts_day_56 = \\\n",
    "            df_events_all_accounts_day_56.loc[:, df_events_all_accounts_day_56.columns.str.contains('|'.join(imp_features_list))]\n",
    "\n",
    "\n",
    "### Filtering average word counts features from the invoice data\n",
    "# Invoice features at day 56\n",
    "df_invoice_features_all_accounts_day_56 = df_periodic_invoice_all_counts[[\n",
    "        'systemid',\n",
    "        'admin_email',\n",
    "        'is_sales_managed', \n",
    "        'is_freshbooks_account_active',\n",
    "        'is_paying',\n",
    "        'avg_wc_description_day_56',\n",
    "        'avg_wc_notes_day_56',\n",
    "        'avg_wc_terms_day_56',\n",
    "        'avg_wc_address_day_56',\n",
    "        'invoice_count_day_56',\n",
    "        'client_count_day_56'\n",
    "        ]]\n",
    "\n",
    "# CSV export\n",
    "df_invoice_features_all_accounts_day_56.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_56.csv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_invoice_features_all_accounts_day_56 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_56.csv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Merging events' and invoice features\n",
    "df_final_features_day_56 = pd.merge(df_events_imp_features_all_accounts_day_56, \n",
    "                                   df_invoice_features_all_accounts_day_56,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# Filtering final data from the FreshBooks Test emails\n",
    "df_final_features_day_56 = df_final_features_day_56[\n",
    "    df_final_features_day_56.apply(lambda x: email_match(x['admin_email'], fb_test_email_list) > 0.9, axis=1)]\n",
    "\n",
    "# CSV export \n",
    "df_final_features_day_56.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_56.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_final_features_day_56 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_56.tsv\", sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Final Features Data: Day 63 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Final Features Data: Day 63 Model ###########\n",
    "\n",
    "# Filtered the events columns for day 63 period\n",
    "df_events_all_accounts_day_63 = df_events_all_accounts[['systemid', 'event_count_day_63', 'event_name']]\n",
    "\n",
    "### Pivote the Day 63 Events (Each Unique Event Become a Column)###\n",
    "# Pivot table based on the unique column value in 'event_name'\n",
    "df_events_all_accounts_day_63 = df_events_all_accounts_day_63.pivot_table(values='event_count_day_63', columns='event_name', index='systemid', aggfunc=np.sum,  fill_value=0)\n",
    "\n",
    "# Drop the old column name\n",
    "df_events_all_accounts_day_63.columns.name = None\n",
    "\n",
    "# Reset the index\n",
    "df_events_all_accounts_day_63 = df_events_all_accounts_day_63.reset_index()\n",
    "\n",
    "# Replace 'NaN' with zero\n",
    "df_events_all_accounts_day_63.fillna(0, inplace=True)\n",
    "\n",
    "# CSV export \n",
    "df_events_all_accounts_day_63.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_63.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_events_all_accounts_day_63 = pd.read_csv(\"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_63.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Importing importing features list\n",
    "important_features = pd.read_csv( \n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/important_features.csv\", sep=\"\\n,\")\n",
    "\n",
    "# Get the important feature as a list\n",
    "imp_features_list = list(important_features['important_feature'])\n",
    "\n",
    "# Adding missing important feature column \n",
    "for i in range(len(imp_features_list)):\n",
    "    if imp_features_list[i] in df_events_all_accounts_day_63.columns:\n",
    "        print(\"True\")\n",
    "    else:\n",
    "        print(\"False\")\n",
    "        df_events_all_accounts_day_63[imp_features_list[i]] = 0\n",
    "\n",
    "# Filtering only important features \n",
    "df_events_imp_features_all_accounts_day_63 = \\\n",
    "            df_events_all_accounts_day_63.loc[:, df_events_all_accounts_day_63.columns.str.contains('|'.join(imp_features_list))]\n",
    "\n",
    "\n",
    "### Filtering average word counts features from the invoice data\n",
    "# Invoice features at day 63\n",
    "df_invoice_features_all_accounts_day_63 = df_periodic_invoice_all_counts[[\n",
    "        'systemid',\n",
    "        'admin_email',\n",
    "        'is_sales_managed', \n",
    "        'is_freshbooks_account_active',\n",
    "        'is_paying',\n",
    "        'avg_wc_description_day_63',\n",
    "        'avg_wc_notes_day_63',\n",
    "        'avg_wc_terms_day_63',\n",
    "        'avg_wc_address_day_63',\n",
    "        'invoice_count_day_63',\n",
    "        'client_count_day_63'\n",
    "        ]]\n",
    "\n",
    "# CSV export\n",
    "df_invoice_features_all_accounts_day_63.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_63.csv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_invoice_features_all_accounts_day_63 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_63.csv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Merging events' and invoice features\n",
    "df_final_features_day_63 = pd.merge(df_events_imp_features_all_accounts_day_63, \n",
    "                                   df_invoice_features_all_accounts_day_63,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# Filtering final data from the FreshBooks Test emails\n",
    "df_final_features_day_63 = df_final_features_day_63[\n",
    "    df_final_features_day_63.apply(lambda x: email_match(x['admin_email'], fb_test_email_list) > 0.9, axis=1)]\n",
    "\n",
    "# CSV export \n",
    "df_final_features_day_63.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_63.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_final_features_day_63 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_63.tsv\", sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. Final Features Data: Day 70 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Final Features Data: Day 700 Model ###########\n",
    "\n",
    "# Filtered the events columns for day 700 period\n",
    "df_events_all_accounts_day_700 = df_events_all_accounts[['systemid', 'event_count_day_700', 'event_name']]\n",
    "\n",
    "### Pivote the Day 700 Events (Each Unique Event Become a Column)###\n",
    "# Pivot table based on the unique column value in 'event_name'\n",
    "df_events_all_accounts_day_700 = df_events_all_accounts_day_700.pivot_table(values='event_count_day_700', columns='event_name', index='systemid', aggfunc=np.sum,  fill_value=0)\n",
    "\n",
    "# Drop the old column name\n",
    "df_events_all_accounts_day_700.columns.name = None\n",
    "\n",
    "# Reset the index\n",
    "df_events_all_accounts_day_700 = df_events_all_accounts_day_700.reset_index()\n",
    "\n",
    "# Replace 'NaN' with zero\n",
    "df_events_all_accounts_day_700.fillna(0, inplace=True)\n",
    "\n",
    "# CSV export \n",
    "df_events_all_accounts_day_700.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_700.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_events_all_accounts_day_700 = pd.read_csv(\"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_700.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Importing importing features list\n",
    "important_features = pd.read_csv( \n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/important_features.csv\", sep=\"\\n,\")\n",
    "\n",
    "# Get the important feature as a list\n",
    "imp_features_list = list(important_features['important_feature'])\n",
    "\n",
    "# Adding missing important feature column \n",
    "for i in range(len(imp_features_list)):\n",
    "    if imp_features_list[i] in df_events_all_accounts_day_700.columns:\n",
    "        print(\"True\")\n",
    "    else:\n",
    "        print(\"False\")\n",
    "        df_events_all_accounts_day_700[imp_features_list[i]] = 0\n",
    "\n",
    "# Filtering only important features \n",
    "df_events_imp_features_all_accounts_day_700 = \\\n",
    "            df_events_all_accounts_day_700.loc[:, df_events_all_accounts_day_700.columns.str.contains('|'.join(imp_features_list))]\n",
    "\n",
    "\n",
    "### Filtering average word counts features from the invoice data\n",
    "# Invoice features at day 700\n",
    "df_invoice_features_all_accounts_day_700 = df_periodic_invoice_all_counts[[\n",
    "        'systemid',\n",
    "        'admin_email',\n",
    "        'is_sales_managed', \n",
    "        'is_freshbooks_account_active',\n",
    "        'is_paying',\n",
    "        'avg_wc_description_day_700',\n",
    "        'avg_wc_notes_day_700',\n",
    "        'avg_wc_terms_day_700',\n",
    "        'avg_wc_address_day_700',\n",
    "        'invoice_count_day_700',\n",
    "        'client_count_day_700'\n",
    "        ]]\n",
    "\n",
    "# CSV export\n",
    "df_invoice_features_all_accounts_day_700.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_700.csv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_invoice_features_all_accounts_day_700 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_700.csv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Merging events' and invoice features\n",
    "df_final_features_day_700 = pd.merge(df_events_imp_features_all_accounts_day_700, \n",
    "                                   df_invoice_features_all_accounts_day_700,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# Filtering final data from the FreshBooks Test emails\n",
    "df_final_features_day_70 = df_final_features_day_70[\n",
    "    df_final_features_day_70.apply(lambda x: email_match(x['admin_email'], fb_test_email_list) > 0.9, axis=1)]\n",
    "\n",
    "# CSV export \n",
    "df_final_features_day_700.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_700.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_final_features_day_700 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_700.tsv\", sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. Final Features Data: Day 77 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Final Features Data: Day 77 Model ###########\n",
    "\n",
    "# Filtered the events columns for day 77 period\n",
    "df_events_all_accounts_day_77 = df_events_all_accounts[['systemid', 'event_count_day_77', 'event_name']]\n",
    "\n",
    "### Pivote the Day 77 Events (Each Unique Event Become a Column)###\n",
    "# Pivot table based on the unique column value in 'event_name'\n",
    "df_events_all_accounts_day_77 = df_events_all_accounts_day_77.pivot_table(values='event_count_day_77', columns='event_name', index='systemid', aggfunc=np.sum,  fill_value=0)\n",
    "\n",
    "# Drop the old column name\n",
    "df_events_all_accounts_day_77.columns.name = None\n",
    "\n",
    "# Reset the index\n",
    "df_events_all_accounts_day_77 = df_events_all_accounts_day_77.reset_index()\n",
    "\n",
    "# Replace 'NaN' with zero\n",
    "df_events_all_accounts_day_77.fillna(0, inplace=True)\n",
    "\n",
    "# CSV export \n",
    "df_events_all_accounts_day_77.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_77.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_events_all_accounts_day_77 = pd.read_csv(\"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_77.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Importing importing features list\n",
    "important_features = pd.read_csv( \n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/important_features.csv\", sep=\"\\n,\")\n",
    "\n",
    "# Get the important feature as a list\n",
    "imp_features_list = list(important_features['important_feature'])\n",
    "\n",
    "# Adding missing important feature column \n",
    "for i in range(len(imp_features_list)):\n",
    "    if imp_features_list[i] in df_events_all_accounts_day_77.columns:\n",
    "        print(\"True\")\n",
    "    else:\n",
    "        print(\"False\")\n",
    "        df_events_all_accounts_day_77[imp_features_list[i]] = 0\n",
    "\n",
    "# Filtering only important features \n",
    "df_events_imp_features_all_accounts_day_77 = \\\n",
    "            df_events_all_accounts_day_77.loc[:, df_events_all_accounts_day_77.columns.str.contains('|'.join(imp_features_list))]\n",
    "\n",
    "\n",
    "### Filtering average word counts features from the invoice data\n",
    "# Invoice features at day 77\n",
    "df_invoice_features_all_accounts_day_77 = df_periodic_invoice_all_counts[[\n",
    "        'systemid',\n",
    "        'admin_email',\n",
    "        'is_sales_managed', \n",
    "        'is_freshbooks_account_active',\n",
    "        'is_paying',\n",
    "        'avg_wc_description_day_77',\n",
    "        'avg_wc_notes_day_77',\n",
    "        'avg_wc_terms_day_77',\n",
    "        'avg_wc_address_day_77',\n",
    "        'invoice_count_day_77',\n",
    "        'client_count_day_77'\n",
    "        ]]\n",
    "\n",
    "# CSV export\n",
    "df_invoice_features_all_accounts_day_77.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_77.csv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_invoice_features_all_accounts_day_77 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_77.csv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Merging events' and invoice features\n",
    "df_final_features_day_77 = pd.merge(df_events_imp_features_all_accounts_day_77, \n",
    "                                   df_invoice_features_all_accounts_day_77,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# Filtering final data from the FreshBooks Test emails\n",
    "df_final_features_day_77 = df_final_features_day_77[\n",
    "    df_final_features_day_77.apply(lambda x: email_match(x['admin_email'], fb_test_email_list) > 0.9, axis=1)]\n",
    "\n",
    "# CSV export \n",
    "df_final_features_day_77.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_77.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_final_features_day_77 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_77.tsv\", sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Final Features Data: Day 84 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Final Features Data: Day 84 Model ###########\n",
    "\n",
    "# Filtered the events columns for day 84 period\n",
    "df_events_all_accounts_day_84 = df_events_all_accounts[['systemid', 'event_count_day_84', 'event_name']]\n",
    "\n",
    "### Pivote the Day 84 Events (Each Unique Event Become a Column)###\n",
    "# Pivot table based on the unique column value in 'event_name'\n",
    "df_events_all_accounts_day_84 = df_events_all_accounts_day_84.pivot_table(values='event_count_day_84', columns='event_name', index='systemid', aggfunc=np.sum,  fill_value=0)\n",
    "\n",
    "# Drop the old column name\n",
    "df_events_all_accounts_day_84.columns.name = None\n",
    "\n",
    "# Reset the index\n",
    "df_events_all_accounts_day_84 = df_events_all_accounts_day_84.reset_index()\n",
    "\n",
    "# Replace 'NaN' with zero\n",
    "df_events_all_accounts_day_84.fillna(0, inplace=True)\n",
    "\n",
    "# CSV export \n",
    "df_events_all_accounts_day_84.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_84.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_events_all_accounts_day_84 = pd.read_csv(\"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_84.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Importing importing features list\n",
    "important_features = pd.read_csv( \n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/important_features.csv\", sep=\"\\n,\")\n",
    "\n",
    "# Get the important feature as a list\n",
    "imp_features_list = list(important_features['important_feature'])\n",
    "\n",
    "# Adding missing important feature column \n",
    "for i in range(len(imp_features_list)):\n",
    "    if imp_features_list[i] in df_events_all_accounts_day_84.columns:\n",
    "        print(\"True\")\n",
    "    else:\n",
    "        print(\"False\")\n",
    "        df_events_all_accounts_day_84[imp_features_list[i]] = 0\n",
    "\n",
    "# Filtering only important features \n",
    "df_events_imp_features_all_accounts_day_84 = \\\n",
    "            df_events_all_accounts_day_84.loc[:, df_events_all_accounts_day_84.columns.str.contains('|'.join(imp_features_list))]\n",
    "\n",
    "\n",
    "### Filtering average word counts features from the invoice data\n",
    "# Invoice features at day 84\n",
    "df_invoice_features_all_accounts_day_84 = df_periodic_invoice_all_counts[[\n",
    "        'systemid',\n",
    "        'admin_email', \n",
    "        'is_sales_managed', \n",
    "        'is_freshbooks_account_active',\n",
    "        'is_paying',\n",
    "        'avg_wc_description_day_84',\n",
    "        'avg_wc_notes_day_84',\n",
    "        'avg_wc_terms_day_84',\n",
    "        'avg_wc_address_day_84',\n",
    "        'invoice_count_day_84',\n",
    "        'client_count_day_84'\n",
    "        ]]\n",
    "\n",
    "# CSV export\n",
    "df_invoice_features_all_accounts_day_84.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_84.csv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_invoice_features_all_accounts_day_84 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_84.csv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Merging events' and invoice features\n",
    "df_final_features_day_84 = pd.merge(df_events_imp_features_all_accounts_day_84, \n",
    "                                   df_invoice_features_all_accounts_day_84,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# Filtering final data from the FreshBooks Test emails\n",
    "df_final_features_day_84 = df_final_features_day_84[\n",
    "    df_final_features_day_84.apply(lambda x: email_match(x['admin_email'], fb_test_email_list) > 0.9, axis=1)]\n",
    "\n",
    "# CSV export \n",
    "df_final_features_day_84.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_84.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_final_features_day_84 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_84.tsv\", sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20. Final Features Data: Day 91 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Final Features Data: Day 91 Model ###########\n",
    "\n",
    "# Filtered the events columns for day 91 period\n",
    "df_events_all_accounts_day_91 = df_events_all_accounts[['systemid', 'event_count_day_91', 'event_name']]\n",
    "\n",
    "### Pivote the Day 91 Events (Each Unique Event Become a Column)###\n",
    "# Pivot table based on the unique column value in 'event_name'\n",
    "df_events_all_accounts_day_91 = df_events_all_accounts_day_91.pivot_table(values='event_count_day_91', columns='event_name', index='systemid', aggfunc=np.sum,  fill_value=0)\n",
    "\n",
    "# Drop the old column name\n",
    "df_events_all_accounts_day_91.columns.name = None\n",
    "\n",
    "# Reset the index\n",
    "df_events_all_accounts_day_91 = df_events_all_accounts_day_91.reset_index()\n",
    "\n",
    "# Replace 'NaN' with zero\n",
    "df_events_all_accounts_day_91.fillna(0, inplace=True)\n",
    "\n",
    "# CSV export \n",
    "df_events_all_accounts_day_91.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_91.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_events_all_accounts_day_91 = pd.read_csv(\"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/events_all_accounts_day_91.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Importing importing features list\n",
    "important_features = pd.read_csv( \n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/important_features.csv\", sep=\"\\n,\")\n",
    "\n",
    "# Get the important feature as a list\n",
    "imp_features_list = list(important_features['important_feature'])\n",
    "\n",
    "# Adding missing important feature column \n",
    "for i in range(len(imp_features_list)):\n",
    "    if imp_features_list[i] in df_events_all_accounts_day_91.columns:\n",
    "        print(\"True\")\n",
    "    else:\n",
    "        print(\"False\")\n",
    "        df_events_all_accounts_day_91[imp_features_list[i]] = 0\n",
    "\n",
    "# Filtering only important features \n",
    "df_events_imp_features_all_accounts_day_91 = \\\n",
    "            df_events_all_accounts_day_91.loc[:, df_events_all_accounts_day_91.columns.str.contains('|'.join(imp_features_list))]\n",
    "\n",
    "\n",
    "### Filtering average word counts features from the invoice data\n",
    "# Invoice features at day 91\n",
    "df_invoice_features_all_accounts_day_91 = df_periodic_invoice_all_counts[[\n",
    "        'systemid',\n",
    "        'admin_email',\n",
    "        'is_sales_managed', \n",
    "        'is_freshbooks_account_active',\n",
    "        'is_paying',\n",
    "        'avg_wc_description_day_91',\n",
    "        'avg_wc_notes_day_91',\n",
    "        'avg_wc_terms_day_91',\n",
    "        'avg_wc_address_day_91',\n",
    "        'invoice_count_day_91',\n",
    "        'client_count_day_91'\n",
    "        ]]\n",
    "\n",
    "# CSV export\n",
    "df_invoice_features_all_accounts_day_91.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_91.csv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_invoice_features_all_accounts_day_91 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_v1/invoice_features_all_accounts_day_91.csv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Merging events' and invoice features\n",
    "df_final_features_day_91 = pd.merge(df_events_imp_features_all_accounts_day_91, \n",
    "                                   df_invoice_features_all_accounts_day_91,\n",
    "                                     on='systemid', how='left')\n",
    "\n",
    "# Filtering final data from the FreshBooks Test emails\n",
    "df_final_features_day_91 = df_final_features_day_91[\n",
    "    df_final_features_day_91.apply(lambda x: email_match(x['admin_email'], fb_test_email_list) > 0.9, axis=1)]\n",
    "\n",
    "# CSV export \n",
    "df_final_features_day_91.to_csv(\n",
    "    \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_91.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Import CSV\n",
    "# df_final_features_day_91 = pd.read_csv(\n",
    "#     \"/Users/dwahid/Documents/GitHub/fraud_detection/data_final/final_features_day_91.tsv\", sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
