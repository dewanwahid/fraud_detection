{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script 02: Merging and Saving Labeled Fraud Risk Accounts\n",
    "\n",
    "Please run this script only after labeling today's pulled fraud risk account. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "\n",
    "from scipy import stats\n",
    "get_ipython().magic(u'config IPCompleter.greedy=True')\n",
    "today = str(date.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Please enter the date of the labled data file that you are mergin and saving now\n",
    "\n",
    "# date_ = today  # if you are pusing today's labaled data file\n",
    "date_ = '2020-06-17'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### New Labeled Users Accounts By Support Team #######################\n",
    "\n",
    "## Import the labeled fraud risk account by the support team\n",
    "path = \"/Users/dwahid/Documents/GitHub/fraud_detection/data/fraud_risk_acc_to_be_labeled_for_support/\"\n",
    "\n",
    "## without date\n",
    "# file_name = \"new_fraud_risk_acc_tbl_for_support\"\n",
    "# path_fra_labeled_new = path + file_name + \".csv\"  # the labeled data file path and name\n",
    "\n",
    "# with date\n",
    "file_name = \"new_fraud_risk_acc_tbl_for_support_\"\n",
    "path_fra_labeled_new = path + file_name + date_ + \".csv\"  # the labeled data file path and name\n",
    "\n",
    "\n",
    "\n",
    "df_fra_labeled_new = pd.read_csv(path_fra_labeled_new, sep=\",\")  # read the labeled data\n",
    "df_fra_labeled_new = df_fra_labeled_new[df_fra_labeled_new.fraud_label != 'TBL']  # get only labeled accounts\n",
    "# df_fra_labeled_new = df_fra_labeled_new.drop(columns=['fraud_risk_score'], axis=1)\n",
    "df_fra_labeled_new_id = df_fra_labeled_new[['systemid', 'fraud_label', 'support_note']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking\n",
    "df_fra_labeled_new.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fra_labeled_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Labeled User Accounts (From Begining): For Support CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Merge: Labeled Users Accounts (From Begining) #######################\n",
    "\n",
    "## Import all already labeled fraud risk accounts (FRA)\n",
    "df_fra_labeled = pd.read_csv('/Users/dwahid/Documents/GitHub/fraud_detection/data/fraud_risk_acc_labeled/all_fraud_status_labeled_by_support.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fra_labeled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge new labeled accounts with already labeled accounts\n",
    "df_fra_labeled_merged = df_fra_labeled.append(df_fra_labeled_new, sort=False)\n",
    "\n",
    "## Reindexing\n",
    "df_fra_labeled_merged = df_fra_labeled_merged.reset_index(drop=True)\n",
    "\n",
    "## Save the merge list of fraud status labeled accounts labeled by support team\n",
    "path_and_file_name = '/Users/dwahid/Documents/GitHub/fraud_detection/data/fraud_risk_acc_labeled/all_fraud_status_labeled_by_support.csv'\n",
    "df_fra_labeled_merged.to_csv(path_and_file_name, sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fra_labeled_merged.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fra_labeled_merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Labele Fraud Accounts (From Bigining): For Training Data TSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### New RL Training Data: Unlabeled ########################################\n",
    "\n",
    "## Import all features information of fraud risk accunts\n",
    "path = \"/Users/dwahid/Documents/GitHub/fraud_detection/data/fraud_risk_acc_to_be_labeled_all_features/\"\n",
    "\n",
    "## without date\n",
    "# file_name = \"new_fraud_risk_acc_tbl_all_features\"\n",
    "# path_fra_new_unlabeled = path + file_name + \".tsv\"  # the labeled data file path and name\n",
    "\n",
    "## with date\n",
    "file_name = \"new_fraud_risk_acc_tbl_all_features_\"\n",
    "path_fra_new_unlabeled = path + file_name + date_ + \".tsv\"  # the labeled data file path and name\n",
    "\n",
    "\n",
    "df_fra_new_unlabeled = pd.read_csv(path_fra_new_unlabeled, sep=\"\\t\")  # read the labeled data\n",
    "df_fra_new_unlabeled = df_fra_new_unlabeled.drop(columns=['fraud_label', 'support_note'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fra_new_unlabeled.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(df_fra_new_unlabeled.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### New RL Training Data: Labeled by Support Team ###########################\n",
    "\n",
    "## Cross users accounts, if any account is already labeled then remove it \n",
    "df_fra_merge_label_new = pd.merge(df_fra_new_unlabeled, df_fra_labeled_new_id, how='left', on=['systemid'], indicator=True)\n",
    "df_fra_labeled_new = df_fra_merge_label_new[df_fra_merge_label_new._merge == 'both']\n",
    "df_fra_labeled_new = df_fra_labeled_new.drop(columns=['_merge'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fra_labeled_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fra_labeled_new.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Merge RL Training Data: From Begining ##########################################\n",
    "df_rl_labeled = pd.read_csv('/Users/dwahid/Documents/GitHub/fraud_detection/data/fraud_risk_acc_labeled_rl_training/all_fraud_risk_acc_labeled_by_support_for_rl_training.tsv', sep=\"\\t\")\n",
    "\n",
    "# Number of RL training data (so far collected) before merging the current list\n",
    "df_rl_labeled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merging new RL training data with the old RL training data\n",
    "df_rl_labeled_merged = df_rl_labeled.append(df_fra_labeled_new)\n",
    "df_rl_labeled_merged = df_rl_labeled_merged.reset_index(drop=True)\n",
    "\n",
    "## Save the merge list of fraud status labeled accounts labeled by support team\n",
    "path_and_file_name2 = '/Users/dwahid/Documents/GitHub/fraud_detection/data/fraud_risk_acc_labeled_rl_training/all_fraud_risk_acc_labeled_by_support_for_rl_training.tsv'\n",
    "df_rl_labeled_merged.to_csv(path_and_file_name2, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rl_labeled_merged.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rl_labeled_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rl_labeled_merged.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking\n",
    "df_fra_labeled_merged.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
