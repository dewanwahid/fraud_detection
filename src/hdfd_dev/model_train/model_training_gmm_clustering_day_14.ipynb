{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud Detection Day 14 Model: Gaussian Mixture Model (GMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy import stats\n",
    "get_ipython().magic(u'config IPCompleter.greedy=True')\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import mixture\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import and Filter Features Data for Day 14\n",
    "\n",
    "### 1.1 Import day 14 final features data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import day 14 features data \n",
    "df = pd.read_csv(\"path\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Editing dataframe colume names\n",
    "df.columns = [\n",
    "    col.replace('-', '').replace('/', '')\n",
    "    for col in df.columns\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sorting column in the dataframe\n",
    "df = df.reindex(sorted(df.columns), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cleaning Data for GMM Clustering\n",
    "### 2.1 Drop row with missing 'id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the features columns varinaces\n",
    "df = df.drop(columns=['feature_list'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep a copy of the original dataframe\n",
    "df_orig = df.copy()\n",
    "\n",
    "# Rearranging Columns (alphabatically)\n",
    "df = df.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Feature column normalization (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized all features columns except the 'id'\n",
    "column_names_to_not_normalize = ['id']\n",
    "column_names_to_normalize = [x for x in list(df) if x not in column_names_to_not_normalize ]\n",
    "\n",
    "# Min-Max standarization model\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transfrom the data\n",
    "x = df[column_names_to_normalize].values\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df_temp = pd.DataFrame(x_scaled, columns=column_names_to_normalize, index = df.index)\n",
    "df[column_names_to_normalize] = df_temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the standarization model: min-max scalar\n",
    "filename_minmax_scaler = 'path'\n",
    "pickle.dump(min_max_scaler, open(filename_minmax_scaler, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any column with 'Nan'\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# Drop the 'id' \n",
    "df_noid = df.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Determine Number of Clusters: BIC Score Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# Determine the Number of Clusters ########################################\n",
    "# from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# gm_bic= []\n",
    "# gm_score=[]\n",
    "# for i in range(2,12):\n",
    "#     gm = GaussianMixture(n_components=i,n_init=10,tol=1e-3,max_iter=1000).fit(df_noid)\n",
    "#     print(\"BIC for number of cluster(s) {}: {}\".format(i,gm.bic(df_noid)))\n",
    "#     print(\"Log-likelihood score for number of cluster(s) {}: {}\".format(i,gm.score(df_noid)))\n",
    "#     print(\"-\"*100)\n",
    "#     gm_bic.append(-gm.bic(df_noid))\n",
    "#     gm_score.append(gm.score(df_noid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.title(\"The Gaussian Mixture model BIC \\nfor determining number of clusters\\n\",fontsize=16)\n",
    "# plt.scatter(x=[i for i in range(2,12)],y=np.log(gm_bic),s=150,edgecolor='k')\n",
    "# plt.grid(True)\n",
    "# plt.xlabel(\"Number of clusters\",fontsize=14)\n",
    "# plt.ylabel(\"Log of Gaussian mixture BIC score\",fontsize=15)\n",
    "# plt.xticks([i for i in range(2,12)],fontsize=14)\n",
    "# plt.yticks(fontsize=15)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fitting GMM Clustering\n",
    "From the above elbow graph, we fix number of clusters n = 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################### GMM Training (n=6) #######################################################\n",
    "\n",
    "# GMM fitting to the data \n",
    "from sklearn.mixture import GaussianMixture\n",
    "gmm = GaussianMixture(n_components=6)\n",
    "gmm.fit(df_noid)\n",
    "\n",
    "# Predicting clustering\n",
    "cluster_predict = gmm.predict(df_noid)\n",
    "\n",
    "# Adding clusters id of each account to the dataframe\n",
    "df_orig['cluster_id'] = cluster_predict\n",
    "\n",
    "# save the model to disk\n",
    "filename_clustering = 'path'\n",
    "pickle.dump(gmm, open(filename_clustering, 'wb'))\n",
    "\n",
    "# Export the original users data with corresponding cluster id label (clustering output)\n",
    "df_orig.to_csv(\"path\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################### GMM Training (n=7) #######################################################\n",
    "\n",
    "# GMM fitting to the data \n",
    "from sklearn.mixture import GaussianMixture\n",
    "gmm = GaussianMixture(n_components=7)\n",
    "gmm.fit(df_noid)\n",
    "\n",
    "# Predicting clustering\n",
    "cluster_predict = gmm.predict(df_noid)\n",
    "\n",
    "# Adding clusters id of each account to the dataframe\n",
    "df_orig['cluster_id'] = cluster_predict\n",
    "\n",
    "# save the model to disk\n",
    "filename_clustering = 'path'\n",
    "pickle.dump(gmm, open(filename_clustering, 'wb'))\n",
    "\n",
    "# Export the original users data with corresponding cluster id label (clustering output)\n",
    "df_orig.to_csv(\"path\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################### GMM Training (n=8) #######################################################\n",
    "\n",
    "# GMM fitting to the data \n",
    "from sklearn.mixture import GaussianMixture\n",
    "gmm = GaussianMixture(n_components=8)\n",
    "gmm.fit(df_noid)\n",
    "\n",
    "# Predicting clustering\n",
    "cluster_predict = gmm.predict(df_noid)\n",
    "\n",
    "# Adding clusters id of each account to the dataframe\n",
    "df_orig['cluster_id'] = cluster_predict\n",
    "\n",
    "# save the model to disk\n",
    "filename_clustering = 'path'\n",
    "pickle.dump(gmm, open(filename_clustering, 'wb'))\n",
    "\n",
    "# Export the original users data with corresponding cluster id label (clustering output)\n",
    "df_orig.to_csv(\"path\", sep=\"\\t\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
