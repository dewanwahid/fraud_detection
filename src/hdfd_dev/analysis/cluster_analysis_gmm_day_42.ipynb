{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Analysis: GMM Day 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy import stats\n",
    "get_ipython().magic(u'config IPCompleter.greedy=True')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get Day 28 GMM Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the GMM clustering output\n",
    "df = pd.read_csv(\"data/model_outputs_gmm_for_nn_training/gmm_clutering_outputs_day_42_k6.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating 'systemid' according to 'cluster_id'\n",
    "df_c0 = df[df.cluster_id == 0]\n",
    "df_c1 = df[df.cluster_id == 1]\n",
    "df_c2 = df[df.cluster_id == 2]\n",
    "df_c3 = df[df.cluster_id == 3]\n",
    "df_c4 = df[df.cluster_id == 4]\n",
    "df_c5 = df[df.cluster_id == 5]\n",
    "df_c6 = df[df.cluster_id == 6]\n",
    "df_c7 = df[df.cluster_id == 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing 'NaN' with zero\n",
    "df_c0.fillna(0, inplace=True)\n",
    "df_c1.fillna(0, inplace=True)\n",
    "df_c2.fillna(0, inplace=True)\n",
    "df_c3.fillna(0, inplace=True)\n",
    "df_c4.fillna(0, inplace=True)\n",
    "df_c5.fillna(0, inplace=True)\n",
    "df_c6.fillna(0, inplace=True)\n",
    "df_c7.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accounts list (systemid) in each cluster\n",
    "c0_systemid_list = list(df_c0['systemid'])\n",
    "c1_systemid_list = list(df_c1['systemid'])\n",
    "c2_systemid_list = list(df_c2['systemid'])\n",
    "c3_systemid_list = list(df_c3['systemid'])\n",
    "c4_systemid_list = list(df_c4['systemid'])\n",
    "c5_systemid_list = list(df_c5['systemid'])\n",
    "c6_systemid_list = list(df_c6['systemid'])\n",
    "c7_systemid_list = list(df_c7['systemid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Store and print cluster sizes \n",
    "# cls_sizes = {'cluster_id': ['cluster 00', \n",
    "#                             'cluster 01', \n",
    "#                             'cluster 02', \n",
    "#                             'cluster 03', \n",
    "#                             'cluster 04', \n",
    "#                             'cluster 05'], \n",
    "#              'size' : [df_c0.shape[0], \n",
    "#                        df_c1.shape[0], \n",
    "#                        df_c2.shape[0], \n",
    "#                        df_c3.shape[0], \n",
    "#                        df_c4.shape[0], \n",
    "#                        df_c5.shape[0]]}\n",
    "\n",
    "# # Store and print cluster sizes \n",
    "# cls_sizes = {'cluster_id': ['cluster 00', \n",
    "#                             'cluster 01', \n",
    "#                             'cluster 02', \n",
    "#                             'cluster 03', \n",
    "#                             'cluster 04', \n",
    "#                             'cluster 05',\n",
    "#                             'cluster 06'], \n",
    "#              'size' : [df_c0.shape[0], \n",
    "#                        df_c1.shape[0], \n",
    "#                        df_c2.shape[0], \n",
    "#                        df_c3.shape[0], \n",
    "#                        df_c4.shape[0], \n",
    "#                        df_c5.shape[0],\n",
    "#                        df_c6.shape[0]]}\n",
    "\n",
    "# Store and print cluster sizes \n",
    "cls_sizes = {'cluster_id': ['cluster 00', \n",
    "                            'cluster 01', \n",
    "                            'cluster 02', \n",
    "                            'cluster 03', \n",
    "                            'cluster 04', \n",
    "                            'cluster 05',\n",
    "                            'cluster 06',\n",
    "                            'cluster 07'], \n",
    "             'size' : [df_c0.shape[0], \n",
    "                       df_c1.shape[0], \n",
    "                       df_c2.shape[0], \n",
    "                       df_c3.shape[0], \n",
    "                       df_c4.shape[0], \n",
    "                       df_c5.shape[0],\n",
    "                       df_c6.shape[0],\n",
    "                       df_c7.shape[0]]}\n",
    "\n",
    "\n",
    "df_cls_sizes = pd.DataFrame(cls_sizes, columns =['cluster_id', 'size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Number of Fraud Accounts in Each Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import fraud accounts list dated in last 12 months\n",
    "fraud_accounts = pd.read_csv(\"data/fraud_risk_acc_historic/fraud_accounts_12months.tsv\", sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking \n",
    "fraud_accounts.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## Checking the number of fraud accounts exist in each Cluster ##########################\n",
    "\n",
    "fraud_accounts_12months_list = list(fraud_accounts['systemid'])\n",
    "\n",
    "\n",
    "# Initialization: The number of fraud accounts in each clusters\n",
    "fraud_accounts_num_c0 = 0\n",
    "fraud_accounts_num_c1 = 0\n",
    "fraud_accounts_num_c2 = 0\n",
    "fraud_accounts_num_c3 = 0\n",
    "fraud_accounts_num_c4 = 0\n",
    "fraud_accounts_num_c5 = 0\n",
    "fraud_accounts_num_c6 = 0\n",
    "fraud_accounts_num_c7 = 0\n",
    "\n",
    "# Initialization: The fraud accounts in each clusters\n",
    "fraud_accounts_c0 = []\n",
    "fraud_accounts_c1 = []\n",
    "fraud_accounts_c2 = []\n",
    "fraud_accounts_c3 = []\n",
    "fraud_accounts_c4 = []\n",
    "fraud_accounts_c5 = []\n",
    "fraud_accounts_c6 = []\n",
    "fraud_accounts_c7 = []\n",
    "\n",
    "for systemid in fraud_accounts_12months_list:\n",
    "    \n",
    "    # checking in cluster 00\n",
    "    if systemid in c0_systemid_list:\n",
    "        #print('Exist Cluster 00')\n",
    "        fraud_accounts_num_c0 += 1\n",
    "        fraud_accounts_c0.append(systemid)\n",
    "        \n",
    "    # checking in cluster 01   \n",
    "    elif systemid in c1_systemid_list:\n",
    "        #print('Exist Cluster 01')\n",
    "        fraud_accounts_num_c1 += 1\n",
    "        fraud_accounts_c1.append(systemid)\n",
    "        \n",
    "    # checking in cluster 02\n",
    "    elif systemid in c2_systemid_list:\n",
    "        #print('Exist Cluster 02')\n",
    "        fraud_accounts_num_c2 += 1\n",
    "        fraud_accounts_c2.append(systemid)\n",
    "        \n",
    "    # checking in cluster 03\n",
    "    elif systemid in c3_systemid_list:\n",
    "        #print('Exist Cluster 03')\n",
    "        fraud_accounts_num_c3 += 1\n",
    "        fraud_accounts_c3.append(systemid)\n",
    "    \n",
    "    # checking in cluster 04\n",
    "    elif systemid in c4_systemid_list:\n",
    "        #print('Exist Cluster 04')\n",
    "        fraud_accounts_num_c4 += 1\n",
    "        fraud_accounts_c4.append(systemid)\n",
    "        \n",
    "    # checking in cluster 05\n",
    "    elif systemid in c5_systemid_list:\n",
    "        #print('Exist Cluster 05')\n",
    "        fraud_accounts_num_c5 += 1\n",
    "        fraud_accounts_c5.append(systemid)\n",
    "    \n",
    "    # checking in cluster 06\n",
    "    elif systemid in c5_systemid_list:\n",
    "        #print('Exist Cluster 06')\n",
    "        fraud_accounts_num_c6 += 1\n",
    "        fraud_accounts_c6.append(systemid)\n",
    "        \n",
    "    # checking in cluster 07\n",
    "    elif systemid in c7_systemid_list:\n",
    "        #print('Exist Cluster 07')\n",
    "        fraud_accounts_num_c7 += 1\n",
    "        fraud_accounts_c7.append(systemid)\n",
    "        \n",
    "    else:\n",
    "        #print('NOT')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Store and print the number of existance of fraud accounts in each cluster\n",
    "# fraud_accounts_num = {'cluster_id': ['cluster 00', \n",
    "#                                      'cluster 01', \n",
    "#                                      'cluster 02', \n",
    "#                                      'cluster 03', \n",
    "#                                      'cluster 04', \n",
    "#                                      'cluster 05'], \n",
    "#              '#fraud_accounts' : [fraud_accounts_num_c0, \n",
    "#                                   fraud_accounts_num_c1, \n",
    "#                                   fraud_accounts_num_c2, \n",
    "#                                   fraud_accounts_num_c3, \n",
    "#                                   fraud_accounts_num_c4, \n",
    "#                                   fraud_accounts_num_c5]}\n",
    "\n",
    "# # Store and print the number of existance of fraud accounts in each cluster\n",
    "# fraud_accounts_num = {'cluster_id': ['cluster 00', \n",
    "#                                      'cluster 01', \n",
    "#                                      'cluster 02', \n",
    "#                                      'cluster 03', \n",
    "#                                      'cluster 04', \n",
    "#                                      'cluster 05',\n",
    "#                                      'cluster 06'], \n",
    "#              '#fraud_accounts' : [fraud_accounts_num_c0, \n",
    "#                                   fraud_accounts_num_c1, \n",
    "#                                   fraud_accounts_num_c2, \n",
    "#                                   fraud_accounts_num_c3, \n",
    "#                                   fraud_accounts_num_c4, \n",
    "#                                   fraud_accounts_num_c5,\n",
    "#                                   fraud_accounts_num_c6]}\n",
    "\n",
    "# Store and print the number of existance of fraud accounts in each cluster\n",
    "fraud_accounts_num = {'cluster_id': ['cluster 00', \n",
    "                                     'cluster 01', \n",
    "                                     'cluster 02', \n",
    "                                     'cluster 03', \n",
    "                                     'cluster 04', \n",
    "                                     'cluster 05',\n",
    "                                     'cluster 06',\n",
    "                                     'cluster 07'], \n",
    "             '#fraud_accounts' : [fraud_accounts_num_c0, \n",
    "                                  fraud_accounts_num_c1, \n",
    "                                  fraud_accounts_num_c2, \n",
    "                                  fraud_accounts_num_c3, \n",
    "                                  fraud_accounts_num_c4, \n",
    "                                  fraud_accounts_num_c5,\n",
    "                                  fraud_accounts_num_c6,\n",
    "                                  fraud_accounts_num_c7]}\n",
    "\n",
    "df_cls_fraud_accounts_num = pd.DataFrame(fraud_accounts_num, columns =['cluster_id', '#fraud_accounts'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add number of frauds accounts corresponding to the cluster sieze and id\n",
    "df_cls_sizes['#fraud_accounts']= df_cls_fraud_accounts_num['#fraud_accounts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking\n",
    "df_cls_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Features Corresponding to Each Clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all of the weekly final features data\n",
    "df_day_7 = pd.read_csv(\"data/training_data/final_features_day_07_no_fbtest_onlyimp_noinactive.tsv\", sep=\"\\t\")\n",
    "df_day_14 = pd.read_csv(\"data/training_data/final_features_day_14_no_fbtest_onlyimp_noinactive.tsv\", sep=\"\\t\")\n",
    "df_day_21 = pd.read_csv(\"data/training_data/final_features_day_21_no_fbtest_onlyimp_noinactive.tsv\", sep=\"\\t\")\n",
    "df_day_28 = pd.read_csv(\"data/training_data/final_features_day_28_no_fbtest_onlyimp_noinactive.tsv\", sep=\"\\t\")\n",
    "df_day_35 = pd.read_csv(\"data/training_data/final_features_day_35.tsv\", sep=\"\\t\")\n",
    "df_day_42 = pd.read_csv(\"data/training_data/final_features_day_42.tsv\", sep=\"\\t\")\n",
    "df_day_49 = pd.read_csv(\"data/training_data/final_features_day_49.tsv\", sep=\"\\t\")\n",
    "df_day_56 = pd.read_csv(\"data/training_data/final_features_day_56.tsv\", sep=\"\\t\")\n",
    "df_day_63 = pd.read_csv(\"data/training_data/final_features_day_63.tsv\", sep=\"\\t\")\n",
    "df_day_70 = pd.read_csv(\"data/training_data/final_features_day_70.tsv\", sep=\"\\t\")\n",
    "df_day_77 = pd.read_csv(\"data/training_data/final_features_day_77.tsv\", sep=\"\\t\")\n",
    "df_day_84 = pd.read_csv(\"data/training_data/final_features_day_84.tsv\", sep=\"\\t\")\n",
    "df_day_91 = pd.read_csv(\"data/training_data/final_features_day_91.tsv\", sep=\"\\t\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the columns\n",
    "df_day_7 = df_day_7.rename(columns={ \"avg_wc_description_day_7\": \"avg_wc_description\",\n",
    "                                       \"avg_wc_notes_day_7\": \"avg_wc_notes\",\n",
    "                                       \"avg_wc_terms_day_7\": \"avg_wc_terms\",\n",
    "                                       \"avg_wc_address_day_7\": \"avg_wc_address\",\n",
    "                                       \"invoice_count_day_7\": \"invoice_count\",\n",
    "                                       \"client_count_day_7\": \"client_count\"})\n",
    "\n",
    "df_day_14 = df_day_14.rename(columns={ \"avg_wc_description_day_14\": \"avg_wc_description\",\n",
    "                                       \"avg_wc_notes_day_14\": \"avg_wc_notes\",\n",
    "                                       \"avg_wc_terms_day_14\": \"avg_wc_terms\",\n",
    "                                       \"avg_wc_address_day_14\": \"avg_wc_address\",\n",
    "                                       \"invoice_count_day_14\": \"invoice_count\",\n",
    "                                       \"client_count_day_14\": \"client_count\"})\n",
    "\n",
    "df_day_21 = df_day_21.rename(columns={ \"avg_wc_description_day_21\": \"avg_wc_description\",\n",
    "                                       \"avg_wc_notes_day_21\": \"avg_wc_notes\",\n",
    "                                       \"avg_wc_terms_day_21\": \"avg_wc_terms\",\n",
    "                                       \"avg_wc_address_day_21\": \"avg_wc_address\",\n",
    "                                       \"invoice_count_day_21\": \"invoice_count\",\n",
    "                                       \"client_count_day_21\": \"client_count\"})\n",
    "\n",
    "df_day_28 = df_day_28.rename(columns={ \"avg_wc_description_day_28\": \"avg_wc_description\",\n",
    "                                       \"avg_wc_notes_day_28\": \"avg_wc_notes\",\n",
    "                                       \"avg_wc_terms_day_28\": \"avg_wc_terms\",\n",
    "                                       \"avg_wc_address_day_28\": \"avg_wc_address\",\n",
    "                                       \"invoice_count_day_28\": \"invoice_count\",\n",
    "                                       \"client_count_day_28\": \"client_count\"})\n",
    "\n",
    "df_day_35 = df_day_35.rename(columns={ \"avg_wc_description_day_35\": \"avg_wc_description\",\n",
    "                                       \"avg_wc_notes_day_35\": \"avg_wc_notes\",\n",
    "                                       \"avg_wc_terms_day_35\": \"avg_wc_terms\",\n",
    "                                       \"avg_wc_address_day_35\": \"avg_wc_address\",\n",
    "                                       \"invoice_count_day_35\": \"invoice_count\",\n",
    "                                       \"client_count_day_35\": \"client_count\"})\n",
    "\n",
    "df_day_42 = df_day_42.rename(columns={ \"avg_wc_description_day_42\": \"avg_wc_description\",\n",
    "                                       \"avg_wc_notes_day_42\": \"avg_wc_notes\",\n",
    "                                       \"avg_wc_terms_day_42\": \"avg_wc_terms\",\n",
    "                                       \"avg_wc_address_day_42\": \"avg_wc_address\",\n",
    "                                       \"invoice_count_day_42\": \"invoice_count\",\n",
    "                                       \"client_count_day_42\": \"client_count\"})\n",
    "\n",
    "df_day_49 = df_day_49.rename(columns={ \"avg_wc_description_day_49\": \"avg_wc_description\",\n",
    "                                       \"avg_wc_notes_day_49\": \"avg_wc_notes\",\n",
    "                                       \"avg_wc_terms_day_49\": \"avg_wc_terms\",\n",
    "                                       \"avg_wc_address_day_49\": \"avg_wc_address\",\n",
    "                                       \"invoice_count_day_49\": \"invoice_count\",\n",
    "                                       \"client_count_day_49\": \"client_count\"})\n",
    "\n",
    "df_day_56 = df_day_56.rename(columns={ \"avg_wc_description_day_56\": \"avg_wc_description\",\n",
    "                                       \"avg_wc_notes_day_56\": \"avg_wc_notes\",\n",
    "                                       \"avg_wc_terms_day_56\": \"avg_wc_terms\",\n",
    "                                       \"avg_wc_address_day_56\": \"avg_wc_address\",\n",
    "                                       \"invoice_count_day_56\": \"invoice_count\",\n",
    "                                       \"client_count_day_56\": \"client_count\"})\n",
    "\n",
    "df_day_63 = df_day_63.rename(columns={ \"avg_wc_description_day_63\": \"avg_wc_description\",\n",
    "                                       \"avg_wc_notes_day_63\": \"avg_wc_notes\",\n",
    "                                       \"avg_wc_terms_day_63\": \"avg_wc_terms\",\n",
    "                                       \"avg_wc_address_day_63\": \"avg_wc_address\",\n",
    "                                       \"invoice_count_day_63\": \"invoice_count\",\n",
    "                                       \"client_count_day_63\": \"client_count\"})\n",
    "\n",
    "df_day_70 = df_day_70.rename(columns={ \"avg_wc_description_day_70\": \"avg_wc_description\",\n",
    "                                       \"avg_wc_notes_day_70\": \"avg_wc_notes\",\n",
    "                                       \"avg_wc_terms_day_70\": \"avg_wc_terms\",\n",
    "                                       \"avg_wc_address_day_70\": \"avg_wc_address\",\n",
    "                                       \"invoice_count_day_70\": \"invoice_count\",\n",
    "                                       \"client_count_day_70\": \"client_count\"})\n",
    "\n",
    "df_day_77 = df_day_77.rename(columns={ \"avg_wc_description_day_77\": \"avg_wc_description\",\n",
    "                                       \"avg_wc_notes_day_77\": \"avg_wc_notes\",\n",
    "                                       \"avg_wc_terms_day_77\": \"avg_wc_terms\",\n",
    "                                       \"avg_wc_address_day_77\": \"avg_wc_address\",\n",
    "                                       \"invoice_count_day_77\": \"invoice_count\",\n",
    "                                       \"client_count_day_77\": \"client_count\"})\n",
    "\n",
    "df_day_84 = df_day_84.rename(columns={ \"avg_wc_description_day_84\": \"avg_wc_description\",\n",
    "                                       \"avg_wc_notes_day_84\": \"avg_wc_notes\",\n",
    "                                       \"avg_wc_terms_day_84\": \"avg_wc_terms\",\n",
    "                                       \"avg_wc_address_day_84\": \"avg_wc_address\",\n",
    "                                       \"invoice_count_day_84\": \"invoice_count\",\n",
    "                                       \"client_count_day_84\": \"client_count\"})\n",
    "\n",
    "df_day_91 = df_day_91.rename(columns={ \"avg_wc_description_day_91\": \"avg_wc_description\",\n",
    "                                       \"avg_wc_notes_day_91\": \"avg_wc_notes\",\n",
    "                                       \"avg_wc_terms_day_91\": \"avg_wc_terms\",\n",
    "                                       \"avg_wc_address_day_91\": \"avg_wc_address\",\n",
    "                                       \"invoice_count_day_91\": \"invoice_count\",\n",
    "                                       \"client_count_day_91\": \"client_count\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### Each Cluster's Features in Each Week ##################################################\n",
    "\n",
    "\n",
    "# Cluster c0 acounts features in 1st to 13th week\n",
    "df_c0_features_day_7 = pd.concat([df_c0[['systemid']], df_day_7], axis=1, join='inner')\n",
    "df_c0_features_day_14 = pd.concat([df_c0[['systemid']], df_day_14], axis=1, join='inner')\n",
    "df_c0_features_day_21 = pd.concat([df_c0[['systemid']], df_day_21], axis=1, join='inner')\n",
    "df_c0_features_day_28 = pd.concat([df_c0[['systemid']], df_day_28], axis=1, join='inner')\n",
    "df_c0_features_day_35 = pd.concat([df_c0[['systemid']], df_day_35], axis=1, join='inner')\n",
    "df_c0_features_day_42 = pd.concat([df_c0[['systemid']], df_day_42], axis=1, join='inner')\n",
    "df_c0_features_day_49 = pd.concat([df_c0[['systemid']], df_day_49], axis=1, join='inner')\n",
    "df_c0_features_day_56 = pd.concat([df_c0[['systemid']], df_day_56], axis=1, join='inner')\n",
    "df_c0_features_day_63 = pd.concat([df_c0[['systemid']], df_day_63], axis=1, join='inner')\n",
    "df_c0_features_day_70 = pd.concat([df_c0[['systemid']], df_day_70], axis=1, join='inner')\n",
    "df_c0_features_day_77 = pd.concat([df_c0[['systemid']], df_day_77], axis=1, join='inner')\n",
    "df_c0_features_day_84 = pd.concat([df_c0[['systemid']], df_day_84], axis=1, join='inner')\n",
    "df_c0_features_day_91 = pd.concat([df_c0[['systemid']], df_day_91], axis=1, join='inner')\n",
    "\n",
    "\n",
    "# Cluster c1 acounts features in 1st to 13th week\n",
    "df_c1_features_day_7 = pd.concat([df_c1[['systemid']], df_day_7], axis=1, join='inner')\n",
    "df_c1_features_day_14 = pd.concat([df_c1[['systemid']], df_day_14], axis=1, join='inner')\n",
    "df_c1_features_day_21 = pd.concat([df_c1[['systemid']], df_day_21], axis=1, join='inner')\n",
    "df_c1_features_day_28 = pd.concat([df_c1[['systemid']], df_day_28], axis=1, join='inner')\n",
    "df_c1_features_day_35 = pd.concat([df_c1[['systemid']], df_day_35], axis=1, join='inner')\n",
    "df_c1_features_day_42 = pd.concat([df_c1[['systemid']], df_day_42], axis=1, join='inner')\n",
    "df_c1_features_day_49 = pd.concat([df_c1[['systemid']], df_day_49], axis=1, join='inner')\n",
    "df_c1_features_day_56 = pd.concat([df_c1[['systemid']], df_day_56], axis=1, join='inner')\n",
    "df_c1_features_day_63 = pd.concat([df_c1[['systemid']], df_day_63], axis=1, join='inner')\n",
    "df_c1_features_day_70 = pd.concat([df_c1[['systemid']], df_day_70], axis=1, join='inner')\n",
    "df_c1_features_day_77 = pd.concat([df_c1[['systemid']], df_day_77], axis=1, join='inner')\n",
    "df_c1_features_day_84 = pd.concat([df_c1[['systemid']], df_day_84], axis=1, join='inner')\n",
    "df_c1_features_day_91 = pd.concat([df_c1[['systemid']], df_day_91], axis=1, join='inner')\n",
    "\n",
    "# Cluster c2 acounts features in 1st to 13th week\n",
    "df_c2_features_day_7 = pd.concat([df_c2[['systemid']], df_day_7], axis=1, join='inner')\n",
    "df_c2_features_day_14 = pd.concat([df_c2[['systemid']], df_day_14], axis=1, join='inner')\n",
    "df_c2_features_day_21 = pd.concat([df_c2[['systemid']], df_day_21], axis=1, join='inner')\n",
    "df_c2_features_day_28 = pd.concat([df_c2[['systemid']], df_day_28], axis=1, join='inner')\n",
    "df_c2_features_day_35 = pd.concat([df_c2[['systemid']], df_day_35], axis=1, join='inner')\n",
    "df_c2_features_day_42 = pd.concat([df_c2[['systemid']], df_day_42], axis=1, join='inner')\n",
    "df_c2_features_day_49 = pd.concat([df_c2[['systemid']], df_day_49], axis=1, join='inner')\n",
    "df_c2_features_day_56 = pd.concat([df_c2[['systemid']], df_day_56], axis=1, join='inner')\n",
    "df_c2_features_day_63 = pd.concat([df_c2[['systemid']], df_day_63], axis=1, join='inner')\n",
    "df_c2_features_day_70 = pd.concat([df_c2[['systemid']], df_day_70], axis=1, join='inner')\n",
    "df_c2_features_day_77 = pd.concat([df_c2[['systemid']], df_day_77], axis=1, join='inner')\n",
    "df_c2_features_day_84 = pd.concat([df_c2[['systemid']], df_day_84], axis=1, join='inner')\n",
    "df_c2_features_day_91 = pd.concat([df_c2[['systemid']], df_day_91], axis=1, join='inner')\n",
    "\n",
    "\n",
    "# Cluster c3 acounts features in 1st to 13th week\n",
    "df_c3_features_day_7 = pd.concat([df_c3[['systemid']], df_day_7], axis=1, join='inner')\n",
    "df_c3_features_day_14 = pd.concat([df_c3[['systemid']], df_day_14], axis=1, join='inner')\n",
    "df_c3_features_day_21 = pd.concat([df_c3[['systemid']], df_day_21], axis=1, join='inner')\n",
    "df_c3_features_day_28 = pd.concat([df_c3[['systemid']], df_day_28], axis=1, join='inner')\n",
    "df_c3_features_day_35 = pd.concat([df_c3[['systemid']], df_day_35], axis=1, join='inner')\n",
    "df_c3_features_day_42 = pd.concat([df_c3[['systemid']], df_day_42], axis=1, join='inner')\n",
    "df_c3_features_day_49 = pd.concat([df_c3[['systemid']], df_day_49], axis=1, join='inner')\n",
    "df_c3_features_day_56 = pd.concat([df_c3[['systemid']], df_day_56], axis=1, join='inner')\n",
    "df_c3_features_day_63 = pd.concat([df_c3[['systemid']], df_day_63], axis=1, join='inner')\n",
    "df_c3_features_day_70 = pd.concat([df_c3[['systemid']], df_day_70], axis=1, join='inner')\n",
    "df_c3_features_day_77 = pd.concat([df_c3[['systemid']], df_day_77], axis=1, join='inner')\n",
    "df_c3_features_day_84 = pd.concat([df_c3[['systemid']], df_day_84], axis=1, join='inner')\n",
    "df_c3_features_day_91 = pd.concat([df_c3[['systemid']], df_day_91], axis=1, join='inner')\n",
    "\n",
    "\n",
    "# Cluster c4 acounts features in 1st to 13th week\n",
    "df_c4_features_day_7 = pd.concat([df_c4[['systemid']], df_day_7], axis=1, join='inner')\n",
    "df_c4_features_day_14 = pd.concat([df_c4[['systemid']], df_day_14], axis=1, join='inner')\n",
    "df_c4_features_day_21 = pd.concat([df_c4[['systemid']], df_day_21], axis=1, join='inner')\n",
    "df_c4_features_day_28 = pd.concat([df_c4[['systemid']], df_day_28], axis=1, join='inner')\n",
    "df_c4_features_day_35 = pd.concat([df_c4[['systemid']], df_day_35], axis=1, join='inner')\n",
    "df_c4_features_day_42 = pd.concat([df_c4[['systemid']], df_day_42], axis=1, join='inner')\n",
    "df_c4_features_day_49 = pd.concat([df_c4[['systemid']], df_day_49], axis=1, join='inner')\n",
    "df_c4_features_day_56 = pd.concat([df_c4[['systemid']], df_day_56], axis=1, join='inner')\n",
    "df_c4_features_day_63 = pd.concat([df_c4[['systemid']], df_day_63], axis=1, join='inner')\n",
    "df_c4_features_day_70 = pd.concat([df_c4[['systemid']], df_day_70], axis=1, join='inner')\n",
    "df_c4_features_day_77 = pd.concat([df_c4[['systemid']], df_day_77], axis=1, join='inner')\n",
    "df_c4_features_day_84 = pd.concat([df_c4[['systemid']], df_day_84], axis=1, join='inner')\n",
    "df_c4_features_day_91 = pd.concat([df_c4[['systemid']], df_day_91], axis=1, join='inner')\n",
    "\n",
    "\n",
    "# Cluster c5 acounts features in 1st to 13th week\n",
    "df_c5_features_day_7 = pd.concat([df_c5[['systemid']], df_day_7], axis=1, join='inner')\n",
    "df_c5_features_day_14 = pd.concat([df_c5[['systemid']], df_day_14], axis=1, join='inner')\n",
    "df_c5_features_day_21 = pd.concat([df_c5[['systemid']], df_day_21], axis=1, join='inner')\n",
    "df_c5_features_day_28 = pd.concat([df_c5[['systemid']], df_day_28], axis=1, join='inner')\n",
    "df_c5_features_day_35 = pd.concat([df_c5[['systemid']], df_day_35], axis=1, join='inner')\n",
    "df_c5_features_day_42 = pd.concat([df_c5[['systemid']], df_day_42], axis=1, join='inner')\n",
    "df_c5_features_day_49 = pd.concat([df_c5[['systemid']], df_day_49], axis=1, join='inner')\n",
    "df_c5_features_day_56 = pd.concat([df_c5[['systemid']], df_day_56], axis=1, join='inner')\n",
    "df_c5_features_day_63 = pd.concat([df_c5[['systemid']], df_day_63], axis=1, join='inner')\n",
    "df_c5_features_day_70 = pd.concat([df_c5[['systemid']], df_day_70], axis=1, join='inner')\n",
    "df_c5_features_day_77 = pd.concat([df_c5[['systemid']], df_day_77], axis=1, join='inner')\n",
    "df_c5_features_day_84 = pd.concat([df_c5[['systemid']], df_day_84], axis=1, join='inner')\n",
    "df_c5_features_day_91 = pd.concat([df_c5[['systemid']], df_day_91], axis=1, join='inner')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### The features names in this clusters\n",
    "\n",
    "feature_names = list(df_c0_features_day_7)\n",
    "\n",
    "# Remove the 'systemid'\n",
    "while 'systemid' in feature_names:\n",
    "    feature_names.remove('systemid')\n",
    "    \n",
    "while 'dualstripe/paypalgatewayexperienceinvoicepopupclick' in feature_names:\n",
    "    feature_names.remove('dualstripe/paypalgatewayexperienceinvoicepopupclick')\n",
    "\n",
    "while 'is_sales_managed' in feature_names:\n",
    "    feature_names.remove('is_sales_managed')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Check Each Feature Variation in Each Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################  Each feature for Cluster C0 in Each Week ##############################################\n",
    "\n",
    "\n",
    "def cluster_feature_plot(cls_method, cls_period, cls_size, path, feature_str):\n",
    "\n",
    "    # Day markers\n",
    "    day_marks = [7, 14, 21, 28, 35, 42, 49, 56, 63, 70, 77, 84, 91]\n",
    "\n",
    "    # Get the total number of payment declined by the accounts in cluster c0\n",
    "    pdec_c0_day_7 = df_c0_features_day_7[feature_str].mean()\n",
    "    pdec_c0_day_14 = df_c0_features_day_14[feature_str].mean()\n",
    "    pdec_c0_day_21 = df_c0_features_day_21[feature_str].mean()\n",
    "    pdec_c0_day_28 = df_c0_features_day_28[feature_str].mean()\n",
    "    pdec_c0_day_35 = df_c0_features_day_35[feature_str].mean()\n",
    "    pdec_c0_day_42 = df_c0_features_day_42[feature_str].mean()\n",
    "    pdec_c0_day_49 = df_c0_features_day_49[feature_str].mean()\n",
    "    pdec_c0_day_56 = df_c0_features_day_56[feature_str].mean()\n",
    "    pdec_c0_day_63 = df_c0_features_day_63[feature_str].mean()\n",
    "    pdec_c0_day_70 = df_c0_features_day_70[feature_str].mean()\n",
    "    pdec_c0_day_77 = df_c0_features_day_77[feature_str].mean()\n",
    "    pdec_c0_day_84 = df_c0_features_day_84[feature_str].mean()\n",
    "    pdec_c0_day_91 = df_c0_features_day_91[feature_str].mean()\n",
    "\n",
    "    # Create an array of weekley payment decline numbers\n",
    "    pdec_c0 = [pdec_c0_day_7, pdec_c0_day_14, pdec_c0_day_21, pdec_c0_day_28, pdec_c0_day_35, pdec_c0_day_42, \n",
    "               pdec_c0_day_49, pdec_c0_day_56, pdec_c0_day_63, pdec_c0_day_70, pdec_c0_day_77, pdec_c0_day_84,\n",
    "               pdec_c0_day_91]\n",
    "\n",
    "\n",
    "    # Get the total number of payment declined by the accounts in cluster c1\n",
    "    pdec_c1_day_7 = df_c1_features_day_7[feature_str].mean()\n",
    "    pdec_c1_day_14 = df_c1_features_day_14[feature_str].mean()\n",
    "    pdec_c1_day_21 = df_c1_features_day_21[feature_str].mean()\n",
    "    pdec_c1_day_28 = df_c1_features_day_28[feature_str].mean()\n",
    "    pdec_c1_day_35 = df_c1_features_day_35[feature_str].mean()\n",
    "    pdec_c1_day_42 = df_c1_features_day_42[feature_str].mean()\n",
    "    pdec_c1_day_49 = df_c1_features_day_49[feature_str].mean()\n",
    "    pdec_c1_day_56 = df_c1_features_day_56[feature_str].mean()\n",
    "    pdec_c1_day_63 = df_c1_features_day_63[feature_str].mean()\n",
    "    pdec_c1_day_70 = df_c1_features_day_70[feature_str].mean()\n",
    "    pdec_c1_day_77 = df_c1_features_day_77[feature_str].mean()\n",
    "    pdec_c1_day_84 = df_c1_features_day_84[feature_str].mean()\n",
    "    pdec_c1_day_91 = df_c1_features_day_91[feature_str].mean()\n",
    "\n",
    "    # Create an array of weekley payment decline numbers\n",
    "    pdec_c1 = [pdec_c1_day_7, pdec_c1_day_14, pdec_c1_day_21, pdec_c1_day_28, pdec_c1_day_35, pdec_c1_day_42, \n",
    "               pdec_c1_day_49, pdec_c1_day_56, pdec_c1_day_63, pdec_c1_day_70, pdec_c1_day_77, pdec_c1_day_84,\n",
    "               pdec_c1_day_91]\n",
    "\n",
    "\n",
    "    # Get the total number of payment declined by the accounts in cluster c2\n",
    "    pdec_c2_day_7 = df_c2_features_day_7[feature_str].mean()\n",
    "    pdec_c2_day_14 = df_c2_features_day_14[feature_str].mean()\n",
    "    pdec_c2_day_21 = df_c2_features_day_21[feature_str].mean()\n",
    "    pdec_c2_day_28 = df_c2_features_day_28[feature_str].mean()\n",
    "    pdec_c2_day_35 = df_c2_features_day_35[feature_str].mean()\n",
    "    pdec_c2_day_42 = df_c2_features_day_42[feature_str].mean()\n",
    "    pdec_c2_day_49 = df_c2_features_day_49[feature_str].mean()\n",
    "    pdec_c2_day_56 = df_c2_features_day_56[feature_str].mean()\n",
    "    pdec_c2_day_63 = df_c2_features_day_63[feature_str].mean()\n",
    "    pdec_c2_day_70 = df_c2_features_day_70[feature_str].mean()\n",
    "    pdec_c2_day_77 = df_c2_features_day_77[feature_str].mean()\n",
    "    pdec_c2_day_84 = df_c2_features_day_84[feature_str].mean()\n",
    "    pdec_c2_day_91 = df_c2_features_day_91[feature_str].mean()\n",
    "\n",
    "    # Create an array of weekley payment decline numbers\n",
    "    pdec_c2 = [pdec_c2_day_7, pdec_c2_day_14, pdec_c2_day_21, pdec_c2_day_28, pdec_c2_day_35, pdec_c2_day_42, \n",
    "               pdec_c2_day_49, pdec_c2_day_56, pdec_c2_day_63, pdec_c2_day_70, pdec_c2_day_77, pdec_c2_day_84,\n",
    "               pdec_c2_day_91]\n",
    "\n",
    "    # Get the total number of payment declined by the accounts in cluster c3\n",
    "    pdec_c3_day_7 = df_c3_features_day_7[feature_str].mean()\n",
    "    pdec_c3_day_14 = df_c3_features_day_14[feature_str].mean()\n",
    "    pdec_c3_day_21 = df_c3_features_day_21[feature_str].mean()\n",
    "    pdec_c3_day_28 = df_c3_features_day_28[feature_str].mean()\n",
    "    pdec_c3_day_35 = df_c3_features_day_35[feature_str].mean()\n",
    "    pdec_c3_day_42 = df_c3_features_day_42[feature_str].mean()\n",
    "    pdec_c3_day_49 = df_c3_features_day_49[feature_str].mean()\n",
    "    pdec_c3_day_56 = df_c3_features_day_56[feature_str].mean()\n",
    "    pdec_c3_day_63 = df_c3_features_day_63[feature_str].mean()\n",
    "    pdec_c3_day_70 = df_c3_features_day_70[feature_str].mean()\n",
    "    pdec_c3_day_77 = df_c3_features_day_77[feature_str].mean()\n",
    "    pdec_c3_day_84 = df_c3_features_day_84[feature_str].mean()\n",
    "    pdec_c3_day_91 = df_c3_features_day_91[feature_str].mean()\n",
    "\n",
    "    # Create an array of weekley payment decline numbers\n",
    "    pdec_c3 = [pdec_c3_day_7, pdec_c3_day_14, pdec_c3_day_21, pdec_c3_day_28, pdec_c3_day_35, pdec_c3_day_42, \n",
    "               pdec_c3_day_49, pdec_c3_day_56, pdec_c3_day_63, pdec_c3_day_70, pdec_c3_day_77, pdec_c3_day_84,\n",
    "               pdec_c3_day_91]\n",
    "\n",
    "    # Get the total number of payment declined by the accounts in cluster c4\n",
    "    pdec_c4_day_7 = df_c4_features_day_7[feature_str].mean()\n",
    "    pdec_c4_day_14 = df_c4_features_day_14[feature_str].mean()\n",
    "    pdec_c4_day_21 = df_c4_features_day_21[feature_str].mean()\n",
    "    pdec_c4_day_28 = df_c4_features_day_28[feature_str].mean()\n",
    "    pdec_c4_day_35 = df_c4_features_day_35[feature_str].mean()\n",
    "    pdec_c4_day_42 = df_c4_features_day_42[feature_str].mean()\n",
    "    pdec_c4_day_49 = df_c4_features_day_49[feature_str].mean()\n",
    "    pdec_c4_day_56 = df_c4_features_day_56[feature_str].mean()\n",
    "    pdec_c4_day_63 = df_c4_features_day_63[feature_str].mean()\n",
    "    pdec_c4_day_70 = df_c4_features_day_70[feature_str].mean()\n",
    "    pdec_c4_day_77 = df_c4_features_day_77[feature_str].mean()\n",
    "    pdec_c4_day_84 = df_c4_features_day_84[feature_str].mean()\n",
    "    pdec_c4_day_91 = df_c4_features_day_91[feature_str].mean()\n",
    "\n",
    "    # Create an array of weekley payment decline numbers\n",
    "    pdec_c4 = [pdec_c4_day_7, pdec_c4_day_14, pdec_c4_day_21, pdec_c4_day_28, pdec_c4_day_35, pdec_c4_day_42, \n",
    "               pdec_c4_day_49, pdec_c4_day_56, pdec_c4_day_63, pdec_c4_day_70, pdec_c4_day_77, pdec_c4_day_84,\n",
    "               pdec_c4_day_91]\n",
    "\n",
    "\n",
    "    # Get the total number of payment declined by the accounts in cluster c5\n",
    "    pdec_c5_day_7 = df_c5_features_day_7[feature_str].mean()\n",
    "    pdec_c5_day_14 = df_c5_features_day_14[feature_str].mean()\n",
    "    pdec_c5_day_21 = df_c5_features_day_21[feature_str].mean()\n",
    "    pdec_c5_day_28 = df_c5_features_day_28[feature_str].mean()\n",
    "    pdec_c5_day_35 = df_c5_features_day_35[feature_str].mean()\n",
    "    pdec_c5_day_42 = df_c5_features_day_42[feature_str].mean()\n",
    "    pdec_c5_day_49 = df_c5_features_day_49[feature_str].mean()\n",
    "    pdec_c5_day_56 = df_c5_features_day_56[feature_str].mean()\n",
    "    pdec_c5_day_63 = df_c5_features_day_63[feature_str].mean()\n",
    "    pdec_c5_day_70 = df_c5_features_day_70[feature_str].mean()\n",
    "    pdec_c5_day_77 = df_c5_features_day_77[feature_str].mean()\n",
    "    pdec_c5_day_84 = df_c5_features_day_84[feature_str].mean()\n",
    "    pdec_c5_day_91 = df_c5_features_day_91[feature_str].mean()\n",
    "\n",
    "    # Create an array of weekley payment decline numbers\n",
    "    pdec_c5 = [pdec_c5_day_7, pdec_c5_day_14, pdec_c5_day_21, pdec_c5_day_28, pdec_c5_day_35, pdec_c5_day_42, \n",
    "               pdec_c5_day_49, pdec_c5_day_56, pdec_c5_day_63, pdec_c5_day_70, pdec_c5_day_77, pdec_c5_day_84,\n",
    "               pdec_c5_day_91]\n",
    "\n",
    "\n",
    "    # Plot line\n",
    "    plt.figure()\n",
    "    plt.plot( day_marks, pdec_c0, marker='o', markerfacecolor='black', markersize=4, color='blue', linewidth=2, label=\"c00\")\n",
    "    plt.plot( day_marks, pdec_c1, marker='*', markerfacecolor='black', markersize=4, color='lime', linewidth=2, label=\"c01\")\n",
    "    plt.plot( day_marks, pdec_c2, marker='+', markerfacecolor='black', markersize=4, color='black', linewidth=2, label=\"c02\")\n",
    "    plt.plot( day_marks, pdec_c3, marker='^', markerfacecolor='black', markersize=4, color='orange', linewidth=2, label=\"c03\")\n",
    "    plt.plot( day_marks, pdec_c4, marker='o', markerfacecolor='black', markersize=4, color='green', linewidth=2, label=\"c04\")\n",
    "    plt.plot( day_marks, pdec_c5, marker='o', markerfacecolor='black', markersize=4, color='red', linewidth=2, label=\"c05\")\n",
    "    \n",
    "    plt.xlabel('days (7 to 91)')\n",
    "    plt.xlabel('days (7 to 91)')\n",
    "    plt.ylabel(feature_str)\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    # Save figure\n",
    "    fig_name = path + cls_method + '_' + cls_period + '_' + cls_size + '_' + feature_str + '.png'\n",
    "    plt.savefig(fig_name)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Identification\n",
    "cls_method = 'gmm'\n",
    "cls_period = 'day_14'\n",
    "cls_size = 'k6'\n",
    "path = \"data/figures/\"\n",
    "\n",
    "\n",
    "\n",
    "# Feature name string\n",
    "# feature_str = 'activateestimate'\n",
    "\n",
    "for feature_str in feature_names:\n",
    "    cluster_feature_plot(cls_method, cls_period, cls_size, path, feature_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################  Each feature for Cluster C0 in Each Week ##############################################\n",
    "\n",
    "\n",
    "def cluster_feature_plot(cls_method, cls_period, cls_size, path, feature_str):\n",
    "\n",
    "    # Day markers\n",
    "    day_marks = [7, 14, 21, 28, 35, 42, 49, 56, 63, 70, 77, 84, 91]\n",
    "\n",
    "    # Get the total number of payment declined by the accounts in cluster c0\n",
    "    pdec_c0_day_7 = df_c0_features_day_7[feature_str].max()\n",
    "    pdec_c0_day_14 = df_c0_features_day_14[feature_str].max()\n",
    "    pdec_c0_day_21 = df_c0_features_day_21[feature_str].max()\n",
    "    pdec_c0_day_28 = df_c0_features_day_28[feature_str].max()\n",
    "    pdec_c0_day_35 = df_c0_features_day_35[feature_str].max()\n",
    "    pdec_c0_day_42 = df_c0_features_day_42[feature_str].max()\n",
    "    pdec_c0_day_49 = df_c0_features_day_49[feature_str].max()\n",
    "    pdec_c0_day_56 = df_c0_features_day_56[feature_str].max()\n",
    "    pdec_c0_day_63 = df_c0_features_day_63[feature_str].max()\n",
    "    pdec_c0_day_70 = df_c0_features_day_70[feature_str].max()\n",
    "    pdec_c0_day_77 = df_c0_features_day_77[feature_str].max()\n",
    "    pdec_c0_day_84 = df_c0_features_day_84[feature_str].max()\n",
    "    pdec_c0_day_91 = df_c0_features_day_91[feature_str].max()\n",
    "\n",
    "    # Create an array of weekley payment decline numbers\n",
    "    pdec_c0 = [pdec_c0_day_7, pdec_c0_day_14, pdec_c0_day_21, pdec_c0_day_28, pdec_c0_day_35, pdec_c0_day_42, \n",
    "               pdec_c0_day_49, pdec_c0_day_56, pdec_c0_day_63, pdec_c0_day_70, pdec_c0_day_77, pdec_c0_day_84,\n",
    "               pdec_c0_day_91]\n",
    "\n",
    "\n",
    "    # Get the total number of payment declined by the accounts in cluster c1\n",
    "    pdec_c1_day_7 = df_c1_features_day_7[feature_str].max()\n",
    "    pdec_c1_day_14 = df_c1_features_day_14[feature_str].max()\n",
    "    pdec_c1_day_21 = df_c1_features_day_21[feature_str].max()\n",
    "    pdec_c1_day_28 = df_c1_features_day_28[feature_str].max()\n",
    "    pdec_c1_day_35 = df_c1_features_day_35[feature_str].max()\n",
    "    pdec_c1_day_42 = df_c1_features_day_42[feature_str].max()\n",
    "    pdec_c1_day_49 = df_c1_features_day_49[feature_str].max()\n",
    "    pdec_c1_day_56 = df_c1_features_day_56[feature_str].max()\n",
    "    pdec_c1_day_63 = df_c1_features_day_63[feature_str].max()\n",
    "    pdec_c1_day_70 = df_c1_features_day_70[feature_str].max()\n",
    "    pdec_c1_day_77 = df_c1_features_day_77[feature_str].max()\n",
    "    pdec_c1_day_84 = df_c1_features_day_84[feature_str].max()\n",
    "    pdec_c1_day_91 = df_c1_features_day_91[feature_str].max()\n",
    "\n",
    "    # Create an array of weekley payment decline numbers\n",
    "    pdec_c1 = [pdec_c1_day_7, pdec_c1_day_14, pdec_c1_day_21, pdec_c1_day_28, pdec_c1_day_35, pdec_c1_day_42, \n",
    "               pdec_c1_day_49, pdec_c1_day_56, pdec_c1_day_63, pdec_c1_day_70, pdec_c1_day_77, pdec_c1_day_84,\n",
    "               pdec_c1_day_91]\n",
    "\n",
    "\n",
    "    # Get the total number of payment declined by the accounts in cluster c2\n",
    "    pdec_c2_day_7 = df_c2_features_day_7[feature_str].max()\n",
    "    pdec_c2_day_14 = df_c2_features_day_14[feature_str].max()\n",
    "    pdec_c2_day_21 = df_c2_features_day_21[feature_str].max()\n",
    "    pdec_c2_day_28 = df_c2_features_day_28[feature_str].max()\n",
    "    pdec_c2_day_35 = df_c2_features_day_35[feature_str].max()\n",
    "    pdec_c2_day_42 = df_c2_features_day_42[feature_str].max()\n",
    "    pdec_c2_day_49 = df_c2_features_day_49[feature_str].max()\n",
    "    pdec_c2_day_56 = df_c2_features_day_56[feature_str].max()\n",
    "    pdec_c2_day_63 = df_c2_features_day_63[feature_str].max()\n",
    "    pdec_c2_day_70 = df_c2_features_day_70[feature_str].max()\n",
    "    pdec_c2_day_77 = df_c2_features_day_77[feature_str].max()\n",
    "    pdec_c2_day_84 = df_c2_features_day_84[feature_str].max()\n",
    "    pdec_c2_day_91 = df_c2_features_day_91[feature_str].max()\n",
    "\n",
    "    # Create an array of weekley payment decline numbers\n",
    "    pdec_c2 = [pdec_c2_day_7, pdec_c2_day_14, pdec_c2_day_21, pdec_c2_day_28, pdec_c2_day_35, pdec_c2_day_42, \n",
    "               pdec_c2_day_49, pdec_c2_day_56, pdec_c2_day_63, pdec_c2_day_70, pdec_c2_day_77, pdec_c2_day_84,\n",
    "               pdec_c2_day_91]\n",
    "\n",
    "    # Get the total number of payment declined by the accounts in cluster c3\n",
    "    pdec_c3_day_7 = df_c3_features_day_7[feature_str].max()\n",
    "    pdec_c3_day_14 = df_c3_features_day_14[feature_str].max()\n",
    "    pdec_c3_day_21 = df_c3_features_day_21[feature_str].max()\n",
    "    pdec_c3_day_28 = df_c3_features_day_28[feature_str].max()\n",
    "    pdec_c3_day_35 = df_c3_features_day_35[feature_str].max()\n",
    "    pdec_c3_day_42 = df_c3_features_day_42[feature_str].max()\n",
    "    pdec_c3_day_49 = df_c3_features_day_49[feature_str].max()\n",
    "    pdec_c3_day_56 = df_c3_features_day_56[feature_str].max()\n",
    "    pdec_c3_day_63 = df_c3_features_day_63[feature_str].max()\n",
    "    pdec_c3_day_70 = df_c3_features_day_70[feature_str].max()\n",
    "    pdec_c3_day_77 = df_c3_features_day_77[feature_str].max()\n",
    "    pdec_c3_day_84 = df_c3_features_day_84[feature_str].max()\n",
    "    pdec_c3_day_91 = df_c3_features_day_91[feature_str].max()\n",
    "\n",
    "    # Create an array of weekley payment decline numbers\n",
    "    pdec_c3 = [pdec_c3_day_7, pdec_c3_day_14, pdec_c3_day_21, pdec_c3_day_28, pdec_c3_day_35, pdec_c3_day_42, \n",
    "               pdec_c3_day_49, pdec_c3_day_56, pdec_c3_day_63, pdec_c3_day_70, pdec_c3_day_77, pdec_c3_day_84,\n",
    "               pdec_c3_day_91]\n",
    "\n",
    "    # Get the total number of payment declined by the accounts in cluster c4\n",
    "    pdec_c4_day_7 = df_c4_features_day_7[feature_str].max()\n",
    "    pdec_c4_day_14 = df_c4_features_day_14[feature_str].max()\n",
    "    pdec_c4_day_21 = df_c4_features_day_21[feature_str].max()\n",
    "    pdec_c4_day_28 = df_c4_features_day_28[feature_str].max()\n",
    "    pdec_c4_day_35 = df_c4_features_day_35[feature_str].max()\n",
    "    pdec_c4_day_42 = df_c4_features_day_42[feature_str].max()\n",
    "    pdec_c4_day_49 = df_c4_features_day_49[feature_str].max()\n",
    "    pdec_c4_day_56 = df_c4_features_day_56[feature_str].max()\n",
    "    pdec_c4_day_63 = df_c4_features_day_63[feature_str].max()\n",
    "    pdec_c4_day_70 = df_c4_features_day_70[feature_str].max()\n",
    "    pdec_c4_day_77 = df_c4_features_day_77[feature_str].max()\n",
    "    pdec_c4_day_84 = df_c4_features_day_84[feature_str].max()\n",
    "    pdec_c4_day_91 = df_c4_features_day_91[feature_str].max()\n",
    "\n",
    "    # Create an array of weekley payment decline numbers\n",
    "    pdec_c4 = [pdec_c4_day_7, pdec_c4_day_14, pdec_c4_day_21, pdec_c4_day_28, pdec_c4_day_35, pdec_c4_day_42, \n",
    "               pdec_c4_day_49, pdec_c4_day_56, pdec_c4_day_63, pdec_c4_day_70, pdec_c4_day_77, pdec_c4_day_84,\n",
    "               pdec_c4_day_91]\n",
    "\n",
    "\n",
    "    # Get the total number of payment declined by the accounts in cluster c5\n",
    "    pdec_c5_day_7 = df_c5_features_day_7[feature_str].max()\n",
    "    pdec_c5_day_14 = df_c5_features_day_14[feature_str].max()\n",
    "    pdec_c5_day_21 = df_c5_features_day_21[feature_str].max()\n",
    "    pdec_c5_day_28 = df_c5_features_day_28[feature_str].max()\n",
    "    pdec_c5_day_35 = df_c5_features_day_35[feature_str].max()\n",
    "    pdec_c5_day_42 = df_c5_features_day_42[feature_str].max()\n",
    "    pdec_c5_day_49 = df_c5_features_day_49[feature_str].max()\n",
    "    pdec_c5_day_56 = df_c5_features_day_56[feature_str].max()\n",
    "    pdec_c5_day_63 = df_c5_features_day_63[feature_str].max()\n",
    "    pdec_c5_day_70 = df_c5_features_day_70[feature_str].max()\n",
    "    pdec_c5_day_77 = df_c5_features_day_77[feature_str].max()\n",
    "    pdec_c5_day_84 = df_c5_features_day_84[feature_str].max()\n",
    "    pdec_c5_day_91 = df_c5_features_day_91[feature_str].max()\n",
    "\n",
    "    # Create an array of weekley payment decline numbers\n",
    "    pdec_c5 = [pdec_c5_day_7, pdec_c5_day_14, pdec_c5_day_21, pdec_c5_day_28, pdec_c5_day_35, pdec_c5_day_42, \n",
    "               pdec_c5_day_49, pdec_c5_day_56, pdec_c5_day_63, pdec_c5_day_70, pdec_c5_day_77, pdec_c5_day_84,\n",
    "               pdec_c5_day_91]\n",
    "\n",
    "\n",
    "    # Plot line\n",
    "    plt.figure()\n",
    "    plt.plot( day_marks, pdec_c0, marker='o', markerfacecolor='black', markersize=4, color='blue', linewidth=2, label=\"c0 (size: 145184- IF: 0)\")\n",
    "    plt.plot( day_marks, pdec_c1, marker='*', markerfacecolor='black', markersize=4, color='lime', linewidth=2, label=\"c1 (size: 575- IF: 0)\")\n",
    "    plt.plot( day_marks, pdec_c2, marker='+', markerfacecolor='black', markersize=4, color='black', linewidth=2, label=\"c2 (size: 60861- IF: 0)\")\n",
    "    plt.plot( day_marks, pdec_c3, marker='^', markerfacecolor='black', markersize=4, color='orange', linewidth=2, label=\"c3 (size: 15580- IF: 0)\")\n",
    "    plt.plot( day_marks, pdec_c4, marker='o', markerfacecolor='black', markersize=4, color='green', linewidth=2, label=\"c4 (size: 198815- IF: 0)\")\n",
    "    plt.plot( day_marks, pdec_c5, marker='o', markerfacecolor='black', markersize=4, color='red', linewidth=2, label=\"c5 (size: 17282- IF: 13)\")\n",
    "    \n",
    "    plt.xlabel('days (7 to 91)')\n",
    "    plt.xlabel('days (7 to 91)')\n",
    "    plt.ylabel(feature_str)\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    # Save figure\n",
    "    fig_name = path + cls_method + '_' + cls_period + '_' + cls_size + '_' + feature_str + '.png'\n",
    "    plt.savefig(fig_name)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Identification\n",
    "cls_method = 'gmm'\n",
    "cls_period = 'day_14'\n",
    "cls_size = 'k6'\n",
    "path = \"figures/\"\n",
    "\n",
    "\n",
    "\n",
    "# Feature name string\n",
    "# feature_str = 'activateestimate'\n",
    "\n",
    "for feature_str in feature_names:\n",
    "    cluster_feature_plot(cls_method, cls_period, cls_size, path, feature_str)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
